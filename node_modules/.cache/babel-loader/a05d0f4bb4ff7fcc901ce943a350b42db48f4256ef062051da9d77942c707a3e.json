{"ast":null,"code":"import { db } from '../config/firebase';\nimport { collection, getDocs, Timestamp, doc, writeBatch } from 'firebase/firestore';\nimport JSZip from 'jszip';\n\n/**\n * Service pour g√©rer l'int√©gration entre Firebase et SharePoint\n * Utilise une approche de synchronisation manuelle via fichiers CSV/JSON\n * pour contourner les limitations de double authentification\n */\nexport class SharePointService {\n  constructor() {\n    // Collections Firebase √† synchroniser\n    this.collections = ['passages', 'sites', 'tournees', 'vehicules'];\n  }\n  /**\n   * Exporte les donn√©es d'une collection Firebase au format CSV\n   * @param collectionName Nom de la collection √† exporter\n   * @returns Cha√Æne de caract√®res au format CSV\n   */\n  async exportCollectionToCSV(collectionName) {\n    try {\n      console.log(`üîÑ Exportation de la collection ${collectionName} au format CSV...`);\n\n      // R√©cup√©rer les donn√©es de la collection\n      const querySnapshot = await getDocs(collection(db, collectionName));\n      if (querySnapshot.empty) {\n        console.log(`‚ö†Ô∏è La collection ${collectionName} est vide.`);\n        return '';\n      }\n\n      // Extraire les donn√©es\n      const documents = querySnapshot.docs.map(doc => {\n        const data = doc.data();\n\n        // Convertir les Timestamp en cha√Ænes de caract√®res\n        const formattedData = {};\n        Object.entries(data).forEach(([key, value]) => {\n          if (value instanceof Timestamp) {\n            formattedData[key] = value.toDate().toISOString();\n          } else {\n            formattedData[key] = value;\n          }\n        });\n\n        // Ajouter l'ID du document\n        formattedData.id = doc.id;\n        return formattedData;\n      });\n\n      // Obtenir toutes les cl√©s uniques pour les en-t√™tes CSV\n      const allKeys = new Set();\n      documents.forEach(doc => {\n        Object.keys(doc).forEach(key => allKeys.add(key));\n      });\n      const headers = Array.from(allKeys);\n\n      // G√©n√©rer le CSV\n      let csv = headers.join(',') + '\\n';\n      documents.forEach(doc => {\n        const row = headers.map(header => {\n          const value = doc[header];\n\n          // √âchapper les valeurs contenant des virgules ou des sauts de ligne\n          if (value === undefined || value === null) {\n            return '';\n          } else if (typeof value === 'string' && (value.includes(',') || value.includes('\\n') || value.includes('\"'))) {\n            return `\"${value.replace(/\"/g, '\"\"')}\"`;\n          } else {\n            return value;\n          }\n        });\n        csv += row.join(',') + '\\n';\n      });\n      console.log(`‚úÖ Exportation de ${documents.length} documents de la collection ${collectionName} termin√©e.`);\n      return csv;\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de l'exportation de la collection ${collectionName}:`, error);\n      throw error;\n    }\n  }\n\n  /**\n   * Exporte les donn√©es d'une collection Firebase au format JSON\n   * @param collectionName Nom de la collection √† exporter\n   * @returns Objet JSON contenant les donn√©es\n   */\n  async exportCollectionToJSON(collectionName) {\n    try {\n      console.log(`üîÑ Exportation de la collection ${collectionName} au format JSON...`);\n\n      // R√©cup√©rer les donn√©es de la collection\n      const querySnapshot = await getDocs(collection(db, collectionName));\n      if (querySnapshot.empty) {\n        console.log(`‚ö†Ô∏è La collection ${collectionName} est vide.`);\n        return [];\n      }\n\n      // Extraire les donn√©es\n      const documents = querySnapshot.docs.map(doc => {\n        const data = doc.data();\n\n        // Convertir les Timestamp en cha√Ænes de caract√®res\n        const formattedData = {};\n        Object.entries(data).forEach(([key, value]) => {\n          if (value instanceof Timestamp) {\n            formattedData[key] = value.toDate().toISOString();\n          } else {\n            formattedData[key] = value;\n          }\n        });\n\n        // Ajouter l'ID du document\n        formattedData.id = doc.id;\n        return formattedData;\n      });\n      console.log(`‚úÖ Exportation de ${documents.length} documents de la collection ${collectionName} termin√©e.`);\n      return documents;\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de l'exportation de la collection ${collectionName}:`, error);\n      throw error;\n    }\n  }\n\n  /**\n   * T√©l√©charge un fichier CSV contenant les donn√©es d'une collection\n   * @param collectionName Nom de la collection √† exporter\n   */\n  async downloadCollectionAsCSV(collectionName) {\n    try {\n      const csv = await this.exportCollectionToCSV(collectionName);\n      if (!csv) {\n        console.log(`‚ö†Ô∏è Aucune donn√©e √† exporter pour la collection ${collectionName}.`);\n        return;\n      }\n\n      // Cr√©er un blob et un lien de t√©l√©chargement\n      const blob = new Blob([csv], {\n        type: 'text/csv;charset=utf-8;'\n      });\n      const url = URL.createObjectURL(blob);\n      const link = document.createElement('a');\n      link.setAttribute('href', url);\n      link.setAttribute('download', `${collectionName}_${new Date().toISOString().split('T')[0]}.csv`);\n      link.style.visibility = 'hidden';\n      document.body.appendChild(link);\n      link.click();\n      document.body.removeChild(link);\n    } catch (error) {\n      console.error(`‚ùå Erreur lors du t√©l√©chargement de la collection ${collectionName}:`, error);\n      throw error;\n    }\n  }\n\n  /**\n   * T√©l√©charge un fichier JSON contenant les donn√©es d'une collection\n   * @param collectionName Nom de la collection √† exporter\n   */\n  async downloadCollectionAsJSON(collectionName) {\n    try {\n      const data = await this.exportCollectionToJSON(collectionName);\n      if (!data || data.length === 0) {\n        console.log(`‚ö†Ô∏è Aucune donn√©e √† exporter pour la collection ${collectionName}.`);\n        return;\n      }\n\n      // Cr√©er un blob et un lien de t√©l√©chargement\n      const blob = new Blob([JSON.stringify(data, null, 2)], {\n        type: 'application/json'\n      });\n      const url = URL.createObjectURL(blob);\n      const link = document.createElement('a');\n      link.setAttribute('href', url);\n      link.setAttribute('download', `${collectionName}_${new Date().toISOString().split('T')[0]}.json`);\n      link.style.visibility = 'hidden';\n      document.body.appendChild(link);\n      link.click();\n      document.body.removeChild(link);\n    } catch (error) {\n      console.error(`‚ùå Erreur lors du t√©l√©chargement de la collection ${collectionName}:`, error);\n      throw error;\n    }\n  }\n\n  /**\n   * T√©l√©charge toutes les collections au format CSV\n   */\n  async downloadAllCollectionsAsCSV() {\n    try {\n      console.log('üîÑ Exportation de toutes les collections au format CSV...');\n      for (const collectionName of this.collections) {\n        await this.downloadCollectionAsCSV(collectionName);\n      }\n      console.log('‚úÖ Exportation de toutes les collections termin√©e.');\n    } catch (error) {\n      console.error('‚ùå Erreur lors de l\\'exportation de toutes les collections:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * T√©l√©charge toutes les collections au format JSON\n   */\n  async downloadAllCollectionsAsJSON() {\n    try {\n      console.log('üîÑ Exportation de toutes les collections au format JSON...');\n      for (const collectionName of this.collections) {\n        await this.downloadCollectionAsJSON(collectionName);\n      }\n      console.log('‚úÖ Exportation de toutes les collections termin√©e.');\n    } catch (error) {\n      console.error('‚ùå Erreur lors de l\\'exportation de toutes les collections:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * G√©n√®re un fichier ZIP contenant toutes les collections au format JSON\n   */\n  async generateCompleteBackup() {\n    try {\n      console.log(\"üîÑ G√©n√©ration d'une sauvegarde compl√®te...\");\n      const zip = new JSZip();\n\n      // Exporter chaque collection\n      for (const collectionName of this.collections) {\n        const data = await this.exportCollectionToJSON(collectionName);\n        if (data && data.length > 0) {\n          zip.file(`${collectionName}.json`, JSON.stringify(data, null, 2));\n        }\n      }\n\n      // G√©n√©rer le fichier ZIP\n      const content = await zip.generateAsync({\n        type: 'blob'\n      });\n\n      // T√©l√©charger le fichier\n      const url = URL.createObjectURL(content);\n      const link = document.createElement('a');\n      link.setAttribute('href', url);\n      link.setAttribute('download', `firebase_backup_${new Date().toISOString().split('T')[0]}.zip`);\n      link.style.visibility = 'hidden';\n      document.body.appendChild(link);\n      link.click();\n      document.body.removeChild(link);\n      console.log('‚úÖ G√©n√©ration de la sauvegarde compl√®te termin√©e.');\n    } catch (error) {\n      console.error('‚ùå Erreur lors de la g√©n√©ration de la sauvegarde compl√®te:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Importe des donn√©es au format CSV vers une collection Firebase\n   * @param collectionName Nom de la collection cible\n   * @param csvContent Contenu du fichier CSV\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  async importCSVToCollection(collectionName, csvContent, options = {}) {\n    try {\n      console.log(`üîÑ Importation des donn√©es CSV vers la collection ${collectionName}...`);\n\n      // Options par d√©faut\n      const {\n        clearCollection = false,\n        updateExisting = true,\n        idField = 'id'\n      } = options;\n\n      // V√©rifier si la collection existe\n      if (!this.collections.includes(collectionName)) {\n        throw new Error(`La collection ${collectionName} n'est pas valide.`);\n      }\n\n      // Analyser le CSV\n      const lines = csvContent.split('\\n');\n      if (lines.length < 2) {\n        throw new Error('Le fichier CSV est vide ou ne contient que des en-t√™tes.');\n      }\n\n      // Extraire les en-t√™tes\n      const headers = this.parseCSVLine(lines[0]);\n\n      // Pr√©parer les donn√©es\n      const documents = [];\n      for (let i = 1; i < lines.length; i++) {\n        const line = lines[i].trim();\n        if (!line) continue;\n        const values = this.parseCSVLine(line);\n        if (values.length !== headers.length) {\n          console.warn(`‚ö†Ô∏è Ligne ${i + 1} ignor√©e: nombre de valeurs incorrect`);\n          continue;\n        }\n        const doc = {};\n        for (let j = 0; j < headers.length; j++) {\n          const header = headers[j];\n          let value = values[j];\n\n          // Convertir les valeurs en types appropri√©s\n          if (value === 'true') value = true;else if (value === 'false') value = false;else if (!isNaN(Number(value)) && value !== '') value = Number(value);else if (typeof value === 'string' && (value.match(/^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}/) || value.match(/^\\d{4}-\\d{2}-\\d{2}/))) {\n            // Convertir les dates ISO en Timestamp\n            try {\n              value = Timestamp.fromDate(new Date(value));\n            } catch (e) {\n              console.warn(`‚ö†Ô∏è Impossible de convertir la date: ${value}`);\n            }\n          }\n          doc[header] = value;\n        }\n        documents.push(doc);\n      }\n\n      // Vider la collection si demand√©\n      if (clearCollection) {\n        await this.clearCollection(collectionName);\n      }\n\n      // Importer les documents\n      const totalDocuments = documents.length;\n      let processedCount = 0;\n      let importedCount = 0;\n      while (processedCount < totalDocuments) {\n        // Cr√©er un nouveau lot pour chaque groupe de 500 documents\n        const batch = writeBatch(db);\n        const batchSize = Math.min(500, totalDocuments - processedCount);\n\n        // Ajouter les documents au lot\n        for (let i = 0; i < batchSize; i++) {\n          const document = documents[processedCount + i];\n          const docId = document[idField];\n          if (docId && updateExisting) {\n            // Mettre √† jour ou cr√©er le document avec l'ID sp√©cifi√©\n            const docRef = doc(db, collectionName, docId);\n            batch.set(docRef, document);\n          } else {\n            // Cr√©er un nouveau document avec un ID g√©n√©r√©\n            const collectionRef = collection(db, collectionName);\n            const newDocRef = doc(collectionRef);\n            batch.set(newDocRef, document);\n          }\n          importedCount++;\n        }\n\n        // Ex√©cuter le lot\n        await batch.commit();\n        processedCount += batchSize;\n        console.log(`‚úÖ Lot de ${batchSize} documents import√©s (${processedCount}/${totalDocuments})`);\n      }\n      console.log(`‚úÖ Importation termin√©e: ${importedCount} documents import√©s dans la collection ${collectionName}`);\n      return importedCount;\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de l'importation des donn√©es CSV:`, error);\n      throw error;\n    }\n  }\n\n  /**\n   * Importe des donn√©es au format JSON vers une collection Firebase\n   * @param collectionName Nom de la collection cible\n   * @param jsonData Donn√©es JSON √† importer\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  async importJSONToCollection(collectionName, jsonData, options = {}) {\n    try {\n      console.log(`üîÑ Importation des donn√©es JSON vers la collection ${collectionName}...`);\n\n      // Options par d√©faut\n      const {\n        clearCollection = false,\n        updateExisting = true,\n        idField = 'id'\n      } = options;\n\n      // V√©rifier si la collection existe\n      if (!this.collections.includes(collectionName)) {\n        throw new Error(`La collection ${collectionName} n'est pas valide.`);\n      }\n\n      // V√©rifier que les donn√©es sont un tableau\n      if (!Array.isArray(jsonData)) {\n        throw new Error('Les donn√©es JSON doivent √™tre un tableau d\\'objets.');\n      }\n\n      // Convertir les dates en Timestamp\n      const documents = jsonData.map(doc => {\n        const processedDoc = {};\n        Object.entries(doc).forEach(([key, value]) => {\n          if (typeof value === 'string' && (value.match(/^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}/) || value.match(/^\\d{4}-\\d{2}-\\d{2}/))) {\n            // Convertir les dates ISO en Timestamp\n            try {\n              processedDoc[key] = Timestamp.fromDate(new Date(value));\n            } catch (e) {\n              console.warn(`‚ö†Ô∏è Impossible de convertir la date: ${value}`);\n              processedDoc[key] = value;\n            }\n          } else {\n            processedDoc[key] = value;\n          }\n        });\n        return processedDoc;\n      });\n\n      // Vider la collection si demand√©\n      if (clearCollection) {\n        await this.clearCollection(collectionName);\n      }\n\n      // Importer les documents\n      const totalDocuments = documents.length;\n      let processedCount = 0;\n      let importedCount = 0;\n      while (processedCount < totalDocuments) {\n        // Cr√©er un nouveau lot pour chaque groupe de 500 documents\n        const batch = writeBatch(db);\n        const batchSize = Math.min(500, totalDocuments - processedCount);\n\n        // Ajouter les documents au lot\n        for (let i = 0; i < batchSize; i++) {\n          const document = documents[processedCount + i];\n          const docId = document[idField];\n          if (docId && updateExisting) {\n            // Mettre √† jour ou cr√©er le document avec l'ID sp√©cifi√©\n            const docRef = doc(db, collectionName, docId);\n            batch.set(docRef, document);\n          } else {\n            // Cr√©er un nouveau document avec un ID g√©n√©r√©\n            const collectionRef = collection(db, collectionName);\n            const newDocRef = doc(collectionRef);\n            batch.set(newDocRef, document);\n          }\n          importedCount++;\n        }\n\n        // Ex√©cuter le lot\n        await batch.commit();\n        processedCount += batchSize;\n        console.log(`‚úÖ Lot de ${batchSize} documents import√©s (${processedCount}/${totalDocuments})`);\n      }\n      console.log(`‚úÖ Importation termin√©e: ${importedCount} documents import√©s dans la collection ${collectionName}`);\n      return importedCount;\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de l'importation des donn√©es JSON:`, error);\n      throw error;\n    }\n  }\n\n  /**\n   * Importe des donn√©es depuis un fichier ZIP contenant plusieurs collections\n   * @param zipContent Contenu du fichier ZIP\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s par collection\n   */\n  async importFromZip(zipContent, options = {}) {\n    try {\n      console.log('üîÑ Importation des donn√©es depuis le fichier ZIP...');\n      const zip = new JSZip();\n      await zip.loadAsync(zipContent);\n      const results = {};\n\n      // Parcourir les fichiers du ZIP\n      for (const fileName in zip.files) {\n        var _fileName$split$pop;\n        if (zip.files[fileName].dir) continue;\n        const fileExt = (_fileName$split$pop = fileName.split('.').pop()) === null || _fileName$split$pop === void 0 ? void 0 : _fileName$split$pop.toLowerCase();\n        const collectionName = fileName.split('.')[0];\n        if (!this.collections.includes(collectionName)) {\n          console.warn(`‚ö†Ô∏è Collection inconnue ignor√©e: ${collectionName}`);\n          continue;\n        }\n        const fileContent = await zip.files[fileName].async('string');\n        if (fileExt === 'json') {\n          try {\n            const jsonData = JSON.parse(fileContent);\n            const count = await this.importJSONToCollection(collectionName, jsonData, options);\n            results[collectionName] = count;\n          } catch (e) {\n            console.error(`‚ùå Erreur lors de l'importation du fichier JSON ${fileName}:`, e);\n          }\n        } else if (fileExt === 'csv') {\n          try {\n            const count = await this.importCSVToCollection(collectionName, fileContent, options);\n            results[collectionName] = count;\n          } catch (e) {\n            console.error(`‚ùå Erreur lors de l'importation du fichier CSV ${fileName}:`, e);\n          }\n        } else {\n          console.warn(`‚ö†Ô∏è Type de fichier non pris en charge: ${fileExt}`);\n        }\n      }\n      console.log('‚úÖ Importation depuis ZIP termin√©e:', results);\n      return results;\n    } catch (error) {\n      console.error('‚ùå Erreur lors de l\\'importation depuis le fichier ZIP:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Vide une collection\n   * @param collectionName Nom de la collection √† vider\n   */\n  async clearCollection(collectionName) {\n    try {\n      console.log(`üîÑ Suppression des documents existants dans la collection ${collectionName}...`);\n      const collectionRef = collection(db, collectionName);\n      const snapshot = await getDocs(collectionRef);\n      if (snapshot.empty) {\n        console.log(`‚ÑπÔ∏è La collection ${collectionName} est d√©j√† vide.`);\n        return;\n      }\n\n      // Traiter les documents par lots de 500 (limite Firestore)\n      const documents = snapshot.docs;\n      const totalDocuments = documents.length;\n      let processedCount = 0;\n      while (processedCount < totalDocuments) {\n        // Cr√©er un nouveau lot pour chaque groupe de 500 documents\n        const batch = writeBatch(db);\n        const batchSize = Math.min(500, totalDocuments - processedCount);\n\n        // Ajouter les suppressions au lot\n        for (let i = 0; i < batchSize; i++) {\n          const document = documents[processedCount + i];\n          batch.delete(doc(db, collectionName, document.id));\n        }\n\n        // Ex√©cuter le lot\n        await batch.commit();\n        processedCount += batchSize;\n        console.log(`‚úÖ Lot de ${batchSize} documents supprim√©s (${processedCount}/${totalDocuments})`);\n      }\n      console.log(`‚úÖ Collection ${collectionName} vid√©e avec succ√®s.`);\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de la suppression des documents:`, error);\n      throw error;\n    }\n  }\n\n  /**\n   * Analyse une ligne CSV en tenant compte des guillemets\n   * @param line Ligne CSV √† analyser\n   * @returns Tableau des valeurs\n   */\n  parseCSVLine(line) {\n    // Si la ligne est vide, retourner un tableau vide\n    if (!line || line.trim() === '') {\n      return [];\n    }\n\n    // Supprimer TOUS les caract√®res \"√´\" de la ligne avant tout traitement\n    let cleanedLine = line.replace(/√´/g, '');\n    cleanedLine = cleanedLine.replace(/√ã/g, '');\n\n    // D√©tecter le s√©parateur le plus probable pour cette ligne\n    let separator = ';'; // On d√©finit le point-virgule comme s√©parateur par d√©faut\n    const tabCount = (cleanedLine.match(/\\t/g) || []).length;\n    const semicolonCount = (cleanedLine.match(/;/g) || []).length;\n    const commaCount = (cleanedLine.match(/,/g) || []).length;\n    if (tabCount > 0 && tabCount >= semicolonCount && tabCount >= commaCount) {\n      separator = '\\t';\n    } else if (commaCount > semicolonCount) {\n      separator = ',';\n    }\n\n    // Diviser la ligne en utilisant le s√©parateur d√©tect√©\n    const values = cleanedLine.split(separator).map(value => {\n      // Nettoyer chaque valeur\n      let cleanValue = value.trim();\n\n      // Supprimer les guillemets en d√©but et fin si pr√©sents\n      if (cleanValue.startsWith('\"') && cleanValue.endsWith('\"')) {\n        cleanValue = cleanValue.slice(1, -1);\n      }\n\n      // Remplacer les doubles guillemets par des simples\n      cleanValue = cleanValue.replace(/\"\"/g, '\"');\n      return cleanValue;\n    });\n\n    // Afficher des informations de d√©bogage\n    console.log(`Ligne nettoy√©e: \"${cleanedLine}\"`);\n    console.log(`Valeurs extraites: ${JSON.stringify(values)}`);\n    return values;\n  }\n\n  /**\n   * Normalise l'encodage des caract√®res sp√©ciaux\n   * @param text Texte √† normaliser\n   * @returns Texte normalis√©\n   */\n  normalizeEncoding(text) {\n    if (!text) return '';\n\n    // Supprimer tous les caract√®res \"√´\" et \"√ã\"\n    let result = text.replace(/[√´√ã]/g, '');\n\n    // Remplacer les caract√®res mal encod√©s par leurs √©quivalents corrects\n    const replacements = {\n      'Ple': 'P√¥le',\n      'Pole': 'P√¥le',\n      'POLE': 'P√¥le',\n      'Tourne': 'Tourn√©e',\n      'TOURNEE': 'Tourn√©e',\n      'Tournee': 'Tourn√©e',\n      'Complment': 'Compl√©ment',\n      'Complement': 'Compl√©ment',\n      'Tlphone': 'T√©l√©phone',\n      'Telephone': 'T√©l√©phone',\n      'Coordonnes': 'Coordonn√©es',\n      'Coordonnees': 'Coordonn√©es'\n    };\n\n    // Appliquer les remplacements\n    Object.entries(replacements).forEach(([pattern, replacement]) => {\n      result = result.replace(new RegExp(pattern, 'g'), replacement);\n    });\n    return result;\n  }\n\n  /**\n   * Normalise l'encodage d'un fichier CSV/TXT entier\n   * @param content Contenu du fichier\n   * @returns Contenu normalis√©\n   */\n  normalizeFileEncoding(content) {\n    if (!content) return '';\n    console.log('Normalisation de l\\'encodage du fichier...');\n\n    // Supprimer tous les caract√®res \"√´\"\n    content = content.replace(/√´/g, '');\n\n    // D√©tecter et corriger les probl√®mes d'encodage courants\n    const lines = content.split(/\\r?\\n/);\n    const normalizedLines = lines.map(line => {\n      // Normaliser l'encodage de chaque ligne\n      return this.normalizeEncoding(line);\n    });\n    return normalizedLines.join('\\n');\n  }\n\n  /**\n   * D√©tecte et corrige l'encodage d'un fichier CSV\n   * @param content Contenu du fichier\n   * @returns Contenu avec encodage corrig√©\n   */\n  detectAndFixEncoding(content) {\n    if (!content) return '';\n    console.log('D√©tection et correction de l\\'encodage...');\n\n    // V√©rifier si le contenu commence par un BOM UTF-8\n    if (content.charCodeAt(0) === 0xFEFF) {\n      console.log('BOM UTF-8 d√©tect√©, suppression...');\n      content = content.slice(1);\n    }\n\n    // Supprimer tous les caract√®res \"√´\"\n    if (content.includes('√´')) {\n      console.log('Caract√®res \"√´\" d√©tect√©s, suppression...');\n      content = content.replace(/√´/g, '');\n    }\n\n    // D√©tecter les s√©quences typiques d'un encodage UTF-8 mal interpr√©t√©\n    const hasUtf8MisinterpretedSequences = content.includes('√É¬©') ||\n    // √©\n    content.includes('√É¬®') ||\n    // √®\n    content.includes('√É¬™') ||\n    // √™\n    content.includes('√É ') ||\n    // √†\n    content.includes('√É¬ß') ||\n    // √ß\n    content.includes('√É¬¥') ||\n    // √¥\n    content.includes('√É¬Æ') ||\n    // √Æ\n    content.includes('√É¬Ø') ||\n    // √Ø\n    content.includes('√É¬º') ||\n    // √º\n    content.includes('√É¬π') ||\n    // √π\n    content.includes('√É¬ª') ||\n    // √ª\n    content.includes('√É¬¢') ||\n    // √¢\n    content.includes('√É¬´') ||\n    // √´\n    content.includes('√É‚Ä∞') ||\n    // √â\n    content.includes('√É\"'); // √î\n\n    if (hasUtf8MisinterpretedSequences) {\n      console.log('S√©quences UTF-8 mal interpr√©t√©es d√©tect√©es, correction...');\n\n      // Corriger les s√©quences UTF-8 mal interpr√©t√©es\n      content = content.replace(/√É¬©/g, '√©').replace(/√É¬®/g, '√®').replace(/√É¬™/g, '√™').replace(/√É /g, '√†').replace(/√É¬ß/g, '√ß').replace(/√É¬¥/g, '√¥').replace(/√É¬Æ/g, '√Æ').replace(/√É¬Ø/g, '√Ø').replace(/√É¬º/g, '√º').replace(/√É¬π/g, '√π').replace(/√É¬ª/g, '√ª').replace(/√É¬¢/g, '√¢').replace(/√É¬´/g, '√´').replace(/√É‚Ä∞/g, '√â').replace(/√É\"/g, '√î').replace(/P√É¬¥le/g, 'P√¥le').replace(/Tourn√É¬©e/g, 'Tourn√©e').replace(/Compl√É¬©ment d\\'adresse/g, 'Compl√©ment d\\'adresse').replace(/T√É¬©l√É¬©phone/g, 'T√©l√©phone').replace(/Coordonn√É¬©es/g, 'Coordonn√©es');\n    }\n\n    // D√©tecter les caract√®res mal encod√©s sp√©cifiques\n    const hasMissingAccents = content.includes('Ple') || content.includes('Tourne') || content.includes('Complment');\n    if (hasMissingAccents) {\n      console.log('Caract√®res accentu√©s manquants d√©tect√©s, correction...');\n\n      // Corriger les caract√®res mal encod√©s\n      content = content.replace(/Ple/g, 'P√¥le').replace(/Tourne/g, 'Tourn√©e').replace(/Complment d\\'adresse/g, 'Compl√©ment d\\'adresse').replace(/Complment/g, 'Compl√©ment').replace(/Tlphone/g, 'T√©l√©phone').replace(/Coordonnes/g, 'Coordonn√©es');\n    }\n    return content;\n  }\n\n  /**\n   * Importe des sites depuis un fichier TXT\n   * @param txtContent Contenu du fichier TXT\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  async importSitesFromTXT(txtContent, options = {}) {\n    try {\n      console.log('Traitement sp√©cifique pour fichier TXT...');\n\n      // D√©tecter et corriger l'encodage du fichier\n      let normalizedContent = this.detectAndFixEncoding(txtContent);\n\n      // Normaliser l'encodage du contenu du fichier\n      normalizedContent = this.normalizeFileEncoding(normalizedContent);\n\n      // Diviser le contenu en lignes\n      const lines = normalizedContent.split('\\n').map(line => line.trim()).filter(line => line !== '');\n      if (lines.length === 0) {\n        throw new Error('Le fichier est vide.');\n      }\n      const firstLine = lines[0];\n      if (!firstLine) {\n        throw new Error('La premi√®re ligne du fichier est vide.');\n      }\n      console.log('Premi√®re ligne du fichier TXT:', firstLine);\n\n      // D√©tecter le s√©parateur en comptant les occurrences\n      const tabCount = (firstLine.match(/\\t/g) || []).length;\n      const semicolonCount = (firstLine.match(/;/g) || []).length;\n      const commaCount = (firstLine.match(/,/g) || []).length;\n      console.log(`S√©parateurs d√©tect√©s - Tabulations: ${tabCount}, Points-virgules: ${semicolonCount}, Virgules: ${commaCount}`);\n\n      // Afficher un √©chantillon des premi√®res lignes pour le d√©bogage\n      console.log('√âchantillon des 3 premi√®res lignes TXT:');\n      for (let i = 0; i < Math.min(3, lines.length); i++) {\n        console.log(`Ligne ${i}: ${lines[i]}`);\n      }\n\n      // Pour les fichiers TXT, on privil√©gie la tabulation si elle est pr√©sente\n      let separator = '\\t';\n      if (tabCount > 0) {\n        separator = '\\t';\n        console.log('S√©parateur d√©tect√© pour TXT: tabulation');\n      } else if (semicolonCount > 0 && semicolonCount >= commaCount) {\n        separator = ';';\n        console.log('S√©parateur d√©tect√© pour TXT: point-virgule');\n      } else if (commaCount > 0) {\n        separator = ',';\n        console.log('S√©parateur d√©tect√© pour TXT: virgule');\n      } else {\n        console.log('Aucun s√©parateur standard d√©tect√© dans le fichier TXT, utilisation de la tabulation par d√©faut');\n      }\n\n      // Convertir le TXT en format CSV normalis√©\n      const normalizedCSV = lines.map(line => {\n        if (!line) return '';\n\n        // Remplacer le s√©parateur d√©tect√© par des virgules\n        if (separator !== ',') {\n          // G√©rer correctement les champs entre guillemets avec le s√©parateur √† l'int√©rieur\n          const values = this.parseCSVLine(line);\n          return values.map(value => {\n            // Entourer de guillemets si la valeur contient une virgule\n            if (value.includes(',')) {\n              return `\"${value.replace(/\"/g, '\"\"')}\"`;\n            }\n            return value;\n          }).join(',');\n        }\n        return line;\n      }).join('\\n');\n\n      // V√©rifier si la conversion a r√©ussi\n      const normalizedLines = normalizedCSV.split('\\n');\n      if (normalizedLines.length < 2) {\n        throw new Error('La conversion du fichier TXT a √©chou√©.');\n      }\n\n      // Extraire les en-t√™tes\n      const headers = this.parseCSVLine(normalizedLines[0]);\n\n      // V√©rifier que le fichier contient suffisamment de colonnes\n      if (headers.length < 3) {\n        throw new Error(`Le fichier ne contient que ${headers.length} colonnes. V√©rifiez le format du fichier et assurez-vous qu'il utilise des tabulations, des points-virgules ou des virgules comme s√©parateurs.`);\n      }\n      console.log('En-t√™tes d√©tect√©s dans le fichier TXT:', headers);\n\n      // Traiter les lignes avec la fonction commune\n      return this.processImportLines(headers, normalizedLines, options);\n    } catch (error) {\n      console.error('‚ùå Erreur lors de l\\'importation des sites depuis TXT:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Affiche des informations de d√©bogage sur un fichier CSV/TXT\n   * @param content Contenu du fichier\n   * @param fileName Nom du fichier\n   */\n  debugFileInfo(content, fileName = 'inconnu') {\n    console.group(`üìä Informations de d√©bogage pour le fichier: ${fileName}`);\n    try {\n      // Informations g√©n√©rales\n      console.log(`Taille du contenu: ${content.length} caract√®res`);\n      console.log(`Type de fichier: ${fileName.endsWith('.txt') ? 'TXT' : 'CSV'}`);\n\n      // V√©rifier la pr√©sence du BOM UTF-8\n      const hasBOM = content.charCodeAt(0) === 0xFEFF;\n      console.log(`BOM UTF-8 d√©tect√©: ${hasBOM ? 'Oui' : 'Non'}`);\n\n      // Analyser les lignes\n      const lines = content.split('\\n');\n      console.log(`Nombre de lignes: ${lines.length}`);\n      if (lines.length > 0) {\n        // Analyser la premi√®re ligne (en-t√™tes)\n        const firstLine = lines[0].trim();\n        console.log(`Premi√®re ligne (${firstLine.length} caract√®res): ${firstLine.substring(0, 100)}${firstLine.length > 100 ? '...' : ''}`);\n\n        // D√©tecter les s√©parateurs\n        const tabCount = (firstLine.match(/\\t/g) || []).length;\n        const semicolonCount = (firstLine.match(/;/g) || []).length;\n        const commaCount = (firstLine.match(/,/g) || []).length;\n        console.log(`S√©parateurs d√©tect√©s - Tabulations: ${tabCount}, Points-virgules: ${semicolonCount}, Virgules: ${commaCount}`);\n\n        // D√©tecter le s√©parateur le plus probable\n        let probableSeparator = ',';\n        if (tabCount > 0 && tabCount >= semicolonCount && tabCount >= commaCount) {\n          probableSeparator = '\\t';\n        } else if (semicolonCount > 0 && semicolonCount >= commaCount) {\n          probableSeparator = ';';\n        }\n        console.log(`S√©parateur le plus probable: ${probableSeparator === '\\t' ? 'tabulation' : probableSeparator}`);\n\n        // Estimer le nombre de colonnes\n        const estimatedColumns = probableSeparator === '\\t' ? tabCount + 1 : probableSeparator === ';' ? semicolonCount + 1 : commaCount + 1;\n        console.log(`Nombre estim√© de colonnes: ${estimatedColumns}`);\n\n        // V√©rifier la coh√©rence des lignes\n        if (lines.length > 1) {\n          const secondLine = lines[1].trim();\n          const secondLineTabCount = (secondLine.match(/\\t/g) || []).length;\n          const secondLineSemicolonCount = (secondLine.match(/;/g) || []).length;\n          const secondLineCommaCount = (secondLine.match(/,/g) || []).length;\n          const secondLineColumns = probableSeparator === '\\t' ? secondLineTabCount + 1 : probableSeparator === ';' ? secondLineSemicolonCount + 1 : secondLineCommaCount + 1;\n          console.log(`Nombre de colonnes dans la deuxi√®me ligne: ${secondLineColumns}`);\n          console.log(`Coh√©rence des colonnes: ${estimatedColumns === secondLineColumns ? 'OK' : 'PROBL√àME'}`);\n        }\n\n        // V√©rifier l'encodage des caract√®res sp√©ciaux\n        const specialChars = ['√©', '√®', '√™', '√†', '√ß', '√¥', '√Æ', '√Ø', '√º', '√π', '√ª', '√¢', '√´'];\n        const specialCharsFound = specialChars.filter(char => content.includes(char));\n        console.log(`Caract√®res sp√©ciaux correctement encod√©s: ${specialCharsFound.length > 0 ? specialCharsFound.join(', ') : 'Aucun'}`);\n\n        // V√©rifier les s√©quences UTF-8 mal interpr√©t√©es\n        const badSequences = ['√É¬©', '√É¬®', '√É¬™', '√É ', '√É¬ß', '√É¬¥', '√É¬Æ', '√É¬Ø', '√É¬º', '√É¬π', '√É¬ª', '√É¬¢', '√É¬´'];\n        const badSequencesFound = badSequences.filter(seq => content.includes(seq));\n        console.log(`S√©quences UTF-8 mal interpr√©t√©es: ${badSequencesFound.length > 0 ? badSequencesFound.join(', ') : 'Aucune'}`);\n\n        // V√©rifier les caract√®res mal encod√©s sp√©cifiques\n        const specificBadChars = ['Ple', 'Tourne', 'Complment'];\n        const specificBadCharsFound = specificBadChars.filter(char => content.includes(char));\n        console.log(`Caract√®res mal encod√©s sp√©cifiques: ${specificBadCharsFound.length > 0 ? specificBadCharsFound.join(', ') : 'Aucun'}`);\n      }\n    } catch (error) {\n      console.error('Erreur lors de l\\'analyse du fichier:', error);\n    } finally {\n      console.groupEnd();\n    }\n  }\n\n  /**\n   * Importe des sites depuis un fichier CSV\n   * @param csvContent Contenu du fichier CSV\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  async importSitesFromCSV(csvContent, options = {}) {\n    try {\n      const {\n        clearCollection = false,\n        updateExisting = true,\n        idField = 'id',\n        isTxtFile = false,\n        fileName = isTxtFile ? 'fichier.txt' : 'fichier.csv'\n      } = options;\n      console.log(`D√©but de l'importation des sites depuis ${isTxtFile ? 'TXT' : 'CSV'}...`);\n\n      // Afficher des informations de d√©bogage sur le fichier\n      this.debugFileInfo(csvContent, fileName);\n\n      // Traitement sp√©cifique pour les fichiers TXT\n      if (isTxtFile) {\n        return this.importSitesFromTXT(csvContent, options);\n      }\n\n      // Supprimer tous les caract√®res \"√´\" du contenu\n      let cleanedContent = csvContent.replace(/√´/g, '');\n      console.log('Contenu apr√®s nettoyage des caract√®res √´ (50 premiers caract√®res):', cleanedContent.substring(0, 50));\n\n      // D√©tecter et corriger l'encodage du fichier\n      let normalizedContent = this.detectAndFixEncoding(cleanedContent);\n\n      // V√©rifier si le contenu est encod√© en UTF-8 avec BOM\n      if (csvContent.charCodeAt(0) === 0xFEFF) {\n        console.log('D√©tection du BOM UTF-8, suppression...');\n        normalizedContent = csvContent.slice(1);\n      }\n\n      // Normaliser l'encodage du contenu du fichier\n      normalizedContent = this.normalizeFileEncoding(normalizedContent);\n\n      // Diviser le contenu en lignes\n      const lines = normalizedContent.split(/\\r?\\n/).map(line => line.trim()).filter(line => line !== '');\n      if (lines.length === 0) {\n        throw new Error('Le fichier est vide.');\n      }\n      const firstLine = lines[0];\n      if (!firstLine) {\n        throw new Error('La premi√®re ligne du fichier est vide.');\n      }\n      console.log('Premi√®re ligne du fichier:', firstLine);\n\n      // D√©tecter le s√©parateur en comptant les occurrences\n      const tabCount = (firstLine.match(/\\t/g) || []).length;\n      const semicolonCount = (firstLine.match(/;/g) || []).length;\n      const commaCount = (firstLine.match(/,/g) || []).length;\n\n      // Initialiser la variable separator\n      let separator = ',';\n\n      // D√©tecter si c'est le format sp√©cifique de l'utilisateur\n      const isUserSpecificFormat = firstLine.includes('P√¥le;Bassin;MI;Tourn√©e') || firstLine.includes('P√¥le;Bassin;MI;Tourn√©e;PT de rattachement') || firstLine.includes('Pole;Bassin;MI;Tournee') || firstLine.includes('ID;Pole;Bassin;MI;Tournee');\n      if (isUserSpecificFormat) {\n        console.log('Format sp√©cifique d√©tect√©: format utilisateur avec s√©parateur point-virgule');\n        separator = ';';\n      }\n      console.log(`S√©parateurs d√©tect√©s - Tabulations: ${tabCount}, Points-virgules: ${semicolonCount}, Virgules: ${commaCount}`);\n      console.log(`Format d√©tect√©: ${isUserSpecificFormat ? 'Format utilisateur sp√©cifique' : 'Format standard'}`);\n\n      // Pour les fichiers TXT, on privil√©gie la tabulation si elle est pr√©sente\n      if (isTxtFile) {\n        if (tabCount > 0) {\n          separator = '\\t';\n          console.log('S√©parateur d√©tect√© pour TXT: tabulation');\n        } else if (semicolonCount > 0 && semicolonCount >= commaCount) {\n          separator = ';';\n          console.log('S√©parateur d√©tect√© pour TXT: point-virgule');\n        } else if (commaCount > 0) {\n          separator = ',';\n          console.log('S√©parateur d√©tect√© pour TXT: virgule');\n        } else {\n          console.log('Aucun s√©parateur standard d√©tect√© dans le fichier TXT, utilisation de la tabulation par d√©faut');\n        }\n      } else {\n        // Pour les fichiers CSV, logique existante\n        if (tabCount > 0 && tabCount >= semicolonCount && tabCount >= commaCount) {\n          separator = '\\t';\n          console.log('S√©parateur d√©tect√© pour CSV: tabulation');\n        } else if (semicolonCount > 0 && semicolonCount >= commaCount) {\n          separator = ';';\n          console.log('S√©parateur d√©tect√© pour CSV: point-virgule');\n        } else {\n          console.log('S√©parateur d√©tect√© pour CSV: virgule');\n        }\n      }\n\n      // Afficher un √©chantillon des premi√®res lignes pour le d√©bogage\n      console.log('√âchantillon des 3 premi√®res lignes:');\n      for (let i = 0; i < Math.min(3, lines.length); i++) {\n        console.log(`Ligne ${i}: ${lines[i]}`);\n      }\n\n      // Convertir le CSV en utilisant le s√©parateur d√©tect√©\n      let normalizedCSV = '';\n      if (separator !== ',') {\n        normalizedCSV = lines.map(line => {\n          if (!line) return '';\n\n          // G√©rer correctement les champs entre guillemets avec le s√©parateur √† l'int√©rieur\n          const result = [];\n          let current = '';\n          let inQuotes = false;\n          for (let i = 0; i < line.length; i++) {\n            const char = line[i];\n            if (char === '\"') {\n              inQuotes = !inQuotes;\n              current += char;\n            } else if (char === separator && !inQuotes) {\n              result.push(current);\n              current = '';\n            } else {\n              current += char;\n            }\n          }\n\n          // Ajouter le dernier champ\n          result.push(current);\n          return result.join(',');\n        }).join('\\n');\n      } else {\n        normalizedCSV = normalizedContent;\n      }\n\n      // V√©rifier si le fichier a √©t√© correctement normalis√©\n      const normalizedLines = normalizedCSV.split(/\\r?\\n/).filter(line => line.trim() !== '');\n      if (normalizedLines.length < 2) {\n        // Si la normalisation a √©chou√©, essayer une approche diff√©rente\n        console.warn('‚ö†Ô∏è La normalisation standard a √©chou√©, tentative avec une approche alternative...');\n\n        // Utiliser directement les lignes d'origine et laisser parseCSVLine g√©rer les s√©parateurs\n        const alternativeLines = lines.filter(line => line.trim() !== '');\n        if (alternativeLines.length < 2) {\n          throw new Error('Le fichier est vide ou ne contient que des en-t√™tes.');\n        }\n\n        // Extraire les en-t√™tes avec la fonction parseCSVLine am√©lior√©e\n        const headers = this.parseCSVLine(alternativeLines[0]);\n\n        // V√©rifier que le fichier contient suffisamment de colonnes\n        if (headers.length < 3) {\n          throw new Error(`Le fichier ne contient que ${headers.length} colonnes. V√©rifiez le format du fichier et assurez-vous qu'il utilise des virgules, des points-virgules ou des tabulations comme s√©parateurs.`);\n        }\n        console.log('En-t√™tes d√©tect√©s (approche alternative):', headers);\n\n        // Continuer avec les lignes alternatives\n        return this.processImportLines(headers, alternativeLines, options);\n      }\n\n      // Extraire les en-t√™tes\n      const headers = this.parseCSVLine(normalizedLines[0]);\n\n      // V√©rifier que le CSV contient suffisamment de colonnes\n      if (headers.length < 3) {\n        throw new Error(`Le fichier ne contient que ${headers.length} colonnes. V√©rifiez le format du fichier et assurez-vous qu'il utilise des virgules, des points-virgules ou des tabulations comme s√©parateurs.`);\n      }\n      console.log('En-t√™tes d√©tect√©s:', headers);\n      return this.processImportLines(headers, normalizedLines, options);\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de l'importation des sites depuis ${isTxtFile ? 'TXT' : 'CSV'}:`, error);\n      throw error;\n    }\n  }\n\n  /**\n   * Traite les lignes import√©es pour extraire les documents\n   * @param headers En-t√™tes des colonnes\n   * @param lines Lignes de donn√©es\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  async processImportLines(headers, lines, options = {}) {\n    try {\n      const {\n        clearCollection = false,\n        updateExisting = true,\n        idField = 'id'\n      } = options;\n\n      // R√©cup√©rer tous les sites existants pour la v√©rification des doublons\n      const sitesRef = collection(db, 'sites');\n      const existingSites = await getDocs(sitesRef);\n      const existingSitesMap = new Map();\n      const existingSitesByName = new Map();\n      const existingSitesByAddress = new Map();\n      existingSites.forEach(doc => {\n        const siteData = doc.data();\n        existingSitesMap.set(doc.id, siteData);\n\n        // Index par nom normalis√©\n        if (siteData.nom) {\n          const normalizedName = siteData.nom.toLowerCase().trim();\n          existingSitesByName.set(normalizedName, {\n            id: doc.id,\n            ...siteData\n          });\n        }\n\n        // Index par adresse compl√®te normalis√©e\n        if (siteData.adresse && siteData.ville && siteData.codePostal) {\n          const normalizedAddress = `${siteData.adresse},${siteData.ville},${siteData.codePostal}`.toLowerCase().replace(/\\s+/g, '').normalize('NFD').replace(/[\\u0300-\\u036f]/g, '');\n          existingSitesByAddress.set(normalizedAddress, {\n            id: doc.id,\n            ...siteData\n          });\n        }\n      });\n\n      // Nettoyer les en-t√™tes avant de les normaliser\n      const cleanedHeaders = headers.map(header => header.replace(/√´/g, ''));\n      const normalizedHeaders = this.normalizeHeaders(cleanedHeaders);\n      let importCount = 0;\n      let skipCount = 0;\n      let updateCount = 0;\n\n      // Traiter les lignes par lots de 500\n      const BATCH_SIZE = 500;\n      const totalLines = lines.length - 1; // Exclure l'en-t√™te\n\n      for (let startIndex = 1; startIndex < lines.length; startIndex += BATCH_SIZE) {\n        // Cr√©er un nouveau batch pour chaque groupe\n        const batch = writeBatch(db);\n        let batchCount = 0;\n        const endIndex = Math.min(startIndex + BATCH_SIZE, lines.length);\n        for (let i = startIndex; i < endIndex; i++) {\n          const line = lines[i];\n          if (!line.trim()) continue;\n          const values = this.parseCSVLine(line);\n          const document = {};\n\n          // Construire le document √† partir des valeurs\n          normalizedHeaders.forEach((header, index) => {\n            if (header && values[index]) {\n              document[header] = this.normalizeValue(values[index].trim(), header);\n            }\n          });\n\n          // V√©rifier si le site existe d√©j√†\n          let existingSite = null;\n\n          // 1. V√©rifier par ID si disponible\n          if (document.id) {\n            existingSite = existingSitesMap.get(document.id);\n          }\n\n          // 2. V√©rifier par nom normalis√©\n          if (!existingSite && document.nom) {\n            const normalizedName = document.nom.toLowerCase().trim();\n            existingSite = existingSitesByName.get(normalizedName);\n          }\n\n          // 3. V√©rifier par adresse compl√®te\n          if (!existingSite && document.adresse && document.ville && document.codePostal) {\n            const normalizedAddress = `${document.adresse},${document.ville},${document.codePostal}`.toLowerCase().replace(/\\s+/g, '').normalize('NFD').replace(/[\\u0300-\\u036f]/g, '');\n            existingSite = existingSitesByAddress.get(normalizedAddress);\n          }\n\n          // Si le site existe d√©j√†\n          if (existingSite) {\n            if (!updateExisting) {\n              skipCount++;\n              continue;\n            }\n\n            // V√©rifier si les donn√©es sont diff√©rentes avant de mettre √† jour\n            const hasChanges = Object.keys(document).some(key => document[key] !== existingSite[key] && document[key] !== undefined);\n            if (!hasChanges) {\n              skipCount++;\n              continue;\n            }\n\n            // Mettre √† jour le site existant\n            const siteRef = doc(db, 'sites', existingSite.id);\n            batch.set(siteRef, document);\n            updateCount++;\n            batchCount++;\n          } else {\n            // Cr√©er un nouveau site\n            const newSiteRef = doc(collection(db, 'sites'));\n            batch.set(newSiteRef, document);\n            importCount++;\n            batchCount++;\n          }\n        }\n\n        // Commiter le batch s'il contient des op√©rations\n        if (batchCount > 0) {\n          await batch.commit();\n          console.log(`Lot de ${batchCount} documents trait√© (${startIndex}/${totalLines})`);\n        }\n      }\n      console.log(`\n        Importation termin√©e:\n        - ${importCount} nouveaux sites import√©s\n        - ${updateCount} sites mis √† jour\n        - ${skipCount} sites ignor√©s (doublons ou sans changements)\n      `);\n      return importCount + updateCount;\n    } catch (error) {\n      console.error('Erreur lors du traitement des lignes:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Normalise les en-t√™tes pour corriger les probl√®mes d'encodage\n   * @param headers Tableau des en-t√™tes\n   * @returns Tableau des en-t√™tes normalis√©s\n   */\n  normalizeHeaders(headers) {\n    console.log('Normalisation des en-t√™tes...');\n    console.log('En-t√™tes originaux:', headers);\n\n    // Mapping complet des en-t√™tes\n    const headerReplacements = {\n      // Variations de P√¥le\n      'pole': 'pole',\n      'p√¥le': 'pole',\n      'p√¥les': 'pole',\n      'poles': 'pole',\n      'ple': 'pole',\n      'p le': 'pole',\n      'p.le': 'pole',\n      'p?le': 'pole',\n      // Variations de Type\n      'type': 'type',\n      'type de site': 'type',\n      'type site': 'type',\n      'categorie': 'type',\n      'cat√©gorie': 'type',\n      // Variations de Nom\n      'nom': 'nom',\n      'nom site': 'nom',\n      'site': 'nom',\n      'nom du site': 'nom',\n      'denomination': 'nom',\n      'd√©nomination': 'nom',\n      // Variations d'Adresse\n      'adresse': 'adresse',\n      'adresses': 'adresse',\n      'adr': 'adresse',\n      'adresse site': 'adresse',\n      'adresse complete': 'adresse',\n      'adresse compl√®te': 'adresse',\n      // Variations de Compl√©ment d'adresse\n      'complement': 'complementAdresse',\n      'compl√©ment': 'complementAdresse',\n      'complement adresse': 'complementAdresse',\n      'compl√©ment adresse': 'complementAdresse',\n      'complement d\\'adresse': 'complementAdresse',\n      'compl√©ment d\\'adresse': 'complementAdresse',\n      // Variations de Ville\n      'ville': 'ville',\n      'commune': 'ville',\n      'localite': 'ville',\n      'localit√©': 'ville',\n      'villes': 'ville',\n      // Variations de Code postal\n      'cp': 'codePostal',\n      'code postal': 'codePostal',\n      'code_postal': 'codePostal',\n      'codepostal': 'codePostal',\n      'cp site': 'codePostal',\n      // Variations de Pays\n      'pays': 'pays',\n      'country': 'pays',\n      'nation': 'pays',\n      // Variations de T√©l√©phone\n      'tel': 'telephone',\n      't√©l': 'telephone',\n      'telephone': 'telephone',\n      't√©l√©phone': 'telephone',\n      'num tel': 'telephone',\n      'num√©ro': 'telephone',\n      // Variations d'Email\n      'email': 'email',\n      'e-mail': 'email',\n      'mail': 'email',\n      'courriel': 'email',\n      'adresse mail': 'email',\n      // Variations de Status\n      'status': 'statut',\n      'statut': 'statut',\n      'etat': 'statut',\n      '√©tat': 'statut',\n      // Variations de Tourn√©e\n      'tournee': 'tournees',\n      'tourn√©e': 'tournees',\n      'tournees': 'tournees',\n      'tourn√©es': 'tournees',\n      // Variations de MI\n      'mi': 'mi',\n      'responsable': 'mi',\n      'responsable mi': 'mi',\n      // Variations de Bassin\n      'bassin': 'bassin',\n      'zone': 'bassin',\n      'secteur': 'bassin',\n      // Autres champs\n      'id': 'id',\n      'identifiant': 'id',\n      'reference': 'id',\n      'r√©f√©rence': 'id',\n      'horaires lv': 'horairesLV',\n      'horaire lv': 'horairesLV',\n      'horaires semaine': 'horairesLV',\n      'horaires sam': 'horairesSamedi',\n      'horaire sam': 'horairesSamedi',\n      'horaires samedi': 'horairesSamedi'\n    };\n\n    // Nettoyer et normaliser les en-t√™tes\n    const normalizedHeaders = headers.map(header => {\n      // Nettoyage initial\n      const cleanHeader = header.trim().toLowerCase().normalize('NFD').replace(/[\\u0300-\\u036f]/g, '') // Supprimer les accents\n      .replace(/[^a-z0-9\\s]/g, ' ') // Garder uniquement les lettres, chiffres et espaces\n      .replace(/\\s+/g, ' ') // Normaliser les espaces\n      .trim();\n\n      // Rechercher dans le mapping\n      const mappedHeader = headerReplacements[cleanHeader];\n      if (mappedHeader) {\n        console.log(`En-t√™te normalis√©: \"${header}\" -> \"${mappedHeader}\"`);\n        return mappedHeader;\n      }\n\n      // Si pas trouv√© dans le mapping, retourner la version nettoy√©e\n      console.log(`En-t√™te non mapp√©: \"${header}\" -> \"${cleanHeader}\"`);\n      return cleanHeader;\n    });\n    console.log('En-t√™tes finaux apr√®s normalisation:', normalizedHeaders);\n    return normalizedHeaders;\n  }\n\n  /**\n   * Normalise les valeurs des colonnes\n   * @param value Valeur √† normaliser\n   * @param fieldName Nom du champ\n   * @returns Valeur normalis√©e\n   */\n  normalizeValue(value, fieldName) {\n    if (!value) return '';\n\n    // Supprimer les caract√®res sp√©ciaux et les espaces en trop\n    let normalizedValue = value.trim().replace(/[√´√ã]/g, '').replace(/\\s+/g, ' ');\n\n    // Normalisation sp√©cifique selon le type de champ\n    switch (fieldName.toLowerCase()) {\n      case 'pole':\n        // Normaliser les variations de \"P√¥le\"\n        normalizedValue = normalizedValue.replace(/^p[o√¥√≥]le\\s*/i, '').replace(/^p\\s*[o√¥√≥]le\\s*/i, '').trim();\n        break;\n      case 'type':\n        // Normaliser les types de sites\n        const lowerValue = normalizedValue.toLowerCase();\n        if (lowerValue.includes('labo') || lowerValue.includes('lab')) {\n          normalizedValue = 'Laboratoire';\n        } else if (lowerValue.includes('site')) {\n          normalizedValue = 'Site';\n        } else if (lowerValue.includes('client')) {\n          normalizedValue = 'Client';\n        } else if (lowerValue.includes('point')) {\n          normalizedValue = 'Point de collecte';\n        } else {\n          normalizedValue = normalizedValue.charAt(0).toUpperCase() + normalizedValue.slice(1).toLowerCase();\n        }\n        break;\n      case 'ville':\n      case 'nom':\n        // Capitaliser chaque mot pour les villes et les noms\n        normalizedValue = normalizedValue.split(' ').map(word => word.charAt(0).toUpperCase() + word.slice(1).toLowerCase()).join(' ');\n        break;\n      case 'codepostal':\n        // Nettoyer le code postal (garder uniquement les chiffres)\n        normalizedValue = normalizedValue.replace(/\\D/g, '');\n        break;\n      case 'telephone':\n        // Normaliser les num√©ros de t√©l√©phone\n        normalizedValue = normalizedValue.replace(/\\D/g, '');\n        if (normalizedValue.length === 10) {\n          normalizedValue = normalizedValue.replace(/(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})/, '$1.$2.$3.$4.$5');\n        }\n        break;\n      case 'email':\n        // Mettre les emails en minuscules\n        normalizedValue = normalizedValue.toLowerCase();\n        break;\n      case 'adresse':\n        // Normaliser les adresses\n        normalizedValue = normalizedValue.replace(/\\s+/g, ' ').replace(/,\\s*/g, ', ').replace(/\\s*-\\s*/g, '-').trim();\n        break;\n    }\n    return normalizedValue;\n  }\n\n  /**\n   * Traite sp√©cifiquement le format de donn√©es fourni par l'utilisateur\n   * @param csvContent Contenu du fichier CSV\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  async importUserSpecificFormat(csvContent, options = {}) {\n    try {\n      console.log('üîÑ Importation avec le format sp√©cifique de l\\'utilisateur...');\n\n      // Options par d√©faut\n      const {\n        clearCollection = false,\n        updateExisting = true,\n        idField = 'id'\n      } = options;\n\n      // S√©parer les lignes\n      const lines = csvContent.split('\\n').filter(line => line.trim() !== '');\n      if (lines.length < 2) {\n        throw new Error('Le fichier est vide ou ne contient que des en-t√™tes.');\n      }\n\n      // Extraire et normaliser les en-t√™tes\n      const headers = lines[0].split(';').map(header => header.trim());\n      const normalizedHeaders = this.normalizeHeaders(headers);\n      console.log('En-t√™tes normalis√©s:', normalizedHeaders);\n\n      // Mapper les en-t√™tes aux champs de la base de donn√©es\n      const fieldMap = {\n        'pole': 'pole',\n        'p√¥le': 'pole',\n        'tourn√©e': 'tournees',\n        'type de site': 'type',\n        'nom': 'nom',\n        'adresse': 'adresse',\n        'compl√©ment d\\'adresse': 'complementAdresse',\n        'ville': 'ville',\n        'code postal': 'codePostal',\n        'pays': 'pays',\n        'horaire d\\'ouverture - lundi - vendredi': 'horairesLV',\n        'horaire d\\'ouverture - samedi -': 'horairesSamedi',\n        'id': 'id'\n      };\n\n      // Cr√©er un mapping des indices de colonnes vers les noms de champs\n      const columnMap = {};\n      normalizedHeaders.forEach((header, index) => {\n        const mappedField = fieldMap[header.toLowerCase()];\n        if (mappedField) {\n          columnMap[index] = mappedField;\n          console.log(`Mapped header \"${header}\" to field \"${mappedField}\"`);\n        } else {\n          console.log(`No mapping found for header \"${header}\"`);\n        }\n      });\n\n      // Pr√©parer les documents\n      const documents = [];\n\n      // Traiter chaque ligne (sauf la premi√®re qui contient les en-t√™tes)\n      for (let i = 1; i < lines.length; i++) {\n        const line = lines[i].trim();\n        if (!line) continue;\n\n        // Diviser la ligne en valeurs\n        const values = line.split(';');\n\n        // Cr√©er un document avec les valeurs par d√©faut\n        const doc = {\n          pole: '',\n          nom: '',\n          type: 'Laboratoire',\n          adresse: '',\n          ville: '',\n          codePostal: '',\n          telephone: '',\n          email: '',\n          codeBarres: '',\n          tournees: [],\n          codesPorte: '',\n          coordonnees: '',\n          statut: 'actif',\n          complementAdresse: '',\n          pays: 'France',\n          horairesLV: '',\n          horairesSamedi: ''\n        };\n\n        // Remplir le document avec les valeurs de la ligne\n        let hasValidName = false;\n        for (let j = 0; j < values.length; j++) {\n          const fieldName = columnMap[j];\n          if (!fieldName) continue;\n          let value = values[j].trim();\n\n          // Traitement sp√©cial pour certains champs\n          if (fieldName === 'tournees' && value) {\n            // Convertir en tableau\n            value = [value];\n          } else if (fieldName === 'type' && value) {\n            // Standardiser le type\n            const lowerValue = value.toLowerCase();\n            if (lowerValue.includes('labo') || lowerValue.includes('lab')) {\n              value = 'Laboratoire';\n            } else if (lowerValue.includes('site')) {\n              value = 'Site';\n            } else if (lowerValue.includes('client')) {\n              value = 'Client';\n            } else if (lowerValue.includes('point')) {\n              value = 'Point de collecte';\n            } else {\n              value = value.charAt(0).toUpperCase() + value.slice(1).toLowerCase();\n            }\n          }\n\n          // Assigner la valeur au document\n          if (value !== '') {\n            doc[fieldName] = value;\n\n            // V√©rifier si nous avons un nom valide\n            if (fieldName === 'nom' && value) {\n              hasValidName = true;\n            }\n          }\n        }\n\n        // Si nous n'avons pas de nom mais avons une adresse, utiliser l'adresse comme nom\n        if (!hasValidName && !doc.nom && doc.adresse) {\n          doc.nom = `Site - ${doc.adresse}`;\n          hasValidName = true;\n        }\n\n        // Ajouter le document s'il a un nom ou un ID\n        if (hasValidName || doc.id) {\n          documents.push(doc);\n        } else {\n          console.warn(`‚ö†Ô∏è Ligne ${i + 1} ignor√©e: aucun nom ou identifiant valide trouv√©`);\n        }\n      }\n      if (documents.length === 0) {\n        throw new Error('Aucun document valide n\\'a pu √™tre extrait du fichier.');\n      }\n      console.log(`‚úÖ ${documents.length} sites valides extraits du fichier`);\n\n      // Vider la collection si demand√©\n      if (clearCollection) {\n        await this.clearCollection('sites');\n      }\n\n      // Importer les documents\n      const totalDocuments = documents.length;\n      let processedCount = 0;\n      let importedCount = 0;\n      while (processedCount < totalDocuments) {\n        // Cr√©er un nouveau lot pour chaque groupe de 500 documents\n        const batch = writeBatch(db);\n        const batchSize = Math.min(500, totalDocuments - processedCount);\n\n        // Ajouter les documents au lot\n        for (let i = 0; i < batchSize; i++) {\n          const document = documents[processedCount + i];\n          const docId = document[idField];\n          if (docId && updateExisting) {\n            // Mettre √† jour ou cr√©er le document avec l'ID sp√©cifi√©\n            const docRef = doc(db, 'sites', docId);\n            batch.set(docRef, document);\n          } else {\n            // Cr√©er un nouveau document avec un ID g√©n√©r√©\n            const collectionRef = collection(db, 'sites');\n            const newDocRef = doc(collectionRef);\n            batch.set(newDocRef, document);\n          }\n          importedCount++;\n        }\n\n        // Ex√©cuter le lot\n        await batch.commit();\n        processedCount += batchSize;\n        console.log(`‚úÖ Lot de ${batchSize} sites import√©s (${processedCount}/${totalDocuments})`);\n      }\n      console.log(`‚úÖ Importation termin√©e: ${importedCount} sites import√©s`);\n      return importedCount;\n    } catch (error) {\n      console.error('‚ùå Erreur lors de l\\'importation avec le format sp√©cifique:', error);\n      throw error;\n    }\n  }\n}\nexport default new SharePointService();","map":{"version":3,"names":["db","collection","getDocs","Timestamp","doc","writeBatch","JSZip","SharePointService","constructor","collections","exportCollectionToCSV","collectionName","console","log","querySnapshot","empty","documents","docs","map","data","formattedData","Object","entries","forEach","key","value","toDate","toISOString","id","allKeys","Set","keys","add","headers","Array","from","csv","join","row","header","undefined","includes","replace","length","error","exportCollectionToJSON","downloadCollectionAsCSV","blob","Blob","type","url","URL","createObjectURL","link","document","createElement","setAttribute","Date","split","style","visibility","body","appendChild","click","removeChild","downloadCollectionAsJSON","JSON","stringify","downloadAllCollectionsAsCSV","downloadAllCollectionsAsJSON","generateCompleteBackup","zip","file","content","generateAsync","importCSVToCollection","csvContent","options","clearCollection","updateExisting","idField","Error","lines","parseCSVLine","i","line","trim","values","warn","j","isNaN","Number","match","fromDate","e","push","totalDocuments","processedCount","importedCount","batch","batchSize","Math","min","docId","docRef","set","collectionRef","newDocRef","commit","importJSONToCollection","jsonData","isArray","processedDoc","importFromZip","zipContent","loadAsync","results","fileName","files","_fileName$split$pop","dir","fileExt","pop","toLowerCase","fileContent","async","parse","count","snapshot","delete","cleanedLine","separator","tabCount","semicolonCount","commaCount","cleanValue","startsWith","endsWith","slice","normalizeEncoding","text","result","replacements","pattern","replacement","RegExp","normalizeFileEncoding","normalizedLines","detectAndFixEncoding","charCodeAt","hasUtf8MisinterpretedSequences","hasMissingAccents","importSitesFromTXT","txtContent","normalizedContent","filter","firstLine","normalizedCSV","processImportLines","debugFileInfo","group","hasBOM","substring","probableSeparator","estimatedColumns","secondLine","secondLineTabCount","secondLineSemicolonCount","secondLineCommaCount","secondLineColumns","specialChars","specialCharsFound","char","badSequences","badSequencesFound","seq","specificBadChars","specificBadCharsFound","groupEnd","importSitesFromCSV","isTxtFile","cleanedContent","isUserSpecificFormat","current","inQuotes","alternativeLines","sitesRef","existingSites","existingSitesMap","Map","existingSitesByName","existingSitesByAddress","siteData","nom","normalizedName","adresse","ville","codePostal","normalizedAddress","normalize","cleanedHeaders","normalizedHeaders","normalizeHeaders","importCount","skipCount","updateCount","BATCH_SIZE","totalLines","startIndex","batchCount","endIndex","index","normalizeValue","existingSite","get","hasChanges","some","siteRef","newSiteRef","headerReplacements","cleanHeader","mappedHeader","fieldName","normalizedValue","lowerValue","charAt","toUpperCase","word","importUserSpecificFormat","fieldMap","columnMap","mappedField","pole","telephone","email","codeBarres","tournees","codesPorte","coordonnees","statut","complementAdresse","pays","horairesLV","horairesSamedi","hasValidName"],"sources":["C:/Users/LS_110/Documents/GitHub/inovie-SCAN-web-main/src/services/SharePointService.ts"],"sourcesContent":["import { db } from '../config/firebase';\nimport { collection, getDocs, query, where, orderBy, limit, Timestamp, addDoc, doc, setDoc, deleteDoc, writeBatch } from 'firebase/firestore';\nimport JSZip from 'jszip';\n\n/**\n * Service pour g√©rer l'int√©gration entre Firebase et SharePoint\n * Utilise une approche de synchronisation manuelle via fichiers CSV/JSON\n * pour contourner les limitations de double authentification\n */\nexport class SharePointService {\n  // Collections Firebase √† synchroniser\n  private collections = ['passages', 'sites', 'tournees', 'vehicules'];\n  \n  /**\n   * Exporte les donn√©es d'une collection Firebase au format CSV\n   * @param collectionName Nom de la collection √† exporter\n   * @returns Cha√Æne de caract√®res au format CSV\n   */\n  async exportCollectionToCSV(collectionName: string): Promise<string> {\n    try {\n      console.log(`üîÑ Exportation de la collection ${collectionName} au format CSV...`);\n      \n      // R√©cup√©rer les donn√©es de la collection\n      const querySnapshot = await getDocs(collection(db, collectionName));\n      \n      if (querySnapshot.empty) {\n        console.log(`‚ö†Ô∏è La collection ${collectionName} est vide.`);\n        return '';\n      }\n      \n      // Extraire les donn√©es\n      const documents = querySnapshot.docs.map(doc => {\n        const data = doc.data();\n        \n        // Convertir les Timestamp en cha√Ænes de caract√®res\n        const formattedData: Record<string, any> = {};\n        \n        Object.entries(data).forEach(([key, value]) => {\n          if (value instanceof Timestamp) {\n            formattedData[key] = value.toDate().toISOString();\n          } else {\n            formattedData[key] = value;\n          }\n        });\n        \n        // Ajouter l'ID du document\n        formattedData.id = doc.id;\n        \n        return formattedData;\n      });\n      \n      // Obtenir toutes les cl√©s uniques pour les en-t√™tes CSV\n      const allKeys = new Set<string>();\n      documents.forEach(doc => {\n        Object.keys(doc).forEach(key => allKeys.add(key));\n      });\n      \n      const headers = Array.from(allKeys);\n      \n      // G√©n√©rer le CSV\n      let csv = headers.join(',') + '\\n';\n      \n      documents.forEach(doc => {\n        const row = headers.map(header => {\n          const value = doc[header];\n          \n          // √âchapper les valeurs contenant des virgules ou des sauts de ligne\n          if (value === undefined || value === null) {\n            return '';\n          } else if (typeof value === 'string' && (value.includes(',') || value.includes('\\n') || value.includes('\"'))) {\n            return `\"${value.replace(/\"/g, '\"\"')}\"`;\n          } else {\n            return value;\n          }\n        });\n        \n        csv += row.join(',') + '\\n';\n      });\n      \n      console.log(`‚úÖ Exportation de ${documents.length} documents de la collection ${collectionName} termin√©e.`);\n      \n      return csv;\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de l'exportation de la collection ${collectionName}:`, error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Exporte les donn√©es d'une collection Firebase au format JSON\n   * @param collectionName Nom de la collection √† exporter\n   * @returns Objet JSON contenant les donn√©es\n   */\n  async exportCollectionToJSON(collectionName: string): Promise<any[]> {\n    try {\n      console.log(`üîÑ Exportation de la collection ${collectionName} au format JSON...`);\n      \n      // R√©cup√©rer les donn√©es de la collection\n      const querySnapshot = await getDocs(collection(db, collectionName));\n      \n      if (querySnapshot.empty) {\n        console.log(`‚ö†Ô∏è La collection ${collectionName} est vide.`);\n        return [];\n      }\n      \n      // Extraire les donn√©es\n      const documents = querySnapshot.docs.map(doc => {\n        const data = doc.data();\n        \n        // Convertir les Timestamp en cha√Ænes de caract√®res\n        const formattedData: Record<string, any> = {};\n        \n        Object.entries(data).forEach(([key, value]) => {\n          if (value instanceof Timestamp) {\n            formattedData[key] = value.toDate().toISOString();\n          } else {\n            formattedData[key] = value;\n          }\n        });\n        \n        // Ajouter l'ID du document\n        formattedData.id = doc.id;\n        \n        return formattedData;\n      });\n      \n      console.log(`‚úÖ Exportation de ${documents.length} documents de la collection ${collectionName} termin√©e.`);\n      \n      return documents;\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de l'exportation de la collection ${collectionName}:`, error);\n      throw error;\n    }\n  }\n  \n  /**\n   * T√©l√©charge un fichier CSV contenant les donn√©es d'une collection\n   * @param collectionName Nom de la collection √† exporter\n   */\n  async downloadCollectionAsCSV(collectionName: string): Promise<void> {\n    try {\n      const csv = await this.exportCollectionToCSV(collectionName);\n      \n      if (!csv) {\n        console.log(`‚ö†Ô∏è Aucune donn√©e √† exporter pour la collection ${collectionName}.`);\n        return;\n      }\n      \n      // Cr√©er un blob et un lien de t√©l√©chargement\n      const blob = new Blob([csv], { type: 'text/csv;charset=utf-8;' });\n      const url = URL.createObjectURL(blob);\n      const link = document.createElement('a');\n      \n      link.setAttribute('href', url);\n      link.setAttribute('download', `${collectionName}_${new Date().toISOString().split('T')[0]}.csv`);\n      link.style.visibility = 'hidden';\n      \n      document.body.appendChild(link);\n      link.click();\n      document.body.removeChild(link);\n    } catch (error) {\n      console.error(`‚ùå Erreur lors du t√©l√©chargement de la collection ${collectionName}:`, error);\n      throw error;\n    }\n  }\n  \n  /**\n   * T√©l√©charge un fichier JSON contenant les donn√©es d'une collection\n   * @param collectionName Nom de la collection √† exporter\n   */\n  async downloadCollectionAsJSON(collectionName: string): Promise<void> {\n    try {\n      const data = await this.exportCollectionToJSON(collectionName);\n      \n      if (!data || data.length === 0) {\n        console.log(`‚ö†Ô∏è Aucune donn√©e √† exporter pour la collection ${collectionName}.`);\n        return;\n      }\n      \n      // Cr√©er un blob et un lien de t√©l√©chargement\n      const blob = new Blob([JSON.stringify(data, null, 2)], { type: 'application/json' });\n      const url = URL.createObjectURL(blob);\n      const link = document.createElement('a');\n      \n      link.setAttribute('href', url);\n      link.setAttribute('download', `${collectionName}_${new Date().toISOString().split('T')[0]}.json`);\n      link.style.visibility = 'hidden';\n      \n      document.body.appendChild(link);\n      link.click();\n      document.body.removeChild(link);\n    } catch (error) {\n      console.error(`‚ùå Erreur lors du t√©l√©chargement de la collection ${collectionName}:`, error);\n      throw error;\n    }\n  }\n  \n  /**\n   * T√©l√©charge toutes les collections au format CSV\n   */\n  async downloadAllCollectionsAsCSV(): Promise<void> {\n    try {\n      console.log('üîÑ Exportation de toutes les collections au format CSV...');\n      \n      for (const collectionName of this.collections) {\n        await this.downloadCollectionAsCSV(collectionName);\n      }\n      \n      console.log('‚úÖ Exportation de toutes les collections termin√©e.');\n    } catch (error) {\n      console.error('‚ùå Erreur lors de l\\'exportation de toutes les collections:', error);\n      throw error;\n    }\n  }\n  \n  /**\n   * T√©l√©charge toutes les collections au format JSON\n   */\n  async downloadAllCollectionsAsJSON(): Promise<void> {\n    try {\n      console.log('üîÑ Exportation de toutes les collections au format JSON...');\n      \n      for (const collectionName of this.collections) {\n        await this.downloadCollectionAsJSON(collectionName);\n      }\n      \n      console.log('‚úÖ Exportation de toutes les collections termin√©e.');\n    } catch (error) {\n      console.error('‚ùå Erreur lors de l\\'exportation de toutes les collections:', error);\n      throw error;\n    }\n  }\n  \n  /**\n   * G√©n√®re un fichier ZIP contenant toutes les collections au format JSON\n   */\n  async generateCompleteBackup(): Promise<void> {\n    try {\n      console.log(\"üîÑ G√©n√©ration d'une sauvegarde compl√®te...\");\n      \n      const zip = new JSZip();\n      \n      // Exporter chaque collection\n      for (const collectionName of this.collections) {\n        const data = await this.exportCollectionToJSON(collectionName);\n        \n        if (data && data.length > 0) {\n          zip.file(`${collectionName}.json`, JSON.stringify(data, null, 2));\n        }\n      }\n      \n      // G√©n√©rer le fichier ZIP\n      const content = await zip.generateAsync({ type: 'blob' });\n      \n      // T√©l√©charger le fichier\n      const url = URL.createObjectURL(content);\n      const link = document.createElement('a');\n      \n      link.setAttribute('href', url);\n      link.setAttribute('download', `firebase_backup_${new Date().toISOString().split('T')[0]}.zip`);\n      link.style.visibility = 'hidden';\n      \n      document.body.appendChild(link);\n      link.click();\n      document.body.removeChild(link);\n      \n      console.log('‚úÖ G√©n√©ration de la sauvegarde compl√®te termin√©e.');\n    } catch (error) {\n      console.error('‚ùå Erreur lors de la g√©n√©ration de la sauvegarde compl√®te:', error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Importe des donn√©es au format CSV vers une collection Firebase\n   * @param collectionName Nom de la collection cible\n   * @param csvContent Contenu du fichier CSV\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  async importCSVToCollection(\n    collectionName: string, \n    csvContent: string,\n    options: {\n      clearCollection?: boolean;\n      updateExisting?: boolean;\n      idField?: string;\n    } = {}\n  ): Promise<number> {\n    try {\n      console.log(`üîÑ Importation des donn√©es CSV vers la collection ${collectionName}...`);\n      \n      // Options par d√©faut\n      const { \n        clearCollection = false, \n        updateExisting = true,\n        idField = 'id'\n      } = options;\n      \n      // V√©rifier si la collection existe\n      if (!this.collections.includes(collectionName)) {\n        throw new Error(`La collection ${collectionName} n'est pas valide.`);\n      }\n      \n      // Analyser le CSV\n      const lines = csvContent.split('\\n');\n      if (lines.length < 2) {\n        throw new Error('Le fichier CSV est vide ou ne contient que des en-t√™tes.');\n      }\n      \n      // Extraire les en-t√™tes\n      const headers = this.parseCSVLine(lines[0]);\n      \n      // Pr√©parer les donn√©es\n      const documents: Record<string, any>[] = [];\n      \n      for (let i = 1; i < lines.length; i++) {\n        const line = lines[i].trim();\n        if (!line) continue;\n        \n        const values = this.parseCSVLine(line);\n        if (values.length !== headers.length) {\n          console.warn(`‚ö†Ô∏è Ligne ${i + 1} ignor√©e: nombre de valeurs incorrect`);\n          continue;\n        }\n        \n        const doc: Record<string, any> = {};\n        \n        for (let j = 0; j < headers.length; j++) {\n          const header = headers[j];\n          let value: any = values[j];\n          \n          // Convertir les valeurs en types appropri√©s\n          if (value === 'true') value = true;\n          else if (value === 'false') value = false;\n          else if (!isNaN(Number(value)) && value !== '') value = Number(value);\n          else if (typeof value === 'string' && (value.match(/^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}/) || value.match(/^\\d{4}-\\d{2}-\\d{2}/))) {\n            // Convertir les dates ISO en Timestamp\n            try {\n              value = Timestamp.fromDate(new Date(value));\n            } catch (e) {\n              console.warn(`‚ö†Ô∏è Impossible de convertir la date: ${value}`);\n            }\n          }\n          \n          doc[header] = value;\n        }\n        \n        documents.push(doc);\n      }\n      \n      // Vider la collection si demand√©\n      if (clearCollection) {\n        await this.clearCollection(collectionName);\n      }\n      \n      // Importer les documents\n      const totalDocuments = documents.length;\n      let processedCount = 0;\n      let importedCount = 0;\n      \n      while (processedCount < totalDocuments) {\n        // Cr√©er un nouveau lot pour chaque groupe de 500 documents\n        const batch = writeBatch(db);\n        const batchSize = Math.min(500, totalDocuments - processedCount);\n        \n        // Ajouter les documents au lot\n        for (let i = 0; i < batchSize; i++) {\n          const document = documents[processedCount + i];\n          const docId = document[idField];\n          \n          if (docId && updateExisting) {\n            // Mettre √† jour ou cr√©er le document avec l'ID sp√©cifi√©\n            const docRef = doc(db, collectionName, docId);\n            batch.set(docRef, document);\n          } else {\n            // Cr√©er un nouveau document avec un ID g√©n√©r√©\n            const collectionRef = collection(db, collectionName);\n            const newDocRef = doc(collectionRef);\n            batch.set(newDocRef, document);\n          }\n          \n          importedCount++;\n        }\n        \n        // Ex√©cuter le lot\n        await batch.commit();\n        processedCount += batchSize;\n        console.log(`‚úÖ Lot de ${batchSize} documents import√©s (${processedCount}/${totalDocuments})`);\n      }\n      \n      console.log(`‚úÖ Importation termin√©e: ${importedCount} documents import√©s dans la collection ${collectionName}`);\n      return importedCount;\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de l'importation des donn√©es CSV:`, error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Importe des donn√©es au format JSON vers une collection Firebase\n   * @param collectionName Nom de la collection cible\n   * @param jsonData Donn√©es JSON √† importer\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  async importJSONToCollection(\n    collectionName: string, \n    jsonData: any[],\n    options: {\n      clearCollection?: boolean;\n      updateExisting?: boolean;\n      idField?: string;\n    } = {}\n  ): Promise<number> {\n    try {\n      console.log(`üîÑ Importation des donn√©es JSON vers la collection ${collectionName}...`);\n      \n      // Options par d√©faut\n      const { \n        clearCollection = false, \n        updateExisting = true,\n        idField = 'id'\n      } = options;\n      \n      // V√©rifier si la collection existe\n      if (!this.collections.includes(collectionName)) {\n        throw new Error(`La collection ${collectionName} n'est pas valide.`);\n      }\n      \n      // V√©rifier que les donn√©es sont un tableau\n      if (!Array.isArray(jsonData)) {\n        throw new Error('Les donn√©es JSON doivent √™tre un tableau d\\'objets.');\n      }\n      \n      // Convertir les dates en Timestamp\n      const documents = jsonData.map(doc => {\n        const processedDoc: Record<string, any> = {};\n        \n        Object.entries(doc).forEach(([key, value]) => {\n          if (typeof value === 'string' && (value.match(/^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}/) || value.match(/^\\d{4}-\\d{2}-\\d{2}/))) {\n            // Convertir les dates ISO en Timestamp\n            try {\n              processedDoc[key] = Timestamp.fromDate(new Date(value));\n            } catch (e) {\n              console.warn(`‚ö†Ô∏è Impossible de convertir la date: ${value}`);\n              processedDoc[key] = value;\n            }\n          } else {\n            processedDoc[key] = value;\n          }\n        });\n        \n        return processedDoc;\n      });\n      \n      // Vider la collection si demand√©\n      if (clearCollection) {\n        await this.clearCollection(collectionName);\n      }\n      \n      // Importer les documents\n      const totalDocuments = documents.length;\n      let processedCount = 0;\n      let importedCount = 0;\n      \n      while (processedCount < totalDocuments) {\n        // Cr√©er un nouveau lot pour chaque groupe de 500 documents\n        const batch = writeBatch(db);\n        const batchSize = Math.min(500, totalDocuments - processedCount);\n        \n        // Ajouter les documents au lot\n        for (let i = 0; i < batchSize; i++) {\n          const document = documents[processedCount + i];\n          const docId = document[idField];\n          \n          if (docId && updateExisting) {\n            // Mettre √† jour ou cr√©er le document avec l'ID sp√©cifi√©\n            const docRef = doc(db, collectionName, docId);\n            batch.set(docRef, document);\n          } else {\n            // Cr√©er un nouveau document avec un ID g√©n√©r√©\n            const collectionRef = collection(db, collectionName);\n            const newDocRef = doc(collectionRef);\n            batch.set(newDocRef, document);\n          }\n          \n          importedCount++;\n        }\n        \n        // Ex√©cuter le lot\n        await batch.commit();\n        processedCount += batchSize;\n        console.log(`‚úÖ Lot de ${batchSize} documents import√©s (${processedCount}/${totalDocuments})`);\n      }\n      \n      console.log(`‚úÖ Importation termin√©e: ${importedCount} documents import√©s dans la collection ${collectionName}`);\n      return importedCount;\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de l'importation des donn√©es JSON:`, error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Importe des donn√©es depuis un fichier ZIP contenant plusieurs collections\n   * @param zipContent Contenu du fichier ZIP\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s par collection\n   */\n  async importFromZip(\n    zipContent: ArrayBuffer,\n    options: {\n      clearCollections?: boolean;\n      updateExisting?: boolean;\n      idField?: string;\n    } = {}\n  ): Promise<Record<string, number>> {\n    try {\n      console.log('üîÑ Importation des donn√©es depuis le fichier ZIP...');\n      \n      const zip = new JSZip();\n      await zip.loadAsync(zipContent);\n      \n      const results: Record<string, number> = {};\n      \n      // Parcourir les fichiers du ZIP\n      for (const fileName in zip.files) {\n        if (zip.files[fileName].dir) continue;\n        \n        const fileExt = fileName.split('.').pop()?.toLowerCase();\n        const collectionName = fileName.split('.')[0];\n        \n        if (!this.collections.includes(collectionName)) {\n          console.warn(`‚ö†Ô∏è Collection inconnue ignor√©e: ${collectionName}`);\n          continue;\n        }\n        \n        const fileContent = await zip.files[fileName].async('string');\n        \n        if (fileExt === 'json') {\n          try {\n            const jsonData = JSON.parse(fileContent);\n            const count = await this.importJSONToCollection(collectionName, jsonData, options);\n            results[collectionName] = count;\n          } catch (e) {\n            console.error(`‚ùå Erreur lors de l'importation du fichier JSON ${fileName}:`, e);\n          }\n        } else if (fileExt === 'csv') {\n          try {\n            const count = await this.importCSVToCollection(collectionName, fileContent, options);\n            results[collectionName] = count;\n          } catch (e) {\n            console.error(`‚ùå Erreur lors de l'importation du fichier CSV ${fileName}:`, e);\n          }\n        } else {\n          console.warn(`‚ö†Ô∏è Type de fichier non pris en charge: ${fileExt}`);\n        }\n      }\n      \n      console.log('‚úÖ Importation depuis ZIP termin√©e:', results);\n      return results;\n    } catch (error) {\n      console.error('‚ùå Erreur lors de l\\'importation depuis le fichier ZIP:', error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Vide une collection\n   * @param collectionName Nom de la collection √† vider\n   */\n  private async clearCollection(collectionName: string): Promise<void> {\n    try {\n      console.log(`üîÑ Suppression des documents existants dans la collection ${collectionName}...`);\n      \n      const collectionRef = collection(db, collectionName);\n      const snapshot = await getDocs(collectionRef);\n      \n      if (snapshot.empty) {\n        console.log(`‚ÑπÔ∏è La collection ${collectionName} est d√©j√† vide.`);\n        return;\n      }\n      \n      // Traiter les documents par lots de 500 (limite Firestore)\n      const documents = snapshot.docs;\n      const totalDocuments = documents.length;\n      let processedCount = 0;\n      \n      while (processedCount < totalDocuments) {\n        // Cr√©er un nouveau lot pour chaque groupe de 500 documents\n        const batch = writeBatch(db);\n        const batchSize = Math.min(500, totalDocuments - processedCount);\n        \n        // Ajouter les suppressions au lot\n        for (let i = 0; i < batchSize; i++) {\n          const document = documents[processedCount + i];\n          batch.delete(doc(db, collectionName, document.id));\n        }\n        \n        // Ex√©cuter le lot\n        await batch.commit();\n        processedCount += batchSize;\n        console.log(`‚úÖ Lot de ${batchSize} documents supprim√©s (${processedCount}/${totalDocuments})`);\n      }\n      \n      console.log(`‚úÖ Collection ${collectionName} vid√©e avec succ√®s.`);\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de la suppression des documents:`, error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Analyse une ligne CSV en tenant compte des guillemets\n   * @param line Ligne CSV √† analyser\n   * @returns Tableau des valeurs\n   */\n  private parseCSVLine(line: string): string[] {\n    // Si la ligne est vide, retourner un tableau vide\n    if (!line || line.trim() === '') {\n      return [];\n    }\n    \n    // Supprimer TOUS les caract√®res \"√´\" de la ligne avant tout traitement\n    let cleanedLine = line.replace(/√´/g, '');\n    cleanedLine = cleanedLine.replace(/√ã/g, '');\n    \n    // D√©tecter le s√©parateur le plus probable pour cette ligne\n    let separator = ';'; // On d√©finit le point-virgule comme s√©parateur par d√©faut\n    const tabCount = (cleanedLine.match(/\\t/g) || []).length;\n    const semicolonCount = (cleanedLine.match(/;/g) || []).length;\n    const commaCount = (cleanedLine.match(/,/g) || []).length;\n    \n    if (tabCount > 0 && tabCount >= semicolonCount && tabCount >= commaCount) {\n      separator = '\\t';\n    } else if (commaCount > semicolonCount) {\n      separator = ',';\n    }\n    \n    // Diviser la ligne en utilisant le s√©parateur d√©tect√©\n    const values = cleanedLine.split(separator).map(value => {\n      // Nettoyer chaque valeur\n      let cleanValue = value.trim();\n      \n      // Supprimer les guillemets en d√©but et fin si pr√©sents\n      if (cleanValue.startsWith('\"') && cleanValue.endsWith('\"')) {\n        cleanValue = cleanValue.slice(1, -1);\n      }\n      \n      // Remplacer les doubles guillemets par des simples\n      cleanValue = cleanValue.replace(/\"\"/g, '\"');\n      \n      return cleanValue;\n    });\n    \n    // Afficher des informations de d√©bogage\n    console.log(`Ligne nettoy√©e: \"${cleanedLine}\"`);\n    console.log(`Valeurs extraites: ${JSON.stringify(values)}`);\n    \n    return values;\n  }\n  \n  /**\n   * Normalise l'encodage des caract√®res sp√©ciaux\n   * @param text Texte √† normaliser\n   * @returns Texte normalis√©\n   */\n  private normalizeEncoding(text: string): string {\n    if (!text) return '';\n    \n    // Supprimer tous les caract√®res \"√´\" et \"√ã\"\n    let result = text.replace(/[√´√ã]/g, '');\n    \n    // Remplacer les caract√®res mal encod√©s par leurs √©quivalents corrects\n    const replacements: Record<string, string> = {\n      'Ple': 'P√¥le',\n      'Pole': 'P√¥le',\n      'POLE': 'P√¥le',\n      'Tourne': 'Tourn√©e',\n      'TOURNEE': 'Tourn√©e',\n      'Tournee': 'Tourn√©e',\n      'Complment': 'Compl√©ment',\n      'Complement': 'Compl√©ment',\n      'Tlphone': 'T√©l√©phone',\n      'Telephone': 'T√©l√©phone',\n      'Coordonnes': 'Coordonn√©es',\n      'Coordonnees': 'Coordonn√©es'\n    };\n    \n    // Appliquer les remplacements\n    Object.entries(replacements).forEach(([pattern, replacement]) => {\n      result = result.replace(new RegExp(pattern, 'g'), replacement);\n    });\n    \n    return result;\n  }\n  \n  /**\n   * Normalise l'encodage d'un fichier CSV/TXT entier\n   * @param content Contenu du fichier\n   * @returns Contenu normalis√©\n   */\n  private normalizeFileEncoding(content: string): string {\n    if (!content) return '';\n    \n    console.log('Normalisation de l\\'encodage du fichier...');\n    \n    // Supprimer tous les caract√®res \"√´\"\n    content = content.replace(/√´/g, '');\n    \n    // D√©tecter et corriger les probl√®mes d'encodage courants\n    const lines = content.split(/\\r?\\n/);\n    const normalizedLines = lines.map(line => {\n      // Normaliser l'encodage de chaque ligne\n      return this.normalizeEncoding(line);\n    });\n    \n    return normalizedLines.join('\\n');\n  }\n  \n  /**\n   * D√©tecte et corrige l'encodage d'un fichier CSV\n   * @param content Contenu du fichier\n   * @returns Contenu avec encodage corrig√©\n   */\n  private detectAndFixEncoding(content: string): string {\n    if (!content) return '';\n    \n    console.log('D√©tection et correction de l\\'encodage...');\n    \n    // V√©rifier si le contenu commence par un BOM UTF-8\n    if (content.charCodeAt(0) === 0xFEFF) {\n      console.log('BOM UTF-8 d√©tect√©, suppression...');\n      content = content.slice(1);\n    }\n    \n    // Supprimer tous les caract√®res \"√´\"\n    if (content.includes('√´')) {\n      console.log('Caract√®res \"√´\" d√©tect√©s, suppression...');\n      content = content.replace(/√´/g, '');\n    }\n    \n    // D√©tecter les s√©quences typiques d'un encodage UTF-8 mal interpr√©t√©\n    const hasUtf8MisinterpretedSequences = \n      content.includes('√É¬©') || // √©\n      content.includes('√É¬®') || // √®\n      content.includes('√É¬™') || // √™\n      content.includes('√É ') || // √†\n      content.includes('√É¬ß') || // √ß\n      content.includes('√É¬¥') || // √¥\n      content.includes('√É¬Æ') || // √Æ\n      content.includes('√É¬Ø') || // √Ø\n      content.includes('√É¬º') || // √º\n      content.includes('√É¬π') || // √π\n      content.includes('√É¬ª') || // √ª\n      content.includes('√É¬¢') || // √¢\n      content.includes('√É¬´') || // √´\n      content.includes('√É‚Ä∞') || // √â\n      content.includes('√É\"'); // √î\n    \n    if (hasUtf8MisinterpretedSequences) {\n      console.log('S√©quences UTF-8 mal interpr√©t√©es d√©tect√©es, correction...');\n      \n      // Corriger les s√©quences UTF-8 mal interpr√©t√©es\n      content = content\n        .replace(/√É¬©/g, '√©')\n        .replace(/√É¬®/g, '√®')\n        .replace(/√É¬™/g, '√™')\n        .replace(/√É /g, '√†')\n        .replace(/√É¬ß/g, '√ß')\n        .replace(/√É¬¥/g, '√¥')\n        .replace(/√É¬Æ/g, '√Æ')\n        .replace(/√É¬Ø/g, '√Ø')\n        .replace(/√É¬º/g, '√º')\n        .replace(/√É¬π/g, '√π')\n        .replace(/√É¬ª/g, '√ª')\n        .replace(/√É¬¢/g, '√¢')\n        .replace(/√É¬´/g, '√´')\n        .replace(/√É‚Ä∞/g, '√â')\n        .replace(/√É\"/g, '√î')\n        .replace(/P√É¬¥le/g, 'P√¥le')\n        .replace(/Tourn√É¬©e/g, 'Tourn√©e')\n        .replace(/Compl√É¬©ment d\\'adresse/g, 'Compl√©ment d\\'adresse')\n        .replace(/T√É¬©l√É¬©phone/g, 'T√©l√©phone')\n        .replace(/Coordonn√É¬©es/g, 'Coordonn√©es');\n    }\n    \n    // D√©tecter les caract√®res mal encod√©s sp√©cifiques\n    const hasMissingAccents = \n      content.includes('Ple') || \n      content.includes('Tourne') || \n      content.includes('Complment');\n    \n    if (hasMissingAccents) {\n      console.log('Caract√®res accentu√©s manquants d√©tect√©s, correction...');\n      \n      // Corriger les caract√®res mal encod√©s\n      content = content\n        .replace(/Ple/g, 'P√¥le')\n        .replace(/Tourne/g, 'Tourn√©e')\n        .replace(/Complment d\\'adresse/g, 'Compl√©ment d\\'adresse')\n        .replace(/Complment/g, 'Compl√©ment')\n        .replace(/Tlphone/g, 'T√©l√©phone')\n        .replace(/Coordonnes/g, 'Coordonn√©es');\n    }\n    \n    return content;\n  }\n  \n  /**\n   * Importe des sites depuis un fichier TXT\n   * @param txtContent Contenu du fichier TXT\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  private async importSitesFromTXT(\n    txtContent: string,\n    options: {\n      clearCollection?: boolean;\n      updateExisting?: boolean;\n      idField?: string;\n    } = {}\n  ): Promise<number> {\n    try {\n      console.log('Traitement sp√©cifique pour fichier TXT...');\n      \n      // D√©tecter et corriger l'encodage du fichier\n      let normalizedContent = this.detectAndFixEncoding(txtContent);\n      \n      // Normaliser l'encodage du contenu du fichier\n      normalizedContent = this.normalizeFileEncoding(normalizedContent);\n      \n      // Diviser le contenu en lignes\n      const lines = normalizedContent.split('\\n').map(line => line.trim()).filter(line => line !== '');\n      \n      if (lines.length === 0) {\n        throw new Error('Le fichier est vide.');\n      }\n      \n      const firstLine = lines[0];\n      \n      if (!firstLine) {\n        throw new Error('La premi√®re ligne du fichier est vide.');\n      }\n      \n      console.log('Premi√®re ligne du fichier TXT:', firstLine);\n      \n      // D√©tecter le s√©parateur en comptant les occurrences\n      const tabCount = (firstLine.match(/\\t/g) || []).length;\n      const semicolonCount = (firstLine.match(/;/g) || []).length;\n      const commaCount = (firstLine.match(/,/g) || []).length;\n      \n      console.log(`S√©parateurs d√©tect√©s - Tabulations: ${tabCount}, Points-virgules: ${semicolonCount}, Virgules: ${commaCount}`);\n      \n      // Afficher un √©chantillon des premi√®res lignes pour le d√©bogage\n      console.log('√âchantillon des 3 premi√®res lignes TXT:');\n      for (let i = 0; i < Math.min(3, lines.length); i++) {\n        console.log(`Ligne ${i}: ${lines[i]}`);\n      }\n      \n      // Pour les fichiers TXT, on privil√©gie la tabulation si elle est pr√©sente\n      let separator = '\\t';\n      \n      if (tabCount > 0) {\n        separator = '\\t';\n        console.log('S√©parateur d√©tect√© pour TXT: tabulation');\n      } else if (semicolonCount > 0 && semicolonCount >= commaCount) {\n        separator = ';';\n        console.log('S√©parateur d√©tect√© pour TXT: point-virgule');\n      } else if (commaCount > 0) {\n        separator = ',';\n        console.log('S√©parateur d√©tect√© pour TXT: virgule');\n      } else {\n        console.log('Aucun s√©parateur standard d√©tect√© dans le fichier TXT, utilisation de la tabulation par d√©faut');\n      }\n      \n      // Convertir le TXT en format CSV normalis√©\n      const normalizedCSV = lines.map(line => {\n        if (!line) return '';\n        \n        // Remplacer le s√©parateur d√©tect√© par des virgules\n        if (separator !== ',') {\n          // G√©rer correctement les champs entre guillemets avec le s√©parateur √† l'int√©rieur\n          const values = this.parseCSVLine(line);\n          return values.map(value => {\n            // Entourer de guillemets si la valeur contient une virgule\n            if (value.includes(',')) {\n              return `\"${value.replace(/\"/g, '\"\"')}\"`;\n            }\n            return value;\n          }).join(',');\n        }\n        \n        return line;\n      }).join('\\n');\n      \n      // V√©rifier si la conversion a r√©ussi\n      const normalizedLines = normalizedCSV.split('\\n');\n      if (normalizedLines.length < 2) {\n        throw new Error('La conversion du fichier TXT a √©chou√©.');\n      }\n      \n      // Extraire les en-t√™tes\n      const headers = this.parseCSVLine(normalizedLines[0]);\n      \n      // V√©rifier que le fichier contient suffisamment de colonnes\n      if (headers.length < 3) {\n        throw new Error(`Le fichier ne contient que ${headers.length} colonnes. V√©rifiez le format du fichier et assurez-vous qu'il utilise des tabulations, des points-virgules ou des virgules comme s√©parateurs.`);\n      }\n      \n      console.log('En-t√™tes d√©tect√©s dans le fichier TXT:', headers);\n      \n      // Traiter les lignes avec la fonction commune\n      return this.processImportLines(headers, normalizedLines, options);\n    } catch (error) {\n      console.error('‚ùå Erreur lors de l\\'importation des sites depuis TXT:', error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Affiche des informations de d√©bogage sur un fichier CSV/TXT\n   * @param content Contenu du fichier\n   * @param fileName Nom du fichier\n   */\n  private debugFileInfo(content: string, fileName: string = 'inconnu'): void {\n    console.group(`üìä Informations de d√©bogage pour le fichier: ${fileName}`);\n    \n    try {\n      // Informations g√©n√©rales\n      console.log(`Taille du contenu: ${content.length} caract√®res`);\n      console.log(`Type de fichier: ${fileName.endsWith('.txt') ? 'TXT' : 'CSV'}`);\n      \n      // V√©rifier la pr√©sence du BOM UTF-8\n      const hasBOM = content.charCodeAt(0) === 0xFEFF;\n      console.log(`BOM UTF-8 d√©tect√©: ${hasBOM ? 'Oui' : 'Non'}`);\n      \n      // Analyser les lignes\n      const lines = content.split('\\n');\n      console.log(`Nombre de lignes: ${lines.length}`);\n      \n      if (lines.length > 0) {\n        // Analyser la premi√®re ligne (en-t√™tes)\n        const firstLine = lines[0].trim();\n        console.log(`Premi√®re ligne (${firstLine.length} caract√®res): ${firstLine.substring(0, 100)}${firstLine.length > 100 ? '...' : ''}`);\n        \n        // D√©tecter les s√©parateurs\n        const tabCount = (firstLine.match(/\\t/g) || []).length;\n        const semicolonCount = (firstLine.match(/;/g) || []).length;\n        const commaCount = (firstLine.match(/,/g) || []).length;\n        \n        console.log(`S√©parateurs d√©tect√©s - Tabulations: ${tabCount}, Points-virgules: ${semicolonCount}, Virgules: ${commaCount}`);\n        \n        // D√©tecter le s√©parateur le plus probable\n        let probableSeparator = ',';\n        if (tabCount > 0 && tabCount >= semicolonCount && tabCount >= commaCount) {\n          probableSeparator = '\\t';\n        } else if (semicolonCount > 0 && semicolonCount >= commaCount) {\n          probableSeparator = ';';\n        }\n        \n        console.log(`S√©parateur le plus probable: ${probableSeparator === '\\t' ? 'tabulation' : probableSeparator}`);\n        \n        // Estimer le nombre de colonnes\n        const estimatedColumns = probableSeparator === '\\t' \n          ? tabCount + 1 \n          : (probableSeparator === ';' ? semicolonCount + 1 : commaCount + 1);\n        \n        console.log(`Nombre estim√© de colonnes: ${estimatedColumns}`);\n        \n        // V√©rifier la coh√©rence des lignes\n        if (lines.length > 1) {\n          const secondLine = lines[1].trim();\n          const secondLineTabCount = (secondLine.match(/\\t/g) || []).length;\n          const secondLineSemicolonCount = (secondLine.match(/;/g) || []).length;\n          const secondLineCommaCount = (secondLine.match(/,/g) || []).length;\n          \n          const secondLineColumns = probableSeparator === '\\t' \n            ? secondLineTabCount + 1 \n            : (probableSeparator === ';' ? secondLineSemicolonCount + 1 : secondLineCommaCount + 1);\n          \n          console.log(`Nombre de colonnes dans la deuxi√®me ligne: ${secondLineColumns}`);\n          console.log(`Coh√©rence des colonnes: ${estimatedColumns === secondLineColumns ? 'OK' : 'PROBL√àME'}`);\n        }\n        \n        // V√©rifier l'encodage des caract√®res sp√©ciaux\n        const specialChars = ['√©', '√®', '√™', '√†', '√ß', '√¥', '√Æ', '√Ø', '√º', '√π', '√ª', '√¢', '√´'];\n        const specialCharsFound = specialChars.filter(char => content.includes(char));\n        \n        console.log(`Caract√®res sp√©ciaux correctement encod√©s: ${specialCharsFound.length > 0 ? specialCharsFound.join(', ') : 'Aucun'}`);\n        \n        // V√©rifier les s√©quences UTF-8 mal interpr√©t√©es\n        const badSequences = ['√É¬©', '√É¬®', '√É¬™', '√É ', '√É¬ß', '√É¬¥', '√É¬Æ', '√É¬Ø', '√É¬º', '√É¬π', '√É¬ª', '√É¬¢', '√É¬´'];\n        const badSequencesFound = badSequences.filter(seq => content.includes(seq));\n        \n        console.log(`S√©quences UTF-8 mal interpr√©t√©es: ${badSequencesFound.length > 0 ? badSequencesFound.join(', ') : 'Aucune'}`);\n        \n        // V√©rifier les caract√®res mal encod√©s sp√©cifiques\n        const specificBadChars = ['Ple', 'Tourne', 'Complment'];\n        const specificBadCharsFound = specificBadChars.filter(char => content.includes(char));\n        \n        console.log(`Caract√®res mal encod√©s sp√©cifiques: ${specificBadCharsFound.length > 0 ? specificBadCharsFound.join(', ') : 'Aucun'}`);\n      }\n    } catch (error) {\n      console.error('Erreur lors de l\\'analyse du fichier:', error);\n    } finally {\n      console.groupEnd();\n    }\n  }\n  \n  /**\n   * Importe des sites depuis un fichier CSV\n   * @param csvContent Contenu du fichier CSV\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  async importSitesFromCSV(\n    csvContent: string,\n    options: {\n      clearCollection?: boolean;\n      updateExisting?: boolean;\n      idField?: string;\n      isTxtFile?: boolean;\n      fileName?: string;\n    } = {}\n  ): Promise<number> {\n    try {\n      const { \n        clearCollection = false, \n        updateExisting = true,\n        idField = 'id',\n        isTxtFile = false,\n        fileName = isTxtFile ? 'fichier.txt' : 'fichier.csv'\n      } = options;\n      \n      console.log(`D√©but de l'importation des sites depuis ${isTxtFile ? 'TXT' : 'CSV'}...`);\n      \n      // Afficher des informations de d√©bogage sur le fichier\n      this.debugFileInfo(csvContent, fileName);\n      \n      // Traitement sp√©cifique pour les fichiers TXT\n      if (isTxtFile) {\n        return this.importSitesFromTXT(csvContent, options);\n      }\n      \n      // Supprimer tous les caract√®res \"√´\" du contenu\n      let cleanedContent = csvContent.replace(/√´/g, '');\n      console.log('Contenu apr√®s nettoyage des caract√®res √´ (50 premiers caract√®res):', cleanedContent.substring(0, 50));\n      \n      // D√©tecter et corriger l'encodage du fichier\n      let normalizedContent = this.detectAndFixEncoding(cleanedContent);\n      \n      // V√©rifier si le contenu est encod√© en UTF-8 avec BOM\n      if (csvContent.charCodeAt(0) === 0xFEFF) {\n        console.log('D√©tection du BOM UTF-8, suppression...');\n        normalizedContent = csvContent.slice(1);\n      }\n      \n      // Normaliser l'encodage du contenu du fichier\n      normalizedContent = this.normalizeFileEncoding(normalizedContent);\n      \n      // Diviser le contenu en lignes\n      const lines = normalizedContent.split(/\\r?\\n/).map(line => line.trim()).filter(line => line !== '');\n      \n      if (lines.length === 0) {\n        throw new Error('Le fichier est vide.');\n      }\n      \n      const firstLine = lines[0];\n      \n      if (!firstLine) {\n        throw new Error('La premi√®re ligne du fichier est vide.');\n      }\n      \n      console.log('Premi√®re ligne du fichier:', firstLine);\n      \n      // D√©tecter le s√©parateur en comptant les occurrences\n      const tabCount = (firstLine.match(/\\t/g) || []).length;\n      const semicolonCount = (firstLine.match(/;/g) || []).length;\n      const commaCount = (firstLine.match(/,/g) || []).length;\n      \n      // Initialiser la variable separator\n      let separator = ',';\n      \n      // D√©tecter si c'est le format sp√©cifique de l'utilisateur\n      const isUserSpecificFormat = firstLine.includes('P√¥le;Bassin;MI;Tourn√©e') || \n                                  firstLine.includes('P√¥le;Bassin;MI;Tourn√©e;PT de rattachement') ||\n                                  firstLine.includes('Pole;Bassin;MI;Tournee') ||\n                                  firstLine.includes('ID;Pole;Bassin;MI;Tournee');\n      \n      if (isUserSpecificFormat) {\n        console.log('Format sp√©cifique d√©tect√©: format utilisateur avec s√©parateur point-virgule');\n        separator = ';';\n      }\n      \n      console.log(`S√©parateurs d√©tect√©s - Tabulations: ${tabCount}, Points-virgules: ${semicolonCount}, Virgules: ${commaCount}`);\n      console.log(`Format d√©tect√©: ${isUserSpecificFormat ? 'Format utilisateur sp√©cifique' : 'Format standard'}`);\n      \n      // Pour les fichiers TXT, on privil√©gie la tabulation si elle est pr√©sente\n      if (isTxtFile) {\n        if (tabCount > 0) {\n          separator = '\\t';\n          console.log('S√©parateur d√©tect√© pour TXT: tabulation');\n        } else if (semicolonCount > 0 && semicolonCount >= commaCount) {\n          separator = ';';\n          console.log('S√©parateur d√©tect√© pour TXT: point-virgule');\n        } else if (commaCount > 0) {\n          separator = ',';\n          console.log('S√©parateur d√©tect√© pour TXT: virgule');\n        } else {\n          console.log('Aucun s√©parateur standard d√©tect√© dans le fichier TXT, utilisation de la tabulation par d√©faut');\n        }\n      } else {\n        // Pour les fichiers CSV, logique existante\n        if (tabCount > 0 && tabCount >= semicolonCount && tabCount >= commaCount) {\n          separator = '\\t';\n          console.log('S√©parateur d√©tect√© pour CSV: tabulation');\n        } else if (semicolonCount > 0 && semicolonCount >= commaCount) {\n          separator = ';';\n          console.log('S√©parateur d√©tect√© pour CSV: point-virgule');\n        } else {\n          console.log('S√©parateur d√©tect√© pour CSV: virgule');\n        }\n      }\n      \n      // Afficher un √©chantillon des premi√®res lignes pour le d√©bogage\n      console.log('√âchantillon des 3 premi√®res lignes:');\n      for (let i = 0; i < Math.min(3, lines.length); i++) {\n        console.log(`Ligne ${i}: ${lines[i]}`);\n      }\n      \n      // Convertir le CSV en utilisant le s√©parateur d√©tect√©\n      let normalizedCSV = '';\n      \n      if (separator !== ',') {\n        normalizedCSV = lines.map(line => {\n          if (!line) return '';\n          \n          // G√©rer correctement les champs entre guillemets avec le s√©parateur √† l'int√©rieur\n          const result: string[] = [];\n          let current = '';\n          let inQuotes = false;\n          \n          for (let i = 0; i < line.length; i++) {\n            const char = line[i];\n            \n            if (char === '\"') {\n              inQuotes = !inQuotes;\n              current += char;\n            } else if (char === separator && !inQuotes) {\n              result.push(current);\n              current = '';\n            } else {\n              current += char;\n            }\n          }\n          \n          // Ajouter le dernier champ\n          result.push(current);\n          \n          return result.join(',');\n        }).join('\\n');\n      } else {\n        normalizedCSV = normalizedContent;\n      }\n      \n      // V√©rifier si le fichier a √©t√© correctement normalis√©\n      const normalizedLines = normalizedCSV.split(/\\r?\\n/).filter(line => line.trim() !== '');\n      if (normalizedLines.length < 2) {\n        // Si la normalisation a √©chou√©, essayer une approche diff√©rente\n        console.warn('‚ö†Ô∏è La normalisation standard a √©chou√©, tentative avec une approche alternative...');\n        \n        // Utiliser directement les lignes d'origine et laisser parseCSVLine g√©rer les s√©parateurs\n        const alternativeLines = lines.filter(line => line.trim() !== '');\n        \n        if (alternativeLines.length < 2) {\n          throw new Error('Le fichier est vide ou ne contient que des en-t√™tes.');\n        }\n        \n        // Extraire les en-t√™tes avec la fonction parseCSVLine am√©lior√©e\n        const headers = this.parseCSVLine(alternativeLines[0]);\n        \n        // V√©rifier que le fichier contient suffisamment de colonnes\n        if (headers.length < 3) {\n          throw new Error(`Le fichier ne contient que ${headers.length} colonnes. V√©rifiez le format du fichier et assurez-vous qu'il utilise des virgules, des points-virgules ou des tabulations comme s√©parateurs.`);\n        }\n        \n        console.log('En-t√™tes d√©tect√©s (approche alternative):', headers);\n        \n        // Continuer avec les lignes alternatives\n        return this.processImportLines(headers, alternativeLines, options);\n      }\n      \n      // Extraire les en-t√™tes\n      const headers = this.parseCSVLine(normalizedLines[0]);\n      \n      // V√©rifier que le CSV contient suffisamment de colonnes\n      if (headers.length < 3) {\n        throw new Error(`Le fichier ne contient que ${headers.length} colonnes. V√©rifiez le format du fichier et assurez-vous qu'il utilise des virgules, des points-virgules ou des tabulations comme s√©parateurs.`);\n      }\n      \n      console.log('En-t√™tes d√©tect√©s:', headers);\n      \n      return this.processImportLines(headers, normalizedLines, options);\n    } catch (error) {\n      console.error(`‚ùå Erreur lors de l'importation des sites depuis ${isTxtFile ? 'TXT' : 'CSV'}:`, error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Traite les lignes import√©es pour extraire les documents\n   * @param headers En-t√™tes des colonnes\n   * @param lines Lignes de donn√©es\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  private async processImportLines(\n    headers: string[],\n    lines: string[],\n    options: {\n      clearCollection?: boolean;\n      updateExisting?: boolean;\n      idField?: string;\n    } = {}\n  ): Promise<number> {\n    try {\n      const { \n        clearCollection = false, \n        updateExisting = true,\n        idField = 'id'\n      } = options;\n\n      // R√©cup√©rer tous les sites existants pour la v√©rification des doublons\n      const sitesRef = collection(db, 'sites');\n      const existingSites = await getDocs(sitesRef);\n      const existingSitesMap = new Map<string, any>();\n      const existingSitesByName = new Map<string, any>();\n      const existingSitesByAddress = new Map<string, any>();\n\n      existingSites.forEach(doc => {\n        const siteData = doc.data();\n        existingSitesMap.set(doc.id, siteData);\n        \n        // Index par nom normalis√©\n        if (siteData.nom) {\n          const normalizedName = siteData.nom.toLowerCase().trim();\n          existingSitesByName.set(normalizedName, { id: doc.id, ...siteData });\n        }\n        \n        // Index par adresse compl√®te normalis√©e\n        if (siteData.adresse && siteData.ville && siteData.codePostal) {\n          const normalizedAddress = `${siteData.adresse},${siteData.ville},${siteData.codePostal}`\n            .toLowerCase()\n            .replace(/\\s+/g, '')\n            .normalize('NFD')\n            .replace(/[\\u0300-\\u036f]/g, '');\n          existingSitesByAddress.set(normalizedAddress, { id: doc.id, ...siteData });\n        }\n      });\n      \n      // Nettoyer les en-t√™tes avant de les normaliser\n      const cleanedHeaders = headers.map(header => header.replace(/√´/g, ''));\n      const normalizedHeaders = this.normalizeHeaders(cleanedHeaders);\n      \n      let importCount = 0;\n      let skipCount = 0;\n      let updateCount = 0;\n      \n      // Traiter les lignes par lots de 500\n      const BATCH_SIZE = 500;\n      const totalLines = lines.length - 1; // Exclure l'en-t√™te\n      \n      for (let startIndex = 1; startIndex < lines.length; startIndex += BATCH_SIZE) {\n        // Cr√©er un nouveau batch pour chaque groupe\n        const batch = writeBatch(db);\n        let batchCount = 0;\n        \n        const endIndex = Math.min(startIndex + BATCH_SIZE, lines.length);\n        \n        for (let i = startIndex; i < endIndex; i++) {\n          const line = lines[i];\n          if (!line.trim()) continue;\n          \n          const values = this.parseCSVLine(line);\n          const document: Record<string, any> = {};\n          \n          // Construire le document √† partir des valeurs\n          normalizedHeaders.forEach((header, index) => {\n            if (header && values[index]) {\n              document[header] = this.normalizeValue(values[index].trim(), header);\n            }\n          });\n\n          // V√©rifier si le site existe d√©j√†\n          let existingSite = null;\n\n          // 1. V√©rifier par ID si disponible\n          if (document.id) {\n            existingSite = existingSitesMap.get(document.id);\n          }\n\n          // 2. V√©rifier par nom normalis√©\n          if (!existingSite && document.nom) {\n            const normalizedName = document.nom.toLowerCase().trim();\n            existingSite = existingSitesByName.get(normalizedName);\n          }\n\n          // 3. V√©rifier par adresse compl√®te\n          if (!existingSite && document.adresse && document.ville && document.codePostal) {\n            const normalizedAddress = `${document.adresse},${document.ville},${document.codePostal}`\n              .toLowerCase()\n              .replace(/\\s+/g, '')\n              .normalize('NFD')\n              .replace(/[\\u0300-\\u036f]/g, '');\n            existingSite = existingSitesByAddress.get(normalizedAddress);\n          }\n\n          // Si le site existe d√©j√†\n          if (existingSite) {\n            if (!updateExisting) {\n              skipCount++;\n              continue;\n            }\n\n            // V√©rifier si les donn√©es sont diff√©rentes avant de mettre √† jour\n            const hasChanges = Object.keys(document).some(key => \n              document[key] !== existingSite[key] && document[key] !== undefined\n            );\n\n            if (!hasChanges) {\n              skipCount++;\n              continue;\n            }\n\n            // Mettre √† jour le site existant\n            const siteRef = doc(db, 'sites', existingSite.id);\n            batch.set(siteRef, document);\n            updateCount++;\n            batchCount++;\n          } else {\n            // Cr√©er un nouveau site\n            const newSiteRef = doc(collection(db, 'sites'));\n            batch.set(newSiteRef, document);\n            importCount++;\n            batchCount++;\n          }\n        }\n\n        // Commiter le batch s'il contient des op√©rations\n        if (batchCount > 0) {\n          await batch.commit();\n          console.log(`Lot de ${batchCount} documents trait√© (${startIndex}/${totalLines})`);\n        }\n      }\n\n      console.log(`\n        Importation termin√©e:\n        - ${importCount} nouveaux sites import√©s\n        - ${updateCount} sites mis √† jour\n        - ${skipCount} sites ignor√©s (doublons ou sans changements)\n      `);\n\n      return importCount + updateCount;\n    } catch (error) {\n      console.error('Erreur lors du traitement des lignes:', error);\n      throw error;\n    }\n  }\n  \n  /**\n   * Normalise les en-t√™tes pour corriger les probl√®mes d'encodage\n   * @param headers Tableau des en-t√™tes\n   * @returns Tableau des en-t√™tes normalis√©s\n   */\n  private normalizeHeaders(headers: string[]): string[] {\n    console.log('Normalisation des en-t√™tes...');\n    console.log('En-t√™tes originaux:', headers);\n    \n    // Mapping complet des en-t√™tes\n    const headerReplacements: Record<string, string> = {\n      // Variations de P√¥le\n      'pole': 'pole',\n      'p√¥le': 'pole',\n      'p√¥les': 'pole',\n      'poles': 'pole',\n      'ple': 'pole',\n      'p le': 'pole',\n      'p.le': 'pole',\n      'p?le': 'pole',\n      \n      // Variations de Type\n      'type': 'type',\n      'type de site': 'type',\n      'type site': 'type',\n      'categorie': 'type',\n      'cat√©gorie': 'type',\n      \n      // Variations de Nom\n      'nom': 'nom',\n      'nom site': 'nom',\n      'site': 'nom',\n      'nom du site': 'nom',\n      'denomination': 'nom',\n      'd√©nomination': 'nom',\n      \n      // Variations d'Adresse\n      'adresse': 'adresse',\n      'adresses': 'adresse',\n      'adr': 'adresse',\n      'adresse site': 'adresse',\n      'adresse complete': 'adresse',\n      'adresse compl√®te': 'adresse',\n      \n      // Variations de Compl√©ment d'adresse\n      'complement': 'complementAdresse',\n      'compl√©ment': 'complementAdresse',\n      'complement adresse': 'complementAdresse',\n      'compl√©ment adresse': 'complementAdresse',\n      'complement d\\'adresse': 'complementAdresse',\n      'compl√©ment d\\'adresse': 'complementAdresse',\n      \n      // Variations de Ville\n      'ville': 'ville',\n      'commune': 'ville',\n      'localite': 'ville',\n      'localit√©': 'ville',\n      'villes': 'ville',\n      \n      // Variations de Code postal\n      'cp': 'codePostal',\n      'code postal': 'codePostal',\n      'code_postal': 'codePostal',\n      'codepostal': 'codePostal',\n      'cp site': 'codePostal',\n      \n      // Variations de Pays\n      'pays': 'pays',\n      'country': 'pays',\n      'nation': 'pays',\n      \n      // Variations de T√©l√©phone\n      'tel': 'telephone',\n      't√©l': 'telephone',\n      'telephone': 'telephone',\n      't√©l√©phone': 'telephone',\n      'num tel': 'telephone',\n      'num√©ro': 'telephone',\n      \n      // Variations d'Email\n      'email': 'email',\n      'e-mail': 'email',\n      'mail': 'email',\n      'courriel': 'email',\n      'adresse mail': 'email',\n      \n      // Variations de Status\n      'status': 'statut',\n      'statut': 'statut',\n      'etat': 'statut',\n      '√©tat': 'statut',\n      \n      // Variations de Tourn√©e\n      'tournee': 'tournees',\n      'tourn√©e': 'tournees',\n      'tournees': 'tournees',\n      'tourn√©es': 'tournees',\n      \n      // Variations de MI\n      'mi': 'mi',\n      'responsable': 'mi',\n      'responsable mi': 'mi',\n      \n      // Variations de Bassin\n      'bassin': 'bassin',\n      'zone': 'bassin',\n      'secteur': 'bassin',\n      \n      // Autres champs\n      'id': 'id',\n      'identifiant': 'id',\n      'reference': 'id',\n      'r√©f√©rence': 'id',\n      'horaires lv': 'horairesLV',\n      'horaire lv': 'horairesLV',\n      'horaires semaine': 'horairesLV',\n      'horaires sam': 'horairesSamedi',\n      'horaire sam': 'horairesSamedi',\n      'horaires samedi': 'horairesSamedi'\n    };\n    \n    // Nettoyer et normaliser les en-t√™tes\n    const normalizedHeaders = headers.map(header => {\n      // Nettoyage initial\n      const cleanHeader = header\n        .trim()\n        .toLowerCase()\n        .normalize('NFD')\n        .replace(/[\\u0300-\\u036f]/g, '') // Supprimer les accents\n        .replace(/[^a-z0-9\\s]/g, ' ') // Garder uniquement les lettres, chiffres et espaces\n        .replace(/\\s+/g, ' ') // Normaliser les espaces\n        .trim();\n      \n      // Rechercher dans le mapping\n      const mappedHeader = headerReplacements[cleanHeader];\n      \n      if (mappedHeader) {\n        console.log(`En-t√™te normalis√©: \"${header}\" -> \"${mappedHeader}\"`);\n        return mappedHeader;\n      }\n      \n      // Si pas trouv√© dans le mapping, retourner la version nettoy√©e\n      console.log(`En-t√™te non mapp√©: \"${header}\" -> \"${cleanHeader}\"`);\n      return cleanHeader;\n    });\n    \n    console.log('En-t√™tes finaux apr√®s normalisation:', normalizedHeaders);\n    return normalizedHeaders;\n  }\n  \n  /**\n   * Normalise les valeurs des colonnes\n   * @param value Valeur √† normaliser\n   * @param fieldName Nom du champ\n   * @returns Valeur normalis√©e\n   */\n  private normalizeValue(value: string, fieldName: string): string {\n    if (!value) return '';\n    \n    // Supprimer les caract√®res sp√©ciaux et les espaces en trop\n    let normalizedValue = value.trim()\n      .replace(/[√´√ã]/g, '')\n      .replace(/\\s+/g, ' ');\n\n    // Normalisation sp√©cifique selon le type de champ\n    switch (fieldName.toLowerCase()) {\n      case 'pole':\n        // Normaliser les variations de \"P√¥le\"\n        normalizedValue = normalizedValue\n          .replace(/^p[o√¥√≥]le\\s*/i, '')\n          .replace(/^p\\s*[o√¥√≥]le\\s*/i, '')\n          .trim();\n        break;\n      \n      case 'type':\n        // Normaliser les types de sites\n        const lowerValue = normalizedValue.toLowerCase();\n        if (lowerValue.includes('labo') || lowerValue.includes('lab')) {\n          normalizedValue = 'Laboratoire';\n        } else if (lowerValue.includes('site')) {\n          normalizedValue = 'Site';\n        } else if (lowerValue.includes('client')) {\n          normalizedValue = 'Client';\n        } else if (lowerValue.includes('point')) {\n          normalizedValue = 'Point de collecte';\n        } else {\n          normalizedValue = normalizedValue.charAt(0).toUpperCase() + normalizedValue.slice(1).toLowerCase();\n        }\n        break;\n      \n      case 'ville':\n      case 'nom':\n        // Capitaliser chaque mot pour les villes et les noms\n        normalizedValue = normalizedValue.split(' ')\n          .map(word => word.charAt(0).toUpperCase() + word.slice(1).toLowerCase())\n          .join(' ');\n        break;\n      \n      case 'codepostal':\n        // Nettoyer le code postal (garder uniquement les chiffres)\n        normalizedValue = normalizedValue.replace(/\\D/g, '');\n        break;\n      \n      case 'telephone':\n        // Normaliser les num√©ros de t√©l√©phone\n        normalizedValue = normalizedValue.replace(/\\D/g, '');\n        if (normalizedValue.length === 10) {\n          normalizedValue = normalizedValue.replace(/(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})/, '$1.$2.$3.$4.$5');\n        }\n        break;\n      \n      case 'email':\n        // Mettre les emails en minuscules\n        normalizedValue = normalizedValue.toLowerCase();\n        break;\n      \n      case 'adresse':\n        // Normaliser les adresses\n        normalizedValue = normalizedValue\n          .replace(/\\s+/g, ' ')\n          .replace(/,\\s*/g, ', ')\n          .replace(/\\s*-\\s*/g, '-')\n          .trim();\n        break;\n    }\n    \n    return normalizedValue;\n  }\n  \n  /**\n   * Traite sp√©cifiquement le format de donn√©es fourni par l'utilisateur\n   * @param csvContent Contenu du fichier CSV\n   * @param options Options d'importation\n   * @returns Nombre de documents import√©s\n   */\n  async importUserSpecificFormat(\n    csvContent: string,\n    options: {\n      clearCollection?: boolean;\n      updateExisting?: boolean;\n      idField?: string;\n    } = {}\n  ): Promise<number> {\n    try {\n      console.log('üîÑ Importation avec le format sp√©cifique de l\\'utilisateur...');\n      \n      // Options par d√©faut\n      const { \n        clearCollection = false, \n        updateExisting = true,\n        idField = 'id'\n      } = options;\n      \n      // S√©parer les lignes\n      const lines = csvContent.split('\\n').filter(line => line.trim() !== '');\n      \n      if (lines.length < 2) {\n        throw new Error('Le fichier est vide ou ne contient que des en-t√™tes.');\n      }\n      \n      // Extraire et normaliser les en-t√™tes\n      const headers = lines[0].split(';').map(header => header.trim());\n      const normalizedHeaders = this.normalizeHeaders(headers);\n      console.log('En-t√™tes normalis√©s:', normalizedHeaders);\n      \n      // Mapper les en-t√™tes aux champs de la base de donn√©es\n      const fieldMap: Record<string, string> = {\n        'pole': 'pole',\n        'p√¥le': 'pole',\n        'tourn√©e': 'tournees',\n        'type de site': 'type',\n        'nom': 'nom',\n        'adresse': 'adresse',\n        'compl√©ment d\\'adresse': 'complementAdresse',\n        'ville': 'ville',\n        'code postal': 'codePostal',\n        'pays': 'pays',\n        'horaire d\\'ouverture - lundi - vendredi': 'horairesLV',\n        'horaire d\\'ouverture - samedi -': 'horairesSamedi',\n        'id': 'id'\n      };\n      \n      // Cr√©er un mapping des indices de colonnes vers les noms de champs\n      const columnMap: Record<number, string> = {};\n      normalizedHeaders.forEach((header, index) => {\n        const mappedField = fieldMap[header.toLowerCase()];\n        if (mappedField) {\n          columnMap[index] = mappedField;\n          console.log(`Mapped header \"${header}\" to field \"${mappedField}\"`);\n        } else {\n          console.log(`No mapping found for header \"${header}\"`);\n        }\n      });\n      \n      // Pr√©parer les documents\n      const documents: Record<string, any>[] = [];\n      \n      // Traiter chaque ligne (sauf la premi√®re qui contient les en-t√™tes)\n      for (let i = 1; i < lines.length; i++) {\n        const line = lines[i].trim();\n        if (!line) continue;\n        \n        // Diviser la ligne en valeurs\n        const values = line.split(';');\n        \n        // Cr√©er un document avec les valeurs par d√©faut\n        const doc: Record<string, any> = {\n          pole: '',\n          nom: '',\n          type: 'Laboratoire',\n          adresse: '',\n          ville: '',\n          codePostal: '',\n          telephone: '',\n          email: '',\n          codeBarres: '',\n          tournees: [],\n          codesPorte: '',\n          coordonnees: '',\n          statut: 'actif',\n          complementAdresse: '',\n          pays: 'France',\n          horairesLV: '',\n          horairesSamedi: ''\n        };\n        \n        // Remplir le document avec les valeurs de la ligne\n        let hasValidName = false;\n        \n        for (let j = 0; j < values.length; j++) {\n          const fieldName = columnMap[j];\n          if (!fieldName) continue;\n          \n          let value = values[j].trim();\n          \n          // Traitement sp√©cial pour certains champs\n          if (fieldName === 'tournees' && value) {\n            // Convertir en tableau\n            value = [value];\n          } else if (fieldName === 'type' && value) {\n            // Standardiser le type\n            const lowerValue = value.toLowerCase();\n            if (lowerValue.includes('labo') || lowerValue.includes('lab')) {\n              value = 'Laboratoire';\n            } else if (lowerValue.includes('site')) {\n              value = 'Site';\n            } else if (lowerValue.includes('client')) {\n              value = 'Client';\n            } else if (lowerValue.includes('point')) {\n              value = 'Point de collecte';\n            } else {\n              value = value.charAt(0).toUpperCase() + value.slice(1).toLowerCase();\n            }\n          }\n          \n          // Assigner la valeur au document\n          if (value !== '') {\n            doc[fieldName] = value;\n            \n            // V√©rifier si nous avons un nom valide\n            if (fieldName === 'nom' && value) {\n              hasValidName = true;\n            }\n          }\n        }\n        \n        // Si nous n'avons pas de nom mais avons une adresse, utiliser l'adresse comme nom\n        if (!hasValidName && !doc.nom && doc.adresse) {\n          doc.nom = `Site - ${doc.adresse}`;\n          hasValidName = true;\n        }\n        \n        // Ajouter le document s'il a un nom ou un ID\n        if (hasValidName || doc.id) {\n          documents.push(doc);\n        } else {\n          console.warn(`‚ö†Ô∏è Ligne ${i + 1} ignor√©e: aucun nom ou identifiant valide trouv√©`);\n        }\n      }\n      \n      if (documents.length === 0) {\n        throw new Error('Aucun document valide n\\'a pu √™tre extrait du fichier.');\n      }\n      \n      console.log(`‚úÖ ${documents.length} sites valides extraits du fichier`);\n      \n      // Vider la collection si demand√©\n      if (clearCollection) {\n        await this.clearCollection('sites');\n      }\n      \n      // Importer les documents\n      const totalDocuments = documents.length;\n      let processedCount = 0;\n      let importedCount = 0;\n      \n      while (processedCount < totalDocuments) {\n        // Cr√©er un nouveau lot pour chaque groupe de 500 documents\n        const batch = writeBatch(db);\n        const batchSize = Math.min(500, totalDocuments - processedCount);\n        \n        // Ajouter les documents au lot\n        for (let i = 0; i < batchSize; i++) {\n          const document = documents[processedCount + i];\n          const docId = document[idField];\n          \n          if (docId && updateExisting) {\n            // Mettre √† jour ou cr√©er le document avec l'ID sp√©cifi√©\n            const docRef = doc(db, 'sites', docId);\n            batch.set(docRef, document);\n          } else {\n            // Cr√©er un nouveau document avec un ID g√©n√©r√©\n            const collectionRef = collection(db, 'sites');\n            const newDocRef = doc(collectionRef);\n            batch.set(newDocRef, document);\n          }\n          \n          importedCount++;\n        }\n        \n        // Ex√©cuter le lot\n        await batch.commit();\n        processedCount += batchSize;\n        console.log(`‚úÖ Lot de ${batchSize} sites import√©s (${processedCount}/${totalDocuments})`);\n      }\n      \n      console.log(`‚úÖ Importation termin√©e: ${importedCount} sites import√©s`);\n      return importedCount;\n    } catch (error) {\n      console.error('‚ùå Erreur lors de l\\'importation avec le format sp√©cifique:', error);\n      throw error;\n    }\n  }\n}\n\nexport default new SharePointService(); \r\n"],"mappings":"AAAA,SAASA,EAAE,QAAQ,oBAAoB;AACvC,SAASC,UAAU,EAAEC,OAAO,EAAgCC,SAAS,EAAUC,GAAG,EAAqBC,UAAU,QAAQ,oBAAoB;AAC7I,OAAOC,KAAK,MAAM,OAAO;;AAEzB;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,iBAAiB,CAAC;EAAAC,YAAA;IAC7B;IAAA,KACQC,WAAW,GAAG,CAAC,UAAU,EAAE,OAAO,EAAE,UAAU,EAAE,WAAW,CAAC;EAAA;EAEpE;AACF;AACA;AACA;AACA;EACE,MAAMC,qBAAqBA,CAACC,cAAsB,EAAmB;IACnE,IAAI;MACFC,OAAO,CAACC,GAAG,CAAC,mCAAmCF,cAAc,mBAAmB,CAAC;;MAEjF;MACA,MAAMG,aAAa,GAAG,MAAMZ,OAAO,CAACD,UAAU,CAACD,EAAE,EAAEW,cAAc,CAAC,CAAC;MAEnE,IAAIG,aAAa,CAACC,KAAK,EAAE;QACvBH,OAAO,CAACC,GAAG,CAAC,oBAAoBF,cAAc,YAAY,CAAC;QAC3D,OAAO,EAAE;MACX;;MAEA;MACA,MAAMK,SAAS,GAAGF,aAAa,CAACG,IAAI,CAACC,GAAG,CAACd,GAAG,IAAI;QAC9C,MAAMe,IAAI,GAAGf,GAAG,CAACe,IAAI,CAAC,CAAC;;QAEvB;QACA,MAAMC,aAAkC,GAAG,CAAC,CAAC;QAE7CC,MAAM,CAACC,OAAO,CAACH,IAAI,CAAC,CAACI,OAAO,CAAC,CAAC,CAACC,GAAG,EAAEC,KAAK,CAAC,KAAK;UAC7C,IAAIA,KAAK,YAAYtB,SAAS,EAAE;YAC9BiB,aAAa,CAACI,GAAG,CAAC,GAAGC,KAAK,CAACC,MAAM,CAAC,CAAC,CAACC,WAAW,CAAC,CAAC;UACnD,CAAC,MAAM;YACLP,aAAa,CAACI,GAAG,CAAC,GAAGC,KAAK;UAC5B;QACF,CAAC,CAAC;;QAEF;QACAL,aAAa,CAACQ,EAAE,GAAGxB,GAAG,CAACwB,EAAE;QAEzB,OAAOR,aAAa;MACtB,CAAC,CAAC;;MAEF;MACA,MAAMS,OAAO,GAAG,IAAIC,GAAG,CAAS,CAAC;MACjCd,SAAS,CAACO,OAAO,CAACnB,GAAG,IAAI;QACvBiB,MAAM,CAACU,IAAI,CAAC3B,GAAG,CAAC,CAACmB,OAAO,CAACC,GAAG,IAAIK,OAAO,CAACG,GAAG,CAACR,GAAG,CAAC,CAAC;MACnD,CAAC,CAAC;MAEF,MAAMS,OAAO,GAAGC,KAAK,CAACC,IAAI,CAACN,OAAO,CAAC;;MAEnC;MACA,IAAIO,GAAG,GAAGH,OAAO,CAACI,IAAI,CAAC,GAAG,CAAC,GAAG,IAAI;MAElCrB,SAAS,CAACO,OAAO,CAACnB,GAAG,IAAI;QACvB,MAAMkC,GAAG,GAAGL,OAAO,CAACf,GAAG,CAACqB,MAAM,IAAI;UAChC,MAAMd,KAAK,GAAGrB,GAAG,CAACmC,MAAM,CAAC;;UAEzB;UACA,IAAId,KAAK,KAAKe,SAAS,IAAIf,KAAK,KAAK,IAAI,EAAE;YACzC,OAAO,EAAE;UACX,CAAC,MAAM,IAAI,OAAOA,KAAK,KAAK,QAAQ,KAAKA,KAAK,CAACgB,QAAQ,CAAC,GAAG,CAAC,IAAIhB,KAAK,CAACgB,QAAQ,CAAC,IAAI,CAAC,IAAIhB,KAAK,CAACgB,QAAQ,CAAC,GAAG,CAAC,CAAC,EAAE;YAC5G,OAAO,IAAIhB,KAAK,CAACiB,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC,GAAG;UACzC,CAAC,MAAM;YACL,OAAOjB,KAAK;UACd;QACF,CAAC,CAAC;QAEFW,GAAG,IAAIE,GAAG,CAACD,IAAI,CAAC,GAAG,CAAC,GAAG,IAAI;MAC7B,CAAC,CAAC;MAEFzB,OAAO,CAACC,GAAG,CAAC,oBAAoBG,SAAS,CAAC2B,MAAM,+BAA+BhC,cAAc,YAAY,CAAC;MAE1G,OAAOyB,GAAG;IACZ,CAAC,CAAC,OAAOQ,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,mDAAmDjC,cAAc,GAAG,EAAEiC,KAAK,CAAC;MAC1F,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;EACE,MAAMC,sBAAsBA,CAAClC,cAAsB,EAAkB;IACnE,IAAI;MACFC,OAAO,CAACC,GAAG,CAAC,mCAAmCF,cAAc,oBAAoB,CAAC;;MAElF;MACA,MAAMG,aAAa,GAAG,MAAMZ,OAAO,CAACD,UAAU,CAACD,EAAE,EAAEW,cAAc,CAAC,CAAC;MAEnE,IAAIG,aAAa,CAACC,KAAK,EAAE;QACvBH,OAAO,CAACC,GAAG,CAAC,oBAAoBF,cAAc,YAAY,CAAC;QAC3D,OAAO,EAAE;MACX;;MAEA;MACA,MAAMK,SAAS,GAAGF,aAAa,CAACG,IAAI,CAACC,GAAG,CAACd,GAAG,IAAI;QAC9C,MAAMe,IAAI,GAAGf,GAAG,CAACe,IAAI,CAAC,CAAC;;QAEvB;QACA,MAAMC,aAAkC,GAAG,CAAC,CAAC;QAE7CC,MAAM,CAACC,OAAO,CAACH,IAAI,CAAC,CAACI,OAAO,CAAC,CAAC,CAACC,GAAG,EAAEC,KAAK,CAAC,KAAK;UAC7C,IAAIA,KAAK,YAAYtB,SAAS,EAAE;YAC9BiB,aAAa,CAACI,GAAG,CAAC,GAAGC,KAAK,CAACC,MAAM,CAAC,CAAC,CAACC,WAAW,CAAC,CAAC;UACnD,CAAC,MAAM;YACLP,aAAa,CAACI,GAAG,CAAC,GAAGC,KAAK;UAC5B;QACF,CAAC,CAAC;;QAEF;QACAL,aAAa,CAACQ,EAAE,GAAGxB,GAAG,CAACwB,EAAE;QAEzB,OAAOR,aAAa;MACtB,CAAC,CAAC;MAEFR,OAAO,CAACC,GAAG,CAAC,oBAAoBG,SAAS,CAAC2B,MAAM,+BAA+BhC,cAAc,YAAY,CAAC;MAE1G,OAAOK,SAAS;IAClB,CAAC,CAAC,OAAO4B,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,mDAAmDjC,cAAc,GAAG,EAAEiC,KAAK,CAAC;MAC1F,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;EACE,MAAME,uBAAuBA,CAACnC,cAAsB,EAAiB;IACnE,IAAI;MACF,MAAMyB,GAAG,GAAG,MAAM,IAAI,CAAC1B,qBAAqB,CAACC,cAAc,CAAC;MAE5D,IAAI,CAACyB,GAAG,EAAE;QACRxB,OAAO,CAACC,GAAG,CAAC,kDAAkDF,cAAc,GAAG,CAAC;QAChF;MACF;;MAEA;MACA,MAAMoC,IAAI,GAAG,IAAIC,IAAI,CAAC,CAACZ,GAAG,CAAC,EAAE;QAAEa,IAAI,EAAE;MAA0B,CAAC,CAAC;MACjE,MAAMC,GAAG,GAAGC,GAAG,CAACC,eAAe,CAACL,IAAI,CAAC;MACrC,MAAMM,IAAI,GAAGC,QAAQ,CAACC,aAAa,CAAC,GAAG,CAAC;MAExCF,IAAI,CAACG,YAAY,CAAC,MAAM,EAAEN,GAAG,CAAC;MAC9BG,IAAI,CAACG,YAAY,CAAC,UAAU,EAAE,GAAG7C,cAAc,IAAI,IAAI8C,IAAI,CAAC,CAAC,CAAC9B,WAAW,CAAC,CAAC,CAAC+B,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC;MAChGL,IAAI,CAACM,KAAK,CAACC,UAAU,GAAG,QAAQ;MAEhCN,QAAQ,CAACO,IAAI,CAACC,WAAW,CAACT,IAAI,CAAC;MAC/BA,IAAI,CAACU,KAAK,CAAC,CAAC;MACZT,QAAQ,CAACO,IAAI,CAACG,WAAW,CAACX,IAAI,CAAC;IACjC,CAAC,CAAC,OAAOT,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,oDAAoDjC,cAAc,GAAG,EAAEiC,KAAK,CAAC;MAC3F,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;EACE,MAAMqB,wBAAwBA,CAACtD,cAAsB,EAAiB;IACpE,IAAI;MACF,MAAMQ,IAAI,GAAG,MAAM,IAAI,CAAC0B,sBAAsB,CAAClC,cAAc,CAAC;MAE9D,IAAI,CAACQ,IAAI,IAAIA,IAAI,CAACwB,MAAM,KAAK,CAAC,EAAE;QAC9B/B,OAAO,CAACC,GAAG,CAAC,kDAAkDF,cAAc,GAAG,CAAC;QAChF;MACF;;MAEA;MACA,MAAMoC,IAAI,GAAG,IAAIC,IAAI,CAAC,CAACkB,IAAI,CAACC,SAAS,CAAChD,IAAI,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC,EAAE;QAAE8B,IAAI,EAAE;MAAmB,CAAC,CAAC;MACpF,MAAMC,GAAG,GAAGC,GAAG,CAACC,eAAe,CAACL,IAAI,CAAC;MACrC,MAAMM,IAAI,GAAGC,QAAQ,CAACC,aAAa,CAAC,GAAG,CAAC;MAExCF,IAAI,CAACG,YAAY,CAAC,MAAM,EAAEN,GAAG,CAAC;MAC9BG,IAAI,CAACG,YAAY,CAAC,UAAU,EAAE,GAAG7C,cAAc,IAAI,IAAI8C,IAAI,CAAC,CAAC,CAAC9B,WAAW,CAAC,CAAC,CAAC+B,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC;MACjGL,IAAI,CAACM,KAAK,CAACC,UAAU,GAAG,QAAQ;MAEhCN,QAAQ,CAACO,IAAI,CAACC,WAAW,CAACT,IAAI,CAAC;MAC/BA,IAAI,CAACU,KAAK,CAAC,CAAC;MACZT,QAAQ,CAACO,IAAI,CAACG,WAAW,CAACX,IAAI,CAAC;IACjC,CAAC,CAAC,OAAOT,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,oDAAoDjC,cAAc,GAAG,EAAEiC,KAAK,CAAC;MAC3F,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;EACE,MAAMwB,2BAA2BA,CAAA,EAAkB;IACjD,IAAI;MACFxD,OAAO,CAACC,GAAG,CAAC,2DAA2D,CAAC;MAExE,KAAK,MAAMF,cAAc,IAAI,IAAI,CAACF,WAAW,EAAE;QAC7C,MAAM,IAAI,CAACqC,uBAAuB,CAACnC,cAAc,CAAC;MACpD;MAEAC,OAAO,CAACC,GAAG,CAAC,mDAAmD,CAAC;IAClE,CAAC,CAAC,OAAO+B,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,4DAA4D,EAAEA,KAAK,CAAC;MAClF,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;EACE,MAAMyB,4BAA4BA,CAAA,EAAkB;IAClD,IAAI;MACFzD,OAAO,CAACC,GAAG,CAAC,4DAA4D,CAAC;MAEzE,KAAK,MAAMF,cAAc,IAAI,IAAI,CAACF,WAAW,EAAE;QAC7C,MAAM,IAAI,CAACwD,wBAAwB,CAACtD,cAAc,CAAC;MACrD;MAEAC,OAAO,CAACC,GAAG,CAAC,mDAAmD,CAAC;IAClE,CAAC,CAAC,OAAO+B,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,4DAA4D,EAAEA,KAAK,CAAC;MAClF,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;EACE,MAAM0B,sBAAsBA,CAAA,EAAkB;IAC5C,IAAI;MACF1D,OAAO,CAACC,GAAG,CAAC,4CAA4C,CAAC;MAEzD,MAAM0D,GAAG,GAAG,IAAIjE,KAAK,CAAC,CAAC;;MAEvB;MACA,KAAK,MAAMK,cAAc,IAAI,IAAI,CAACF,WAAW,EAAE;QAC7C,MAAMU,IAAI,GAAG,MAAM,IAAI,CAAC0B,sBAAsB,CAAClC,cAAc,CAAC;QAE9D,IAAIQ,IAAI,IAAIA,IAAI,CAACwB,MAAM,GAAG,CAAC,EAAE;UAC3B4B,GAAG,CAACC,IAAI,CAAC,GAAG7D,cAAc,OAAO,EAAEuD,IAAI,CAACC,SAAS,CAAChD,IAAI,EAAE,IAAI,EAAE,CAAC,CAAC,CAAC;QACnE;MACF;;MAEA;MACA,MAAMsD,OAAO,GAAG,MAAMF,GAAG,CAACG,aAAa,CAAC;QAAEzB,IAAI,EAAE;MAAO,CAAC,CAAC;;MAEzD;MACA,MAAMC,GAAG,GAAGC,GAAG,CAACC,eAAe,CAACqB,OAAO,CAAC;MACxC,MAAMpB,IAAI,GAAGC,QAAQ,CAACC,aAAa,CAAC,GAAG,CAAC;MAExCF,IAAI,CAACG,YAAY,CAAC,MAAM,EAAEN,GAAG,CAAC;MAC9BG,IAAI,CAACG,YAAY,CAAC,UAAU,EAAE,mBAAmB,IAAIC,IAAI,CAAC,CAAC,CAAC9B,WAAW,CAAC,CAAC,CAAC+B,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC;MAC9FL,IAAI,CAACM,KAAK,CAACC,UAAU,GAAG,QAAQ;MAEhCN,QAAQ,CAACO,IAAI,CAACC,WAAW,CAACT,IAAI,CAAC;MAC/BA,IAAI,CAACU,KAAK,CAAC,CAAC;MACZT,QAAQ,CAACO,IAAI,CAACG,WAAW,CAACX,IAAI,CAAC;MAE/BzC,OAAO,CAACC,GAAG,CAAC,kDAAkD,CAAC;IACjE,CAAC,CAAC,OAAO+B,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,2DAA2D,EAAEA,KAAK,CAAC;MACjF,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;EACE,MAAM+B,qBAAqBA,CACzBhE,cAAsB,EACtBiE,UAAkB,EAClBC,OAIC,GAAG,CAAC,CAAC,EACW;IACjB,IAAI;MACFjE,OAAO,CAACC,GAAG,CAAC,qDAAqDF,cAAc,KAAK,CAAC;;MAErF;MACA,MAAM;QACJmE,eAAe,GAAG,KAAK;QACvBC,cAAc,GAAG,IAAI;QACrBC,OAAO,GAAG;MACZ,CAAC,GAAGH,OAAO;;MAEX;MACA,IAAI,CAAC,IAAI,CAACpE,WAAW,CAACgC,QAAQ,CAAC9B,cAAc,CAAC,EAAE;QAC9C,MAAM,IAAIsE,KAAK,CAAC,iBAAiBtE,cAAc,oBAAoB,CAAC;MACtE;;MAEA;MACA,MAAMuE,KAAK,GAAGN,UAAU,CAAClB,KAAK,CAAC,IAAI,CAAC;MACpC,IAAIwB,KAAK,CAACvC,MAAM,GAAG,CAAC,EAAE;QACpB,MAAM,IAAIsC,KAAK,CAAC,0DAA0D,CAAC;MAC7E;;MAEA;MACA,MAAMhD,OAAO,GAAG,IAAI,CAACkD,YAAY,CAACD,KAAK,CAAC,CAAC,CAAC,CAAC;;MAE3C;MACA,MAAMlE,SAAgC,GAAG,EAAE;MAE3C,KAAK,IAAIoE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,KAAK,CAACvC,MAAM,EAAEyC,CAAC,EAAE,EAAE;QACrC,MAAMC,IAAI,GAAGH,KAAK,CAACE,CAAC,CAAC,CAACE,IAAI,CAAC,CAAC;QAC5B,IAAI,CAACD,IAAI,EAAE;QAEX,MAAME,MAAM,GAAG,IAAI,CAACJ,YAAY,CAACE,IAAI,CAAC;QACtC,IAAIE,MAAM,CAAC5C,MAAM,KAAKV,OAAO,CAACU,MAAM,EAAE;UACpC/B,OAAO,CAAC4E,IAAI,CAAC,YAAYJ,CAAC,GAAG,CAAC,uCAAuC,CAAC;UACtE;QACF;QAEA,MAAMhF,GAAwB,GAAG,CAAC,CAAC;QAEnC,KAAK,IAAIqF,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGxD,OAAO,CAACU,MAAM,EAAE8C,CAAC,EAAE,EAAE;UACvC,MAAMlD,MAAM,GAAGN,OAAO,CAACwD,CAAC,CAAC;UACzB,IAAIhE,KAAU,GAAG8D,MAAM,CAACE,CAAC,CAAC;;UAE1B;UACA,IAAIhE,KAAK,KAAK,MAAM,EAAEA,KAAK,GAAG,IAAI,CAAC,KAC9B,IAAIA,KAAK,KAAK,OAAO,EAAEA,KAAK,GAAG,KAAK,CAAC,KACrC,IAAI,CAACiE,KAAK,CAACC,MAAM,CAAClE,KAAK,CAAC,CAAC,IAAIA,KAAK,KAAK,EAAE,EAAEA,KAAK,GAAGkE,MAAM,CAAClE,KAAK,CAAC,CAAC,KACjE,IAAI,OAAOA,KAAK,KAAK,QAAQ,KAAKA,KAAK,CAACmE,KAAK,CAAC,sCAAsC,CAAC,IAAInE,KAAK,CAACmE,KAAK,CAAC,oBAAoB,CAAC,CAAC,EAAE;YAChI;YACA,IAAI;cACFnE,KAAK,GAAGtB,SAAS,CAAC0F,QAAQ,CAAC,IAAIpC,IAAI,CAAChC,KAAK,CAAC,CAAC;YAC7C,CAAC,CAAC,OAAOqE,CAAC,EAAE;cACVlF,OAAO,CAAC4E,IAAI,CAAC,uCAAuC/D,KAAK,EAAE,CAAC;YAC9D;UACF;UAEArB,GAAG,CAACmC,MAAM,CAAC,GAAGd,KAAK;QACrB;QAEAT,SAAS,CAAC+E,IAAI,CAAC3F,GAAG,CAAC;MACrB;;MAEA;MACA,IAAI0E,eAAe,EAAE;QACnB,MAAM,IAAI,CAACA,eAAe,CAACnE,cAAc,CAAC;MAC5C;;MAEA;MACA,MAAMqF,cAAc,GAAGhF,SAAS,CAAC2B,MAAM;MACvC,IAAIsD,cAAc,GAAG,CAAC;MACtB,IAAIC,aAAa,GAAG,CAAC;MAErB,OAAOD,cAAc,GAAGD,cAAc,EAAE;QACtC;QACA,MAAMG,KAAK,GAAG9F,UAAU,CAACL,EAAE,CAAC;QAC5B,MAAMoG,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,GAAG,EAAEN,cAAc,GAAGC,cAAc,CAAC;;QAEhE;QACA,KAAK,IAAIb,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGgB,SAAS,EAAEhB,CAAC,EAAE,EAAE;UAClC,MAAM9B,QAAQ,GAAGtC,SAAS,CAACiF,cAAc,GAAGb,CAAC,CAAC;UAC9C,MAAMmB,KAAK,GAAGjD,QAAQ,CAAC0B,OAAO,CAAC;UAE/B,IAAIuB,KAAK,IAAIxB,cAAc,EAAE;YAC3B;YACA,MAAMyB,MAAM,GAAGpG,GAAG,CAACJ,EAAE,EAAEW,cAAc,EAAE4F,KAAK,CAAC;YAC7CJ,KAAK,CAACM,GAAG,CAACD,MAAM,EAAElD,QAAQ,CAAC;UAC7B,CAAC,MAAM;YACL;YACA,MAAMoD,aAAa,GAAGzG,UAAU,CAACD,EAAE,EAAEW,cAAc,CAAC;YACpD,MAAMgG,SAAS,GAAGvG,GAAG,CAACsG,aAAa,CAAC;YACpCP,KAAK,CAACM,GAAG,CAACE,SAAS,EAAErD,QAAQ,CAAC;UAChC;UAEA4C,aAAa,EAAE;QACjB;;QAEA;QACA,MAAMC,KAAK,CAACS,MAAM,CAAC,CAAC;QACpBX,cAAc,IAAIG,SAAS;QAC3BxF,OAAO,CAACC,GAAG,CAAC,YAAYuF,SAAS,wBAAwBH,cAAc,IAAID,cAAc,GAAG,CAAC;MAC/F;MAEApF,OAAO,CAACC,GAAG,CAAC,2BAA2BqF,aAAa,0CAA0CvF,cAAc,EAAE,CAAC;MAC/G,OAAOuF,aAAa;IACtB,CAAC,CAAC,OAAOtD,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,iDAAiD,EAAEA,KAAK,CAAC;MACvE,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;EACE,MAAMiE,sBAAsBA,CAC1BlG,cAAsB,EACtBmG,QAAe,EACfjC,OAIC,GAAG,CAAC,CAAC,EACW;IACjB,IAAI;MACFjE,OAAO,CAACC,GAAG,CAAC,sDAAsDF,cAAc,KAAK,CAAC;;MAEtF;MACA,MAAM;QACJmE,eAAe,GAAG,KAAK;QACvBC,cAAc,GAAG,IAAI;QACrBC,OAAO,GAAG;MACZ,CAAC,GAAGH,OAAO;;MAEX;MACA,IAAI,CAAC,IAAI,CAACpE,WAAW,CAACgC,QAAQ,CAAC9B,cAAc,CAAC,EAAE;QAC9C,MAAM,IAAIsE,KAAK,CAAC,iBAAiBtE,cAAc,oBAAoB,CAAC;MACtE;;MAEA;MACA,IAAI,CAACuB,KAAK,CAAC6E,OAAO,CAACD,QAAQ,CAAC,EAAE;QAC5B,MAAM,IAAI7B,KAAK,CAAC,qDAAqD,CAAC;MACxE;;MAEA;MACA,MAAMjE,SAAS,GAAG8F,QAAQ,CAAC5F,GAAG,CAACd,GAAG,IAAI;QACpC,MAAM4G,YAAiC,GAAG,CAAC,CAAC;QAE5C3F,MAAM,CAACC,OAAO,CAAClB,GAAG,CAAC,CAACmB,OAAO,CAAC,CAAC,CAACC,GAAG,EAAEC,KAAK,CAAC,KAAK;UAC5C,IAAI,OAAOA,KAAK,KAAK,QAAQ,KAAKA,KAAK,CAACmE,KAAK,CAAC,sCAAsC,CAAC,IAAInE,KAAK,CAACmE,KAAK,CAAC,oBAAoB,CAAC,CAAC,EAAE;YAC3H;YACA,IAAI;cACFoB,YAAY,CAACxF,GAAG,CAAC,GAAGrB,SAAS,CAAC0F,QAAQ,CAAC,IAAIpC,IAAI,CAAChC,KAAK,CAAC,CAAC;YACzD,CAAC,CAAC,OAAOqE,CAAC,EAAE;cACVlF,OAAO,CAAC4E,IAAI,CAAC,uCAAuC/D,KAAK,EAAE,CAAC;cAC5DuF,YAAY,CAACxF,GAAG,CAAC,GAAGC,KAAK;YAC3B;UACF,CAAC,MAAM;YACLuF,YAAY,CAACxF,GAAG,CAAC,GAAGC,KAAK;UAC3B;QACF,CAAC,CAAC;QAEF,OAAOuF,YAAY;MACrB,CAAC,CAAC;;MAEF;MACA,IAAIlC,eAAe,EAAE;QACnB,MAAM,IAAI,CAACA,eAAe,CAACnE,cAAc,CAAC;MAC5C;;MAEA;MACA,MAAMqF,cAAc,GAAGhF,SAAS,CAAC2B,MAAM;MACvC,IAAIsD,cAAc,GAAG,CAAC;MACtB,IAAIC,aAAa,GAAG,CAAC;MAErB,OAAOD,cAAc,GAAGD,cAAc,EAAE;QACtC;QACA,MAAMG,KAAK,GAAG9F,UAAU,CAACL,EAAE,CAAC;QAC5B,MAAMoG,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,GAAG,EAAEN,cAAc,GAAGC,cAAc,CAAC;;QAEhE;QACA,KAAK,IAAIb,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGgB,SAAS,EAAEhB,CAAC,EAAE,EAAE;UAClC,MAAM9B,QAAQ,GAAGtC,SAAS,CAACiF,cAAc,GAAGb,CAAC,CAAC;UAC9C,MAAMmB,KAAK,GAAGjD,QAAQ,CAAC0B,OAAO,CAAC;UAE/B,IAAIuB,KAAK,IAAIxB,cAAc,EAAE;YAC3B;YACA,MAAMyB,MAAM,GAAGpG,GAAG,CAACJ,EAAE,EAAEW,cAAc,EAAE4F,KAAK,CAAC;YAC7CJ,KAAK,CAACM,GAAG,CAACD,MAAM,EAAElD,QAAQ,CAAC;UAC7B,CAAC,MAAM;YACL;YACA,MAAMoD,aAAa,GAAGzG,UAAU,CAACD,EAAE,EAAEW,cAAc,CAAC;YACpD,MAAMgG,SAAS,GAAGvG,GAAG,CAACsG,aAAa,CAAC;YACpCP,KAAK,CAACM,GAAG,CAACE,SAAS,EAAErD,QAAQ,CAAC;UAChC;UAEA4C,aAAa,EAAE;QACjB;;QAEA;QACA,MAAMC,KAAK,CAACS,MAAM,CAAC,CAAC;QACpBX,cAAc,IAAIG,SAAS;QAC3BxF,OAAO,CAACC,GAAG,CAAC,YAAYuF,SAAS,wBAAwBH,cAAc,IAAID,cAAc,GAAG,CAAC;MAC/F;MAEApF,OAAO,CAACC,GAAG,CAAC,2BAA2BqF,aAAa,0CAA0CvF,cAAc,EAAE,CAAC;MAC/G,OAAOuF,aAAa;IACtB,CAAC,CAAC,OAAOtD,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,kDAAkD,EAAEA,KAAK,CAAC;MACxE,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;EACE,MAAMqE,aAAaA,CACjBC,UAAuB,EACvBrC,OAIC,GAAG,CAAC,CAAC,EAC2B;IACjC,IAAI;MACFjE,OAAO,CAACC,GAAG,CAAC,qDAAqD,CAAC;MAElE,MAAM0D,GAAG,GAAG,IAAIjE,KAAK,CAAC,CAAC;MACvB,MAAMiE,GAAG,CAAC4C,SAAS,CAACD,UAAU,CAAC;MAE/B,MAAME,OAA+B,GAAG,CAAC,CAAC;;MAE1C;MACA,KAAK,MAAMC,QAAQ,IAAI9C,GAAG,CAAC+C,KAAK,EAAE;QAAA,IAAAC,mBAAA;QAChC,IAAIhD,GAAG,CAAC+C,KAAK,CAACD,QAAQ,CAAC,CAACG,GAAG,EAAE;QAE7B,MAAMC,OAAO,IAAAF,mBAAA,GAAGF,QAAQ,CAAC3D,KAAK,CAAC,GAAG,CAAC,CAACgE,GAAG,CAAC,CAAC,cAAAH,mBAAA,uBAAzBA,mBAAA,CAA2BI,WAAW,CAAC,CAAC;QACxD,MAAMhH,cAAc,GAAG0G,QAAQ,CAAC3D,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QAE7C,IAAI,CAAC,IAAI,CAACjD,WAAW,CAACgC,QAAQ,CAAC9B,cAAc,CAAC,EAAE;UAC9CC,OAAO,CAAC4E,IAAI,CAAC,mCAAmC7E,cAAc,EAAE,CAAC;UACjE;QACF;QAEA,MAAMiH,WAAW,GAAG,MAAMrD,GAAG,CAAC+C,KAAK,CAACD,QAAQ,CAAC,CAACQ,KAAK,CAAC,QAAQ,CAAC;QAE7D,IAAIJ,OAAO,KAAK,MAAM,EAAE;UACtB,IAAI;YACF,MAAMX,QAAQ,GAAG5C,IAAI,CAAC4D,KAAK,CAACF,WAAW,CAAC;YACxC,MAAMG,KAAK,GAAG,MAAM,IAAI,CAAClB,sBAAsB,CAAClG,cAAc,EAAEmG,QAAQ,EAAEjC,OAAO,CAAC;YAClFuC,OAAO,CAACzG,cAAc,CAAC,GAAGoH,KAAK;UACjC,CAAC,CAAC,OAAOjC,CAAC,EAAE;YACVlF,OAAO,CAACgC,KAAK,CAAC,kDAAkDyE,QAAQ,GAAG,EAAEvB,CAAC,CAAC;UACjF;QACF,CAAC,MAAM,IAAI2B,OAAO,KAAK,KAAK,EAAE;UAC5B,IAAI;YACF,MAAMM,KAAK,GAAG,MAAM,IAAI,CAACpD,qBAAqB,CAAChE,cAAc,EAAEiH,WAAW,EAAE/C,OAAO,CAAC;YACpFuC,OAAO,CAACzG,cAAc,CAAC,GAAGoH,KAAK;UACjC,CAAC,CAAC,OAAOjC,CAAC,EAAE;YACVlF,OAAO,CAACgC,KAAK,CAAC,iDAAiDyE,QAAQ,GAAG,EAAEvB,CAAC,CAAC;UAChF;QACF,CAAC,MAAM;UACLlF,OAAO,CAAC4E,IAAI,CAAC,0CAA0CiC,OAAO,EAAE,CAAC;QACnE;MACF;MAEA7G,OAAO,CAACC,GAAG,CAAC,oCAAoC,EAAEuG,OAAO,CAAC;MAC1D,OAAOA,OAAO;IAChB,CAAC,CAAC,OAAOxE,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,wDAAwD,EAAEA,KAAK,CAAC;MAC9E,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;EACE,MAAckC,eAAeA,CAACnE,cAAsB,EAAiB;IACnE,IAAI;MACFC,OAAO,CAACC,GAAG,CAAC,6DAA6DF,cAAc,KAAK,CAAC;MAE7F,MAAM+F,aAAa,GAAGzG,UAAU,CAACD,EAAE,EAAEW,cAAc,CAAC;MACpD,MAAMqH,QAAQ,GAAG,MAAM9H,OAAO,CAACwG,aAAa,CAAC;MAE7C,IAAIsB,QAAQ,CAACjH,KAAK,EAAE;QAClBH,OAAO,CAACC,GAAG,CAAC,oBAAoBF,cAAc,iBAAiB,CAAC;QAChE;MACF;;MAEA;MACA,MAAMK,SAAS,GAAGgH,QAAQ,CAAC/G,IAAI;MAC/B,MAAM+E,cAAc,GAAGhF,SAAS,CAAC2B,MAAM;MACvC,IAAIsD,cAAc,GAAG,CAAC;MAEtB,OAAOA,cAAc,GAAGD,cAAc,EAAE;QACtC;QACA,MAAMG,KAAK,GAAG9F,UAAU,CAACL,EAAE,CAAC;QAC5B,MAAMoG,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,GAAG,EAAEN,cAAc,GAAGC,cAAc,CAAC;;QAEhE;QACA,KAAK,IAAIb,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGgB,SAAS,EAAEhB,CAAC,EAAE,EAAE;UAClC,MAAM9B,QAAQ,GAAGtC,SAAS,CAACiF,cAAc,GAAGb,CAAC,CAAC;UAC9Ce,KAAK,CAAC8B,MAAM,CAAC7H,GAAG,CAACJ,EAAE,EAAEW,cAAc,EAAE2C,QAAQ,CAAC1B,EAAE,CAAC,CAAC;QACpD;;QAEA;QACA,MAAMuE,KAAK,CAACS,MAAM,CAAC,CAAC;QACpBX,cAAc,IAAIG,SAAS;QAC3BxF,OAAO,CAACC,GAAG,CAAC,YAAYuF,SAAS,yBAAyBH,cAAc,IAAID,cAAc,GAAG,CAAC;MAChG;MAEApF,OAAO,CAACC,GAAG,CAAC,gBAAgBF,cAAc,qBAAqB,CAAC;IAClE,CAAC,CAAC,OAAOiC,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,gDAAgD,EAAEA,KAAK,CAAC;MACtE,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;EACUuC,YAAYA,CAACE,IAAY,EAAY;IAC3C;IACA,IAAI,CAACA,IAAI,IAAIA,IAAI,CAACC,IAAI,CAAC,CAAC,KAAK,EAAE,EAAE;MAC/B,OAAO,EAAE;IACX;;IAEA;IACA,IAAI4C,WAAW,GAAG7C,IAAI,CAAC3C,OAAO,CAAC,IAAI,EAAE,EAAE,CAAC;IACxCwF,WAAW,GAAGA,WAAW,CAACxF,OAAO,CAAC,IAAI,EAAE,EAAE,CAAC;;IAE3C;IACA,IAAIyF,SAAS,GAAG,GAAG,CAAC,CAAC;IACrB,MAAMC,QAAQ,GAAG,CAACF,WAAW,CAACtC,KAAK,CAAC,KAAK,CAAC,IAAI,EAAE,EAAEjD,MAAM;IACxD,MAAM0F,cAAc,GAAG,CAACH,WAAW,CAACtC,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,EAAEjD,MAAM;IAC7D,MAAM2F,UAAU,GAAG,CAACJ,WAAW,CAACtC,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,EAAEjD,MAAM;IAEzD,IAAIyF,QAAQ,GAAG,CAAC,IAAIA,QAAQ,IAAIC,cAAc,IAAID,QAAQ,IAAIE,UAAU,EAAE;MACxEH,SAAS,GAAG,IAAI;IAClB,CAAC,MAAM,IAAIG,UAAU,GAAGD,cAAc,EAAE;MACtCF,SAAS,GAAG,GAAG;IACjB;;IAEA;IACA,MAAM5C,MAAM,GAAG2C,WAAW,CAACxE,KAAK,CAACyE,SAAS,CAAC,CAACjH,GAAG,CAACO,KAAK,IAAI;MACvD;MACA,IAAI8G,UAAU,GAAG9G,KAAK,CAAC6D,IAAI,CAAC,CAAC;;MAE7B;MACA,IAAIiD,UAAU,CAACC,UAAU,CAAC,GAAG,CAAC,IAAID,UAAU,CAACE,QAAQ,CAAC,GAAG,CAAC,EAAE;QAC1DF,UAAU,GAAGA,UAAU,CAACG,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;MACtC;;MAEA;MACAH,UAAU,GAAGA,UAAU,CAAC7F,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC;MAE3C,OAAO6F,UAAU;IACnB,CAAC,CAAC;;IAEF;IACA3H,OAAO,CAACC,GAAG,CAAC,oBAAoBqH,WAAW,GAAG,CAAC;IAC/CtH,OAAO,CAACC,GAAG,CAAC,sBAAsBqD,IAAI,CAACC,SAAS,CAACoB,MAAM,CAAC,EAAE,CAAC;IAE3D,OAAOA,MAAM;EACf;;EAEA;AACF;AACA;AACA;AACA;EACUoD,iBAAiBA,CAACC,IAAY,EAAU;IAC9C,IAAI,CAACA,IAAI,EAAE,OAAO,EAAE;;IAEpB;IACA,IAAIC,MAAM,GAAGD,IAAI,CAAClG,OAAO,CAAC,OAAO,EAAE,EAAE,CAAC;;IAEtC;IACA,MAAMoG,YAAoC,GAAG;MAC3C,KAAK,EAAE,MAAM;MACb,MAAM,EAAE,MAAM;MACd,MAAM,EAAE,MAAM;MACd,QAAQ,EAAE,SAAS;MACnB,SAAS,EAAE,SAAS;MACpB,SAAS,EAAE,SAAS;MACpB,WAAW,EAAE,YAAY;MACzB,YAAY,EAAE,YAAY;MAC1B,SAAS,EAAE,WAAW;MACtB,WAAW,EAAE,WAAW;MACxB,YAAY,EAAE,aAAa;MAC3B,aAAa,EAAE;IACjB,CAAC;;IAED;IACAzH,MAAM,CAACC,OAAO,CAACwH,YAAY,CAAC,CAACvH,OAAO,CAAC,CAAC,CAACwH,OAAO,EAAEC,WAAW,CAAC,KAAK;MAC/DH,MAAM,GAAGA,MAAM,CAACnG,OAAO,CAAC,IAAIuG,MAAM,CAACF,OAAO,EAAE,GAAG,CAAC,EAAEC,WAAW,CAAC;IAChE,CAAC,CAAC;IAEF,OAAOH,MAAM;EACf;;EAEA;AACF;AACA;AACA;AACA;EACUK,qBAAqBA,CAACzE,OAAe,EAAU;IACrD,IAAI,CAACA,OAAO,EAAE,OAAO,EAAE;IAEvB7D,OAAO,CAACC,GAAG,CAAC,4CAA4C,CAAC;;IAEzD;IACA4D,OAAO,GAAGA,OAAO,CAAC/B,OAAO,CAAC,IAAI,EAAE,EAAE,CAAC;;IAEnC;IACA,MAAMwC,KAAK,GAAGT,OAAO,CAACf,KAAK,CAAC,OAAO,CAAC;IACpC,MAAMyF,eAAe,GAAGjE,KAAK,CAAChE,GAAG,CAACmE,IAAI,IAAI;MACxC;MACA,OAAO,IAAI,CAACsD,iBAAiB,CAACtD,IAAI,CAAC;IACrC,CAAC,CAAC;IAEF,OAAO8D,eAAe,CAAC9G,IAAI,CAAC,IAAI,CAAC;EACnC;;EAEA;AACF;AACA;AACA;AACA;EACU+G,oBAAoBA,CAAC3E,OAAe,EAAU;IACpD,IAAI,CAACA,OAAO,EAAE,OAAO,EAAE;IAEvB7D,OAAO,CAACC,GAAG,CAAC,2CAA2C,CAAC;;IAExD;IACA,IAAI4D,OAAO,CAAC4E,UAAU,CAAC,CAAC,CAAC,KAAK,MAAM,EAAE;MACpCzI,OAAO,CAACC,GAAG,CAAC,mCAAmC,CAAC;MAChD4D,OAAO,GAAGA,OAAO,CAACiE,KAAK,CAAC,CAAC,CAAC;IAC5B;;IAEA;IACA,IAAIjE,OAAO,CAAChC,QAAQ,CAAC,GAAG,CAAC,EAAE;MACzB7B,OAAO,CAACC,GAAG,CAAC,yCAAyC,CAAC;MACtD4D,OAAO,GAAGA,OAAO,CAAC/B,OAAO,CAAC,IAAI,EAAE,EAAE,CAAC;IACrC;;IAEA;IACA,MAAM4G,8BAA8B,GAClC7E,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC;IAAI;IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC;;IAE1B,IAAI6G,8BAA8B,EAAE;MAClC1I,OAAO,CAACC,GAAG,CAAC,2DAA2D,CAAC;;MAExE;MACA4D,OAAO,GAAGA,OAAO,CACd/B,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC,CACnBA,OAAO,CAAC,QAAQ,EAAE,MAAM,CAAC,CACzBA,OAAO,CAAC,WAAW,EAAE,SAAS,CAAC,CAC/BA,OAAO,CAAC,yBAAyB,EAAE,uBAAuB,CAAC,CAC3DA,OAAO,CAAC,cAAc,EAAE,WAAW,CAAC,CACpCA,OAAO,CAAC,eAAe,EAAE,aAAa,CAAC;IAC5C;;IAEA;IACA,MAAM6G,iBAAiB,GACrB9E,OAAO,CAAChC,QAAQ,CAAC,KAAK,CAAC,IACvBgC,OAAO,CAAChC,QAAQ,CAAC,QAAQ,CAAC,IAC1BgC,OAAO,CAAChC,QAAQ,CAAC,WAAW,CAAC;IAE/B,IAAI8G,iBAAiB,EAAE;MACrB3I,OAAO,CAACC,GAAG,CAAC,wDAAwD,CAAC;;MAErE;MACA4D,OAAO,GAAGA,OAAO,CACd/B,OAAO,CAAC,MAAM,EAAE,MAAM,CAAC,CACvBA,OAAO,CAAC,SAAS,EAAE,SAAS,CAAC,CAC7BA,OAAO,CAAC,uBAAuB,EAAE,uBAAuB,CAAC,CACzDA,OAAO,CAAC,YAAY,EAAE,YAAY,CAAC,CACnCA,OAAO,CAAC,UAAU,EAAE,WAAW,CAAC,CAChCA,OAAO,CAAC,aAAa,EAAE,aAAa,CAAC;IAC1C;IAEA,OAAO+B,OAAO;EAChB;;EAEA;AACF;AACA;AACA;AACA;AACA;EACE,MAAc+E,kBAAkBA,CAC9BC,UAAkB,EAClB5E,OAIC,GAAG,CAAC,CAAC,EACW;IACjB,IAAI;MACFjE,OAAO,CAACC,GAAG,CAAC,2CAA2C,CAAC;;MAExD;MACA,IAAI6I,iBAAiB,GAAG,IAAI,CAACN,oBAAoB,CAACK,UAAU,CAAC;;MAE7D;MACAC,iBAAiB,GAAG,IAAI,CAACR,qBAAqB,CAACQ,iBAAiB,CAAC;;MAEjE;MACA,MAAMxE,KAAK,GAAGwE,iBAAiB,CAAChG,KAAK,CAAC,IAAI,CAAC,CAACxC,GAAG,CAACmE,IAAI,IAAIA,IAAI,CAACC,IAAI,CAAC,CAAC,CAAC,CAACqE,MAAM,CAACtE,IAAI,IAAIA,IAAI,KAAK,EAAE,CAAC;MAEhG,IAAIH,KAAK,CAACvC,MAAM,KAAK,CAAC,EAAE;QACtB,MAAM,IAAIsC,KAAK,CAAC,sBAAsB,CAAC;MACzC;MAEA,MAAM2E,SAAS,GAAG1E,KAAK,CAAC,CAAC,CAAC;MAE1B,IAAI,CAAC0E,SAAS,EAAE;QACd,MAAM,IAAI3E,KAAK,CAAC,wCAAwC,CAAC;MAC3D;MAEArE,OAAO,CAACC,GAAG,CAAC,gCAAgC,EAAE+I,SAAS,CAAC;;MAExD;MACA,MAAMxB,QAAQ,GAAG,CAACwB,SAAS,CAAChE,KAAK,CAAC,KAAK,CAAC,IAAI,EAAE,EAAEjD,MAAM;MACtD,MAAM0F,cAAc,GAAG,CAACuB,SAAS,CAAChE,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,EAAEjD,MAAM;MAC3D,MAAM2F,UAAU,GAAG,CAACsB,SAAS,CAAChE,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,EAAEjD,MAAM;MAEvD/B,OAAO,CAACC,GAAG,CAAC,uCAAuCuH,QAAQ,sBAAsBC,cAAc,eAAeC,UAAU,EAAE,CAAC;;MAE3H;MACA1H,OAAO,CAACC,GAAG,CAAC,yCAAyC,CAAC;MACtD,KAAK,IAAIuE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGiB,IAAI,CAACC,GAAG,CAAC,CAAC,EAAEpB,KAAK,CAACvC,MAAM,CAAC,EAAEyC,CAAC,EAAE,EAAE;QAClDxE,OAAO,CAACC,GAAG,CAAC,SAASuE,CAAC,KAAKF,KAAK,CAACE,CAAC,CAAC,EAAE,CAAC;MACxC;;MAEA;MACA,IAAI+C,SAAS,GAAG,IAAI;MAEpB,IAAIC,QAAQ,GAAG,CAAC,EAAE;QAChBD,SAAS,GAAG,IAAI;QAChBvH,OAAO,CAACC,GAAG,CAAC,yCAAyC,CAAC;MACxD,CAAC,MAAM,IAAIwH,cAAc,GAAG,CAAC,IAAIA,cAAc,IAAIC,UAAU,EAAE;QAC7DH,SAAS,GAAG,GAAG;QACfvH,OAAO,CAACC,GAAG,CAAC,4CAA4C,CAAC;MAC3D,CAAC,MAAM,IAAIyH,UAAU,GAAG,CAAC,EAAE;QACzBH,SAAS,GAAG,GAAG;QACfvH,OAAO,CAACC,GAAG,CAAC,sCAAsC,CAAC;MACrD,CAAC,MAAM;QACLD,OAAO,CAACC,GAAG,CAAC,gGAAgG,CAAC;MAC/G;;MAEA;MACA,MAAMgJ,aAAa,GAAG3E,KAAK,CAAChE,GAAG,CAACmE,IAAI,IAAI;QACtC,IAAI,CAACA,IAAI,EAAE,OAAO,EAAE;;QAEpB;QACA,IAAI8C,SAAS,KAAK,GAAG,EAAE;UACrB;UACA,MAAM5C,MAAM,GAAG,IAAI,CAACJ,YAAY,CAACE,IAAI,CAAC;UACtC,OAAOE,MAAM,CAACrE,GAAG,CAACO,KAAK,IAAI;YACzB;YACA,IAAIA,KAAK,CAACgB,QAAQ,CAAC,GAAG,CAAC,EAAE;cACvB,OAAO,IAAIhB,KAAK,CAACiB,OAAO,CAAC,IAAI,EAAE,IAAI,CAAC,GAAG;YACzC;YACA,OAAOjB,KAAK;UACd,CAAC,CAAC,CAACY,IAAI,CAAC,GAAG,CAAC;QACd;QAEA,OAAOgD,IAAI;MACb,CAAC,CAAC,CAAChD,IAAI,CAAC,IAAI,CAAC;;MAEb;MACA,MAAM8G,eAAe,GAAGU,aAAa,CAACnG,KAAK,CAAC,IAAI,CAAC;MACjD,IAAIyF,eAAe,CAACxG,MAAM,GAAG,CAAC,EAAE;QAC9B,MAAM,IAAIsC,KAAK,CAAC,wCAAwC,CAAC;MAC3D;;MAEA;MACA,MAAMhD,OAAO,GAAG,IAAI,CAACkD,YAAY,CAACgE,eAAe,CAAC,CAAC,CAAC,CAAC;;MAErD;MACA,IAAIlH,OAAO,CAACU,MAAM,GAAG,CAAC,EAAE;QACtB,MAAM,IAAIsC,KAAK,CAAC,8BAA8BhD,OAAO,CAACU,MAAM,gJAAgJ,CAAC;MAC/M;MAEA/B,OAAO,CAACC,GAAG,CAAC,wCAAwC,EAAEoB,OAAO,CAAC;;MAE9D;MACA,OAAO,IAAI,CAAC6H,kBAAkB,CAAC7H,OAAO,EAAEkH,eAAe,EAAEtE,OAAO,CAAC;IACnE,CAAC,CAAC,OAAOjC,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,uDAAuD,EAAEA,KAAK,CAAC;MAC7E,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;EACUmH,aAAaA,CAACtF,OAAe,EAAE4C,QAAgB,GAAG,SAAS,EAAQ;IACzEzG,OAAO,CAACoJ,KAAK,CAAC,gDAAgD3C,QAAQ,EAAE,CAAC;IAEzE,IAAI;MACF;MACAzG,OAAO,CAACC,GAAG,CAAC,sBAAsB4D,OAAO,CAAC9B,MAAM,aAAa,CAAC;MAC9D/B,OAAO,CAACC,GAAG,CAAC,oBAAoBwG,QAAQ,CAACoB,QAAQ,CAAC,MAAM,CAAC,GAAG,KAAK,GAAG,KAAK,EAAE,CAAC;;MAE5E;MACA,MAAMwB,MAAM,GAAGxF,OAAO,CAAC4E,UAAU,CAAC,CAAC,CAAC,KAAK,MAAM;MAC/CzI,OAAO,CAACC,GAAG,CAAC,sBAAsBoJ,MAAM,GAAG,KAAK,GAAG,KAAK,EAAE,CAAC;;MAE3D;MACA,MAAM/E,KAAK,GAAGT,OAAO,CAACf,KAAK,CAAC,IAAI,CAAC;MACjC9C,OAAO,CAACC,GAAG,CAAC,qBAAqBqE,KAAK,CAACvC,MAAM,EAAE,CAAC;MAEhD,IAAIuC,KAAK,CAACvC,MAAM,GAAG,CAAC,EAAE;QACpB;QACA,MAAMiH,SAAS,GAAG1E,KAAK,CAAC,CAAC,CAAC,CAACI,IAAI,CAAC,CAAC;QACjC1E,OAAO,CAACC,GAAG,CAAC,mBAAmB+I,SAAS,CAACjH,MAAM,iBAAiBiH,SAAS,CAACM,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAGN,SAAS,CAACjH,MAAM,GAAG,GAAG,GAAG,KAAK,GAAG,EAAE,EAAE,CAAC;;QAEpI;QACA,MAAMyF,QAAQ,GAAG,CAACwB,SAAS,CAAChE,KAAK,CAAC,KAAK,CAAC,IAAI,EAAE,EAAEjD,MAAM;QACtD,MAAM0F,cAAc,GAAG,CAACuB,SAAS,CAAChE,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,EAAEjD,MAAM;QAC3D,MAAM2F,UAAU,GAAG,CAACsB,SAAS,CAAChE,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,EAAEjD,MAAM;QAEvD/B,OAAO,CAACC,GAAG,CAAC,uCAAuCuH,QAAQ,sBAAsBC,cAAc,eAAeC,UAAU,EAAE,CAAC;;QAE3H;QACA,IAAI6B,iBAAiB,GAAG,GAAG;QAC3B,IAAI/B,QAAQ,GAAG,CAAC,IAAIA,QAAQ,IAAIC,cAAc,IAAID,QAAQ,IAAIE,UAAU,EAAE;UACxE6B,iBAAiB,GAAG,IAAI;QAC1B,CAAC,MAAM,IAAI9B,cAAc,GAAG,CAAC,IAAIA,cAAc,IAAIC,UAAU,EAAE;UAC7D6B,iBAAiB,GAAG,GAAG;QACzB;QAEAvJ,OAAO,CAACC,GAAG,CAAC,gCAAgCsJ,iBAAiB,KAAK,IAAI,GAAG,YAAY,GAAGA,iBAAiB,EAAE,CAAC;;QAE5G;QACA,MAAMC,gBAAgB,GAAGD,iBAAiB,KAAK,IAAI,GAC/C/B,QAAQ,GAAG,CAAC,GACX+B,iBAAiB,KAAK,GAAG,GAAG9B,cAAc,GAAG,CAAC,GAAGC,UAAU,GAAG,CAAE;QAErE1H,OAAO,CAACC,GAAG,CAAC,8BAA8BuJ,gBAAgB,EAAE,CAAC;;QAE7D;QACA,IAAIlF,KAAK,CAACvC,MAAM,GAAG,CAAC,EAAE;UACpB,MAAM0H,UAAU,GAAGnF,KAAK,CAAC,CAAC,CAAC,CAACI,IAAI,CAAC,CAAC;UAClC,MAAMgF,kBAAkB,GAAG,CAACD,UAAU,CAACzE,KAAK,CAAC,KAAK,CAAC,IAAI,EAAE,EAAEjD,MAAM;UACjE,MAAM4H,wBAAwB,GAAG,CAACF,UAAU,CAACzE,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,EAAEjD,MAAM;UACtE,MAAM6H,oBAAoB,GAAG,CAACH,UAAU,CAACzE,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,EAAEjD,MAAM;UAElE,MAAM8H,iBAAiB,GAAGN,iBAAiB,KAAK,IAAI,GAChDG,kBAAkB,GAAG,CAAC,GACrBH,iBAAiB,KAAK,GAAG,GAAGI,wBAAwB,GAAG,CAAC,GAAGC,oBAAoB,GAAG,CAAE;UAEzF5J,OAAO,CAACC,GAAG,CAAC,8CAA8C4J,iBAAiB,EAAE,CAAC;UAC9E7J,OAAO,CAACC,GAAG,CAAC,2BAA2BuJ,gBAAgB,KAAKK,iBAAiB,GAAG,IAAI,GAAG,UAAU,EAAE,CAAC;QACtG;;QAEA;QACA,MAAMC,YAAY,GAAG,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC;QACtF,MAAMC,iBAAiB,GAAGD,YAAY,CAACf,MAAM,CAACiB,IAAI,IAAInG,OAAO,CAAChC,QAAQ,CAACmI,IAAI,CAAC,CAAC;QAE7EhK,OAAO,CAACC,GAAG,CAAC,6CAA6C8J,iBAAiB,CAAChI,MAAM,GAAG,CAAC,GAAGgI,iBAAiB,CAACtI,IAAI,CAAC,IAAI,CAAC,GAAG,OAAO,EAAE,CAAC;;QAEjI;QACA,MAAMwI,YAAY,GAAG,CAAC,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,CAAC;QACnG,MAAMC,iBAAiB,GAAGD,YAAY,CAAClB,MAAM,CAACoB,GAAG,IAAItG,OAAO,CAAChC,QAAQ,CAACsI,GAAG,CAAC,CAAC;QAE3EnK,OAAO,CAACC,GAAG,CAAC,qCAAqCiK,iBAAiB,CAACnI,MAAM,GAAG,CAAC,GAAGmI,iBAAiB,CAACzI,IAAI,CAAC,IAAI,CAAC,GAAG,QAAQ,EAAE,CAAC;;QAE1H;QACA,MAAM2I,gBAAgB,GAAG,CAAC,KAAK,EAAE,QAAQ,EAAE,WAAW,CAAC;QACvD,MAAMC,qBAAqB,GAAGD,gBAAgB,CAACrB,MAAM,CAACiB,IAAI,IAAInG,OAAO,CAAChC,QAAQ,CAACmI,IAAI,CAAC,CAAC;QAErFhK,OAAO,CAACC,GAAG,CAAC,uCAAuCoK,qBAAqB,CAACtI,MAAM,GAAG,CAAC,GAAGsI,qBAAqB,CAAC5I,IAAI,CAAC,IAAI,CAAC,GAAG,OAAO,EAAE,CAAC;MACrI;IACF,CAAC,CAAC,OAAOO,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,uCAAuC,EAAEA,KAAK,CAAC;IAC/D,CAAC,SAAS;MACRhC,OAAO,CAACsK,QAAQ,CAAC,CAAC;IACpB;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;EACE,MAAMC,kBAAkBA,CACtBvG,UAAkB,EAClBC,OAMC,GAAG,CAAC,CAAC,EACW;IACjB,IAAI;MACF,MAAM;QACJC,eAAe,GAAG,KAAK;QACvBC,cAAc,GAAG,IAAI;QACrBC,OAAO,GAAG,IAAI;QACdoG,SAAS,GAAG,KAAK;QACjB/D,QAAQ,GAAG+D,SAAS,GAAG,aAAa,GAAG;MACzC,CAAC,GAAGvG,OAAO;MAEXjE,OAAO,CAACC,GAAG,CAAC,2CAA2CuK,SAAS,GAAG,KAAK,GAAG,KAAK,KAAK,CAAC;;MAEtF;MACA,IAAI,CAACrB,aAAa,CAACnF,UAAU,EAAEyC,QAAQ,CAAC;;MAExC;MACA,IAAI+D,SAAS,EAAE;QACb,OAAO,IAAI,CAAC5B,kBAAkB,CAAC5E,UAAU,EAAEC,OAAO,CAAC;MACrD;;MAEA;MACA,IAAIwG,cAAc,GAAGzG,UAAU,CAAClC,OAAO,CAAC,IAAI,EAAE,EAAE,CAAC;MACjD9B,OAAO,CAACC,GAAG,CAAC,oEAAoE,EAAEwK,cAAc,CAACnB,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC,CAAC;;MAElH;MACA,IAAIR,iBAAiB,GAAG,IAAI,CAACN,oBAAoB,CAACiC,cAAc,CAAC;;MAEjE;MACA,IAAIzG,UAAU,CAACyE,UAAU,CAAC,CAAC,CAAC,KAAK,MAAM,EAAE;QACvCzI,OAAO,CAACC,GAAG,CAAC,wCAAwC,CAAC;QACrD6I,iBAAiB,GAAG9E,UAAU,CAAC8D,KAAK,CAAC,CAAC,CAAC;MACzC;;MAEA;MACAgB,iBAAiB,GAAG,IAAI,CAACR,qBAAqB,CAACQ,iBAAiB,CAAC;;MAEjE;MACA,MAAMxE,KAAK,GAAGwE,iBAAiB,CAAChG,KAAK,CAAC,OAAO,CAAC,CAACxC,GAAG,CAACmE,IAAI,IAAIA,IAAI,CAACC,IAAI,CAAC,CAAC,CAAC,CAACqE,MAAM,CAACtE,IAAI,IAAIA,IAAI,KAAK,EAAE,CAAC;MAEnG,IAAIH,KAAK,CAACvC,MAAM,KAAK,CAAC,EAAE;QACtB,MAAM,IAAIsC,KAAK,CAAC,sBAAsB,CAAC;MACzC;MAEA,MAAM2E,SAAS,GAAG1E,KAAK,CAAC,CAAC,CAAC;MAE1B,IAAI,CAAC0E,SAAS,EAAE;QACd,MAAM,IAAI3E,KAAK,CAAC,wCAAwC,CAAC;MAC3D;MAEArE,OAAO,CAACC,GAAG,CAAC,4BAA4B,EAAE+I,SAAS,CAAC;;MAEpD;MACA,MAAMxB,QAAQ,GAAG,CAACwB,SAAS,CAAChE,KAAK,CAAC,KAAK,CAAC,IAAI,EAAE,EAAEjD,MAAM;MACtD,MAAM0F,cAAc,GAAG,CAACuB,SAAS,CAAChE,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,EAAEjD,MAAM;MAC3D,MAAM2F,UAAU,GAAG,CAACsB,SAAS,CAAChE,KAAK,CAAC,IAAI,CAAC,IAAI,EAAE,EAAEjD,MAAM;;MAEvD;MACA,IAAIwF,SAAS,GAAG,GAAG;;MAEnB;MACA,MAAMmD,oBAAoB,GAAG1B,SAAS,CAACnH,QAAQ,CAAC,wBAAwB,CAAC,IAC7CmH,SAAS,CAACnH,QAAQ,CAAC,2CAA2C,CAAC,IAC/DmH,SAAS,CAACnH,QAAQ,CAAC,wBAAwB,CAAC,IAC5CmH,SAAS,CAACnH,QAAQ,CAAC,2BAA2B,CAAC;MAE3E,IAAI6I,oBAAoB,EAAE;QACxB1K,OAAO,CAACC,GAAG,CAAC,6EAA6E,CAAC;QAC1FsH,SAAS,GAAG,GAAG;MACjB;MAEAvH,OAAO,CAACC,GAAG,CAAC,uCAAuCuH,QAAQ,sBAAsBC,cAAc,eAAeC,UAAU,EAAE,CAAC;MAC3H1H,OAAO,CAACC,GAAG,CAAC,mBAAmByK,oBAAoB,GAAG,+BAA+B,GAAG,iBAAiB,EAAE,CAAC;;MAE5G;MACA,IAAIF,SAAS,EAAE;QACb,IAAIhD,QAAQ,GAAG,CAAC,EAAE;UAChBD,SAAS,GAAG,IAAI;UAChBvH,OAAO,CAACC,GAAG,CAAC,yCAAyC,CAAC;QACxD,CAAC,MAAM,IAAIwH,cAAc,GAAG,CAAC,IAAIA,cAAc,IAAIC,UAAU,EAAE;UAC7DH,SAAS,GAAG,GAAG;UACfvH,OAAO,CAACC,GAAG,CAAC,4CAA4C,CAAC;QAC3D,CAAC,MAAM,IAAIyH,UAAU,GAAG,CAAC,EAAE;UACzBH,SAAS,GAAG,GAAG;UACfvH,OAAO,CAACC,GAAG,CAAC,sCAAsC,CAAC;QACrD,CAAC,MAAM;UACLD,OAAO,CAACC,GAAG,CAAC,gGAAgG,CAAC;QAC/G;MACF,CAAC,MAAM;QACL;QACA,IAAIuH,QAAQ,GAAG,CAAC,IAAIA,QAAQ,IAAIC,cAAc,IAAID,QAAQ,IAAIE,UAAU,EAAE;UACxEH,SAAS,GAAG,IAAI;UAChBvH,OAAO,CAACC,GAAG,CAAC,yCAAyC,CAAC;QACxD,CAAC,MAAM,IAAIwH,cAAc,GAAG,CAAC,IAAIA,cAAc,IAAIC,UAAU,EAAE;UAC7DH,SAAS,GAAG,GAAG;UACfvH,OAAO,CAACC,GAAG,CAAC,4CAA4C,CAAC;QAC3D,CAAC,MAAM;UACLD,OAAO,CAACC,GAAG,CAAC,sCAAsC,CAAC;QACrD;MACF;;MAEA;MACAD,OAAO,CAACC,GAAG,CAAC,qCAAqC,CAAC;MAClD,KAAK,IAAIuE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGiB,IAAI,CAACC,GAAG,CAAC,CAAC,EAAEpB,KAAK,CAACvC,MAAM,CAAC,EAAEyC,CAAC,EAAE,EAAE;QAClDxE,OAAO,CAACC,GAAG,CAAC,SAASuE,CAAC,KAAKF,KAAK,CAACE,CAAC,CAAC,EAAE,CAAC;MACxC;;MAEA;MACA,IAAIyE,aAAa,GAAG,EAAE;MAEtB,IAAI1B,SAAS,KAAK,GAAG,EAAE;QACrB0B,aAAa,GAAG3E,KAAK,CAAChE,GAAG,CAACmE,IAAI,IAAI;UAChC,IAAI,CAACA,IAAI,EAAE,OAAO,EAAE;;UAEpB;UACA,MAAMwD,MAAgB,GAAG,EAAE;UAC3B,IAAI0C,OAAO,GAAG,EAAE;UAChB,IAAIC,QAAQ,GAAG,KAAK;UAEpB,KAAK,IAAIpG,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGC,IAAI,CAAC1C,MAAM,EAAEyC,CAAC,EAAE,EAAE;YACpC,MAAMwF,IAAI,GAAGvF,IAAI,CAACD,CAAC,CAAC;YAEpB,IAAIwF,IAAI,KAAK,GAAG,EAAE;cAChBY,QAAQ,GAAG,CAACA,QAAQ;cACpBD,OAAO,IAAIX,IAAI;YACjB,CAAC,MAAM,IAAIA,IAAI,KAAKzC,SAAS,IAAI,CAACqD,QAAQ,EAAE;cAC1C3C,MAAM,CAAC9C,IAAI,CAACwF,OAAO,CAAC;cACpBA,OAAO,GAAG,EAAE;YACd,CAAC,MAAM;cACLA,OAAO,IAAIX,IAAI;YACjB;UACF;;UAEA;UACA/B,MAAM,CAAC9C,IAAI,CAACwF,OAAO,CAAC;UAEpB,OAAO1C,MAAM,CAACxG,IAAI,CAAC,GAAG,CAAC;QACzB,CAAC,CAAC,CAACA,IAAI,CAAC,IAAI,CAAC;MACf,CAAC,MAAM;QACLwH,aAAa,GAAGH,iBAAiB;MACnC;;MAEA;MACA,MAAMP,eAAe,GAAGU,aAAa,CAACnG,KAAK,CAAC,OAAO,CAAC,CAACiG,MAAM,CAACtE,IAAI,IAAIA,IAAI,CAACC,IAAI,CAAC,CAAC,KAAK,EAAE,CAAC;MACvF,IAAI6D,eAAe,CAACxG,MAAM,GAAG,CAAC,EAAE;QAC9B;QACA/B,OAAO,CAAC4E,IAAI,CAAC,mFAAmF,CAAC;;QAEjG;QACA,MAAMiG,gBAAgB,GAAGvG,KAAK,CAACyE,MAAM,CAACtE,IAAI,IAAIA,IAAI,CAACC,IAAI,CAAC,CAAC,KAAK,EAAE,CAAC;QAEjE,IAAImG,gBAAgB,CAAC9I,MAAM,GAAG,CAAC,EAAE;UAC/B,MAAM,IAAIsC,KAAK,CAAC,sDAAsD,CAAC;QACzE;;QAEA;QACA,MAAMhD,OAAO,GAAG,IAAI,CAACkD,YAAY,CAACsG,gBAAgB,CAAC,CAAC,CAAC,CAAC;;QAEtD;QACA,IAAIxJ,OAAO,CAACU,MAAM,GAAG,CAAC,EAAE;UACtB,MAAM,IAAIsC,KAAK,CAAC,8BAA8BhD,OAAO,CAACU,MAAM,gJAAgJ,CAAC;QAC/M;QAEA/B,OAAO,CAACC,GAAG,CAAC,2CAA2C,EAAEoB,OAAO,CAAC;;QAEjE;QACA,OAAO,IAAI,CAAC6H,kBAAkB,CAAC7H,OAAO,EAAEwJ,gBAAgB,EAAE5G,OAAO,CAAC;MACpE;;MAEA;MACA,MAAM5C,OAAO,GAAG,IAAI,CAACkD,YAAY,CAACgE,eAAe,CAAC,CAAC,CAAC,CAAC;;MAErD;MACA,IAAIlH,OAAO,CAACU,MAAM,GAAG,CAAC,EAAE;QACtB,MAAM,IAAIsC,KAAK,CAAC,8BAA8BhD,OAAO,CAACU,MAAM,gJAAgJ,CAAC;MAC/M;MAEA/B,OAAO,CAACC,GAAG,CAAC,oBAAoB,EAAEoB,OAAO,CAAC;MAE1C,OAAO,IAAI,CAAC6H,kBAAkB,CAAC7H,OAAO,EAAEkH,eAAe,EAAEtE,OAAO,CAAC;IACnE,CAAC,CAAC,OAAOjC,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,mDAAmDwI,SAAS,GAAG,KAAK,GAAG,KAAK,GAAG,EAAExI,KAAK,CAAC;MACrG,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;EACE,MAAckH,kBAAkBA,CAC9B7H,OAAiB,EACjBiD,KAAe,EACfL,OAIC,GAAG,CAAC,CAAC,EACW;IACjB,IAAI;MACF,MAAM;QACJC,eAAe,GAAG,KAAK;QACvBC,cAAc,GAAG,IAAI;QACrBC,OAAO,GAAG;MACZ,CAAC,GAAGH,OAAO;;MAEX;MACA,MAAM6G,QAAQ,GAAGzL,UAAU,CAACD,EAAE,EAAE,OAAO,CAAC;MACxC,MAAM2L,aAAa,GAAG,MAAMzL,OAAO,CAACwL,QAAQ,CAAC;MAC7C,MAAME,gBAAgB,GAAG,IAAIC,GAAG,CAAc,CAAC;MAC/C,MAAMC,mBAAmB,GAAG,IAAID,GAAG,CAAc,CAAC;MAClD,MAAME,sBAAsB,GAAG,IAAIF,GAAG,CAAc,CAAC;MAErDF,aAAa,CAACpK,OAAO,CAACnB,GAAG,IAAI;QAC3B,MAAM4L,QAAQ,GAAG5L,GAAG,CAACe,IAAI,CAAC,CAAC;QAC3ByK,gBAAgB,CAACnF,GAAG,CAACrG,GAAG,CAACwB,EAAE,EAAEoK,QAAQ,CAAC;;QAEtC;QACA,IAAIA,QAAQ,CAACC,GAAG,EAAE;UAChB,MAAMC,cAAc,GAAGF,QAAQ,CAACC,GAAG,CAACtE,WAAW,CAAC,CAAC,CAACrC,IAAI,CAAC,CAAC;UACxDwG,mBAAmB,CAACrF,GAAG,CAACyF,cAAc,EAAE;YAAEtK,EAAE,EAAExB,GAAG,CAACwB,EAAE;YAAE,GAAGoK;UAAS,CAAC,CAAC;QACtE;;QAEA;QACA,IAAIA,QAAQ,CAACG,OAAO,IAAIH,QAAQ,CAACI,KAAK,IAAIJ,QAAQ,CAACK,UAAU,EAAE;UAC7D,MAAMC,iBAAiB,GAAG,GAAGN,QAAQ,CAACG,OAAO,IAAIH,QAAQ,CAACI,KAAK,IAAIJ,QAAQ,CAACK,UAAU,EAAE,CACrF1E,WAAW,CAAC,CAAC,CACbjF,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,CACnB6J,SAAS,CAAC,KAAK,CAAC,CAChB7J,OAAO,CAAC,kBAAkB,EAAE,EAAE,CAAC;UAClCqJ,sBAAsB,CAACtF,GAAG,CAAC6F,iBAAiB,EAAE;YAAE1K,EAAE,EAAExB,GAAG,CAACwB,EAAE;YAAE,GAAGoK;UAAS,CAAC,CAAC;QAC5E;MACF,CAAC,CAAC;;MAEF;MACA,MAAMQ,cAAc,GAAGvK,OAAO,CAACf,GAAG,CAACqB,MAAM,IAAIA,MAAM,CAACG,OAAO,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC;MACtE,MAAM+J,iBAAiB,GAAG,IAAI,CAACC,gBAAgB,CAACF,cAAc,CAAC;MAE/D,IAAIG,WAAW,GAAG,CAAC;MACnB,IAAIC,SAAS,GAAG,CAAC;MACjB,IAAIC,WAAW,GAAG,CAAC;;MAEnB;MACA,MAAMC,UAAU,GAAG,GAAG;MACtB,MAAMC,UAAU,GAAG7H,KAAK,CAACvC,MAAM,GAAG,CAAC,CAAC,CAAC;;MAErC,KAAK,IAAIqK,UAAU,GAAG,CAAC,EAAEA,UAAU,GAAG9H,KAAK,CAACvC,MAAM,EAAEqK,UAAU,IAAIF,UAAU,EAAE;QAC5E;QACA,MAAM3G,KAAK,GAAG9F,UAAU,CAACL,EAAE,CAAC;QAC5B,IAAIiN,UAAU,GAAG,CAAC;QAElB,MAAMC,QAAQ,GAAG7G,IAAI,CAACC,GAAG,CAAC0G,UAAU,GAAGF,UAAU,EAAE5H,KAAK,CAACvC,MAAM,CAAC;QAEhE,KAAK,IAAIyC,CAAC,GAAG4H,UAAU,EAAE5H,CAAC,GAAG8H,QAAQ,EAAE9H,CAAC,EAAE,EAAE;UAC1C,MAAMC,IAAI,GAAGH,KAAK,CAACE,CAAC,CAAC;UACrB,IAAI,CAACC,IAAI,CAACC,IAAI,CAAC,CAAC,EAAE;UAElB,MAAMC,MAAM,GAAG,IAAI,CAACJ,YAAY,CAACE,IAAI,CAAC;UACtC,MAAM/B,QAA6B,GAAG,CAAC,CAAC;;UAExC;UACAmJ,iBAAiB,CAAClL,OAAO,CAAC,CAACgB,MAAM,EAAE4K,KAAK,KAAK;YAC3C,IAAI5K,MAAM,IAAIgD,MAAM,CAAC4H,KAAK,CAAC,EAAE;cAC3B7J,QAAQ,CAACf,MAAM,CAAC,GAAG,IAAI,CAAC6K,cAAc,CAAC7H,MAAM,CAAC4H,KAAK,CAAC,CAAC7H,IAAI,CAAC,CAAC,EAAE/C,MAAM,CAAC;YACtE;UACF,CAAC,CAAC;;UAEF;UACA,IAAI8K,YAAY,GAAG,IAAI;;UAEvB;UACA,IAAI/J,QAAQ,CAAC1B,EAAE,EAAE;YACfyL,YAAY,GAAGzB,gBAAgB,CAAC0B,GAAG,CAAChK,QAAQ,CAAC1B,EAAE,CAAC;UAClD;;UAEA;UACA,IAAI,CAACyL,YAAY,IAAI/J,QAAQ,CAAC2I,GAAG,EAAE;YACjC,MAAMC,cAAc,GAAG5I,QAAQ,CAAC2I,GAAG,CAACtE,WAAW,CAAC,CAAC,CAACrC,IAAI,CAAC,CAAC;YACxD+H,YAAY,GAAGvB,mBAAmB,CAACwB,GAAG,CAACpB,cAAc,CAAC;UACxD;;UAEA;UACA,IAAI,CAACmB,YAAY,IAAI/J,QAAQ,CAAC6I,OAAO,IAAI7I,QAAQ,CAAC8I,KAAK,IAAI9I,QAAQ,CAAC+I,UAAU,EAAE;YAC9E,MAAMC,iBAAiB,GAAG,GAAGhJ,QAAQ,CAAC6I,OAAO,IAAI7I,QAAQ,CAAC8I,KAAK,IAAI9I,QAAQ,CAAC+I,UAAU,EAAE,CACrF1E,WAAW,CAAC,CAAC,CACbjF,OAAO,CAAC,MAAM,EAAE,EAAE,CAAC,CACnB6J,SAAS,CAAC,KAAK,CAAC,CAChB7J,OAAO,CAAC,kBAAkB,EAAE,EAAE,CAAC;YAClC2K,YAAY,GAAGtB,sBAAsB,CAACuB,GAAG,CAAChB,iBAAiB,CAAC;UAC9D;;UAEA;UACA,IAAIe,YAAY,EAAE;YAChB,IAAI,CAACtI,cAAc,EAAE;cACnB6H,SAAS,EAAE;cACX;YACF;;YAEA;YACA,MAAMW,UAAU,GAAGlM,MAAM,CAACU,IAAI,CAACuB,QAAQ,CAAC,CAACkK,IAAI,CAAChM,GAAG,IAC/C8B,QAAQ,CAAC9B,GAAG,CAAC,KAAK6L,YAAY,CAAC7L,GAAG,CAAC,IAAI8B,QAAQ,CAAC9B,GAAG,CAAC,KAAKgB,SAC3D,CAAC;YAED,IAAI,CAAC+K,UAAU,EAAE;cACfX,SAAS,EAAE;cACX;YACF;;YAEA;YACA,MAAMa,OAAO,GAAGrN,GAAG,CAACJ,EAAE,EAAE,OAAO,EAAEqN,YAAY,CAACzL,EAAE,CAAC;YACjDuE,KAAK,CAACM,GAAG,CAACgH,OAAO,EAAEnK,QAAQ,CAAC;YAC5BuJ,WAAW,EAAE;YACbI,UAAU,EAAE;UACd,CAAC,MAAM;YACL;YACA,MAAMS,UAAU,GAAGtN,GAAG,CAACH,UAAU,CAACD,EAAE,EAAE,OAAO,CAAC,CAAC;YAC/CmG,KAAK,CAACM,GAAG,CAACiH,UAAU,EAAEpK,QAAQ,CAAC;YAC/BqJ,WAAW,EAAE;YACbM,UAAU,EAAE;UACd;QACF;;QAEA;QACA,IAAIA,UAAU,GAAG,CAAC,EAAE;UAClB,MAAM9G,KAAK,CAACS,MAAM,CAAC,CAAC;UACpBhG,OAAO,CAACC,GAAG,CAAC,UAAUoM,UAAU,sBAAsBD,UAAU,IAAID,UAAU,GAAG,CAAC;QACpF;MACF;MAEAnM,OAAO,CAACC,GAAG,CAAC;AAClB;AACA,YAAY8L,WAAW;AACvB,YAAYE,WAAW;AACvB,YAAYD,SAAS;AACrB,OAAO,CAAC;MAEF,OAAOD,WAAW,GAAGE,WAAW;IAClC,CAAC,CAAC,OAAOjK,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,uCAAuC,EAAEA,KAAK,CAAC;MAC7D,MAAMA,KAAK;IACb;EACF;;EAEA;AACF;AACA;AACA;AACA;EACU8J,gBAAgBA,CAACzK,OAAiB,EAAY;IACpDrB,OAAO,CAACC,GAAG,CAAC,+BAA+B,CAAC;IAC5CD,OAAO,CAACC,GAAG,CAAC,qBAAqB,EAAEoB,OAAO,CAAC;;IAE3C;IACA,MAAM0L,kBAA0C,GAAG;MACjD;MACA,MAAM,EAAE,MAAM;MACd,MAAM,EAAE,MAAM;MACd,OAAO,EAAE,MAAM;MACf,OAAO,EAAE,MAAM;MACf,KAAK,EAAE,MAAM;MACb,MAAM,EAAE,MAAM;MACd,MAAM,EAAE,MAAM;MACd,MAAM,EAAE,MAAM;MAEd;MACA,MAAM,EAAE,MAAM;MACd,cAAc,EAAE,MAAM;MACtB,WAAW,EAAE,MAAM;MACnB,WAAW,EAAE,MAAM;MACnB,WAAW,EAAE,MAAM;MAEnB;MACA,KAAK,EAAE,KAAK;MACZ,UAAU,EAAE,KAAK;MACjB,MAAM,EAAE,KAAK;MACb,aAAa,EAAE,KAAK;MACpB,cAAc,EAAE,KAAK;MACrB,cAAc,EAAE,KAAK;MAErB;MACA,SAAS,EAAE,SAAS;MACpB,UAAU,EAAE,SAAS;MACrB,KAAK,EAAE,SAAS;MAChB,cAAc,EAAE,SAAS;MACzB,kBAAkB,EAAE,SAAS;MAC7B,kBAAkB,EAAE,SAAS;MAE7B;MACA,YAAY,EAAE,mBAAmB;MACjC,YAAY,EAAE,mBAAmB;MACjC,oBAAoB,EAAE,mBAAmB;MACzC,oBAAoB,EAAE,mBAAmB;MACzC,uBAAuB,EAAE,mBAAmB;MAC5C,uBAAuB,EAAE,mBAAmB;MAE5C;MACA,OAAO,EAAE,OAAO;MAChB,SAAS,EAAE,OAAO;MAClB,UAAU,EAAE,OAAO;MACnB,UAAU,EAAE,OAAO;MACnB,QAAQ,EAAE,OAAO;MAEjB;MACA,IAAI,EAAE,YAAY;MAClB,aAAa,EAAE,YAAY;MAC3B,aAAa,EAAE,YAAY;MAC3B,YAAY,EAAE,YAAY;MAC1B,SAAS,EAAE,YAAY;MAEvB;MACA,MAAM,EAAE,MAAM;MACd,SAAS,EAAE,MAAM;MACjB,QAAQ,EAAE,MAAM;MAEhB;MACA,KAAK,EAAE,WAAW;MAClB,KAAK,EAAE,WAAW;MAClB,WAAW,EAAE,WAAW;MACxB,WAAW,EAAE,WAAW;MACxB,SAAS,EAAE,WAAW;MACtB,QAAQ,EAAE,WAAW;MAErB;MACA,OAAO,EAAE,OAAO;MAChB,QAAQ,EAAE,OAAO;MACjB,MAAM,EAAE,OAAO;MACf,UAAU,EAAE,OAAO;MACnB,cAAc,EAAE,OAAO;MAEvB;MACA,QAAQ,EAAE,QAAQ;MAClB,QAAQ,EAAE,QAAQ;MAClB,MAAM,EAAE,QAAQ;MAChB,MAAM,EAAE,QAAQ;MAEhB;MACA,SAAS,EAAE,UAAU;MACrB,SAAS,EAAE,UAAU;MACrB,UAAU,EAAE,UAAU;MACtB,UAAU,EAAE,UAAU;MAEtB;MACA,IAAI,EAAE,IAAI;MACV,aAAa,EAAE,IAAI;MACnB,gBAAgB,EAAE,IAAI;MAEtB;MACA,QAAQ,EAAE,QAAQ;MAClB,MAAM,EAAE,QAAQ;MAChB,SAAS,EAAE,QAAQ;MAEnB;MACA,IAAI,EAAE,IAAI;MACV,aAAa,EAAE,IAAI;MACnB,WAAW,EAAE,IAAI;MACjB,WAAW,EAAE,IAAI;MACjB,aAAa,EAAE,YAAY;MAC3B,YAAY,EAAE,YAAY;MAC1B,kBAAkB,EAAE,YAAY;MAChC,cAAc,EAAE,gBAAgB;MAChC,aAAa,EAAE,gBAAgB;MAC/B,iBAAiB,EAAE;IACrB,CAAC;;IAED;IACA,MAAMlB,iBAAiB,GAAGxK,OAAO,CAACf,GAAG,CAACqB,MAAM,IAAI;MAC9C;MACA,MAAMqL,WAAW,GAAGrL,MAAM,CACvB+C,IAAI,CAAC,CAAC,CACNqC,WAAW,CAAC,CAAC,CACb4E,SAAS,CAAC,KAAK,CAAC,CAChB7J,OAAO,CAAC,kBAAkB,EAAE,EAAE,CAAC,CAAC;MAAA,CAChCA,OAAO,CAAC,cAAc,EAAE,GAAG,CAAC,CAAC;MAAA,CAC7BA,OAAO,CAAC,MAAM,EAAE,GAAG,CAAC,CAAC;MAAA,CACrB4C,IAAI,CAAC,CAAC;;MAET;MACA,MAAMuI,YAAY,GAAGF,kBAAkB,CAACC,WAAW,CAAC;MAEpD,IAAIC,YAAY,EAAE;QAChBjN,OAAO,CAACC,GAAG,CAAC,uBAAuB0B,MAAM,SAASsL,YAAY,GAAG,CAAC;QAClE,OAAOA,YAAY;MACrB;;MAEA;MACAjN,OAAO,CAACC,GAAG,CAAC,uBAAuB0B,MAAM,SAASqL,WAAW,GAAG,CAAC;MACjE,OAAOA,WAAW;IACpB,CAAC,CAAC;IAEFhN,OAAO,CAACC,GAAG,CAAC,sCAAsC,EAAE4L,iBAAiB,CAAC;IACtE,OAAOA,iBAAiB;EAC1B;;EAEA;AACF;AACA;AACA;AACA;AACA;EACUW,cAAcA,CAAC3L,KAAa,EAAEqM,SAAiB,EAAU;IAC/D,IAAI,CAACrM,KAAK,EAAE,OAAO,EAAE;;IAErB;IACA,IAAIsM,eAAe,GAAGtM,KAAK,CAAC6D,IAAI,CAAC,CAAC,CAC/B5C,OAAO,CAAC,OAAO,EAAE,EAAE,CAAC,CACpBA,OAAO,CAAC,MAAM,EAAE,GAAG,CAAC;;IAEvB;IACA,QAAQoL,SAAS,CAACnG,WAAW,CAAC,CAAC;MAC7B,KAAK,MAAM;QACT;QACAoG,eAAe,GAAGA,eAAe,CAC9BrL,OAAO,CAAC,eAAe,EAAE,EAAE,CAAC,CAC5BA,OAAO,CAAC,kBAAkB,EAAE,EAAE,CAAC,CAC/B4C,IAAI,CAAC,CAAC;QACT;MAEF,KAAK,MAAM;QACT;QACA,MAAM0I,UAAU,GAAGD,eAAe,CAACpG,WAAW,CAAC,CAAC;QAChD,IAAIqG,UAAU,CAACvL,QAAQ,CAAC,MAAM,CAAC,IAAIuL,UAAU,CAACvL,QAAQ,CAAC,KAAK,CAAC,EAAE;UAC7DsL,eAAe,GAAG,aAAa;QACjC,CAAC,MAAM,IAAIC,UAAU,CAACvL,QAAQ,CAAC,MAAM,CAAC,EAAE;UACtCsL,eAAe,GAAG,MAAM;QAC1B,CAAC,MAAM,IAAIC,UAAU,CAACvL,QAAQ,CAAC,QAAQ,CAAC,EAAE;UACxCsL,eAAe,GAAG,QAAQ;QAC5B,CAAC,MAAM,IAAIC,UAAU,CAACvL,QAAQ,CAAC,OAAO,CAAC,EAAE;UACvCsL,eAAe,GAAG,mBAAmB;QACvC,CAAC,MAAM;UACLA,eAAe,GAAGA,eAAe,CAACE,MAAM,CAAC,CAAC,CAAC,CAACC,WAAW,CAAC,CAAC,GAAGH,eAAe,CAACrF,KAAK,CAAC,CAAC,CAAC,CAACf,WAAW,CAAC,CAAC;QACpG;QACA;MAEF,KAAK,OAAO;MACZ,KAAK,KAAK;QACR;QACAoG,eAAe,GAAGA,eAAe,CAACrK,KAAK,CAAC,GAAG,CAAC,CACzCxC,GAAG,CAACiN,IAAI,IAAIA,IAAI,CAACF,MAAM,CAAC,CAAC,CAAC,CAACC,WAAW,CAAC,CAAC,GAAGC,IAAI,CAACzF,KAAK,CAAC,CAAC,CAAC,CAACf,WAAW,CAAC,CAAC,CAAC,CACvEtF,IAAI,CAAC,GAAG,CAAC;QACZ;MAEF,KAAK,YAAY;QACf;QACA0L,eAAe,GAAGA,eAAe,CAACrL,OAAO,CAAC,KAAK,EAAE,EAAE,CAAC;QACpD;MAEF,KAAK,WAAW;QACd;QACAqL,eAAe,GAAGA,eAAe,CAACrL,OAAO,CAAC,KAAK,EAAE,EAAE,CAAC;QACpD,IAAIqL,eAAe,CAACpL,MAAM,KAAK,EAAE,EAAE;UACjCoL,eAAe,GAAGA,eAAe,CAACrL,OAAO,CAAC,qCAAqC,EAAE,gBAAgB,CAAC;QACpG;QACA;MAEF,KAAK,OAAO;QACV;QACAqL,eAAe,GAAGA,eAAe,CAACpG,WAAW,CAAC,CAAC;QAC/C;MAEF,KAAK,SAAS;QACZ;QACAoG,eAAe,GAAGA,eAAe,CAC9BrL,OAAO,CAAC,MAAM,EAAE,GAAG,CAAC,CACpBA,OAAO,CAAC,OAAO,EAAE,IAAI,CAAC,CACtBA,OAAO,CAAC,UAAU,EAAE,GAAG,CAAC,CACxB4C,IAAI,CAAC,CAAC;QACT;IACJ;IAEA,OAAOyI,eAAe;EACxB;;EAEA;AACF;AACA;AACA;AACA;AACA;EACE,MAAMK,wBAAwBA,CAC5BxJ,UAAkB,EAClBC,OAIC,GAAG,CAAC,CAAC,EACW;IACjB,IAAI;MACFjE,OAAO,CAACC,GAAG,CAAC,+DAA+D,CAAC;;MAE5E;MACA,MAAM;QACJiE,eAAe,GAAG,KAAK;QACvBC,cAAc,GAAG,IAAI;QACrBC,OAAO,GAAG;MACZ,CAAC,GAAGH,OAAO;;MAEX;MACA,MAAMK,KAAK,GAAGN,UAAU,CAAClB,KAAK,CAAC,IAAI,CAAC,CAACiG,MAAM,CAACtE,IAAI,IAAIA,IAAI,CAACC,IAAI,CAAC,CAAC,KAAK,EAAE,CAAC;MAEvE,IAAIJ,KAAK,CAACvC,MAAM,GAAG,CAAC,EAAE;QACpB,MAAM,IAAIsC,KAAK,CAAC,sDAAsD,CAAC;MACzE;;MAEA;MACA,MAAMhD,OAAO,GAAGiD,KAAK,CAAC,CAAC,CAAC,CAACxB,KAAK,CAAC,GAAG,CAAC,CAACxC,GAAG,CAACqB,MAAM,IAAIA,MAAM,CAAC+C,IAAI,CAAC,CAAC,CAAC;MAChE,MAAMmH,iBAAiB,GAAG,IAAI,CAACC,gBAAgB,CAACzK,OAAO,CAAC;MACxDrB,OAAO,CAACC,GAAG,CAAC,sBAAsB,EAAE4L,iBAAiB,CAAC;;MAEtD;MACA,MAAM4B,QAAgC,GAAG;QACvC,MAAM,EAAE,MAAM;QACd,MAAM,EAAE,MAAM;QACd,SAAS,EAAE,UAAU;QACrB,cAAc,EAAE,MAAM;QACtB,KAAK,EAAE,KAAK;QACZ,SAAS,EAAE,SAAS;QACpB,uBAAuB,EAAE,mBAAmB;QAC5C,OAAO,EAAE,OAAO;QAChB,aAAa,EAAE,YAAY;QAC3B,MAAM,EAAE,MAAM;QACd,yCAAyC,EAAE,YAAY;QACvD,iCAAiC,EAAE,gBAAgB;QACnD,IAAI,EAAE;MACR,CAAC;;MAED;MACA,MAAMC,SAAiC,GAAG,CAAC,CAAC;MAC5C7B,iBAAiB,CAAClL,OAAO,CAAC,CAACgB,MAAM,EAAE4K,KAAK,KAAK;QAC3C,MAAMoB,WAAW,GAAGF,QAAQ,CAAC9L,MAAM,CAACoF,WAAW,CAAC,CAAC,CAAC;QAClD,IAAI4G,WAAW,EAAE;UACfD,SAAS,CAACnB,KAAK,CAAC,GAAGoB,WAAW;UAC9B3N,OAAO,CAACC,GAAG,CAAC,kBAAkB0B,MAAM,eAAegM,WAAW,GAAG,CAAC;QACpE,CAAC,MAAM;UACL3N,OAAO,CAACC,GAAG,CAAC,gCAAgC0B,MAAM,GAAG,CAAC;QACxD;MACF,CAAC,CAAC;;MAEF;MACA,MAAMvB,SAAgC,GAAG,EAAE;;MAE3C;MACA,KAAK,IAAIoE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,KAAK,CAACvC,MAAM,EAAEyC,CAAC,EAAE,EAAE;QACrC,MAAMC,IAAI,GAAGH,KAAK,CAACE,CAAC,CAAC,CAACE,IAAI,CAAC,CAAC;QAC5B,IAAI,CAACD,IAAI,EAAE;;QAEX;QACA,MAAME,MAAM,GAAGF,IAAI,CAAC3B,KAAK,CAAC,GAAG,CAAC;;QAE9B;QACA,MAAMtD,GAAwB,GAAG;UAC/BoO,IAAI,EAAE,EAAE;UACRvC,GAAG,EAAE,EAAE;UACPhJ,IAAI,EAAE,aAAa;UACnBkJ,OAAO,EAAE,EAAE;UACXC,KAAK,EAAE,EAAE;UACTC,UAAU,EAAE,EAAE;UACdoC,SAAS,EAAE,EAAE;UACbC,KAAK,EAAE,EAAE;UACTC,UAAU,EAAE,EAAE;UACdC,QAAQ,EAAE,EAAE;UACZC,UAAU,EAAE,EAAE;UACdC,WAAW,EAAE,EAAE;UACfC,MAAM,EAAE,OAAO;UACfC,iBAAiB,EAAE,EAAE;UACrBC,IAAI,EAAE,QAAQ;UACdC,UAAU,EAAE,EAAE;UACdC,cAAc,EAAE;QAClB,CAAC;;QAED;QACA,IAAIC,YAAY,GAAG,KAAK;QAExB,KAAK,IAAI3J,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,MAAM,CAAC5C,MAAM,EAAE8C,CAAC,EAAE,EAAE;UACtC,MAAMqI,SAAS,GAAGQ,SAAS,CAAC7I,CAAC,CAAC;UAC9B,IAAI,CAACqI,SAAS,EAAE;UAEhB,IAAIrM,KAAK,GAAG8D,MAAM,CAACE,CAAC,CAAC,CAACH,IAAI,CAAC,CAAC;;UAE5B;UACA,IAAIwI,SAAS,KAAK,UAAU,IAAIrM,KAAK,EAAE;YACrC;YACAA,KAAK,GAAG,CAACA,KAAK,CAAC;UACjB,CAAC,MAAM,IAAIqM,SAAS,KAAK,MAAM,IAAIrM,KAAK,EAAE;YACxC;YACA,MAAMuM,UAAU,GAAGvM,KAAK,CAACkG,WAAW,CAAC,CAAC;YACtC,IAAIqG,UAAU,CAACvL,QAAQ,CAAC,MAAM,CAAC,IAAIuL,UAAU,CAACvL,QAAQ,CAAC,KAAK,CAAC,EAAE;cAC7DhB,KAAK,GAAG,aAAa;YACvB,CAAC,MAAM,IAAIuM,UAAU,CAACvL,QAAQ,CAAC,MAAM,CAAC,EAAE;cACtChB,KAAK,GAAG,MAAM;YAChB,CAAC,MAAM,IAAIuM,UAAU,CAACvL,QAAQ,CAAC,QAAQ,CAAC,EAAE;cACxChB,KAAK,GAAG,QAAQ;YAClB,CAAC,MAAM,IAAIuM,UAAU,CAACvL,QAAQ,CAAC,OAAO,CAAC,EAAE;cACvChB,KAAK,GAAG,mBAAmB;YAC7B,CAAC,MAAM;cACLA,KAAK,GAAGA,KAAK,CAACwM,MAAM,CAAC,CAAC,CAAC,CAACC,WAAW,CAAC,CAAC,GAAGzM,KAAK,CAACiH,KAAK,CAAC,CAAC,CAAC,CAACf,WAAW,CAAC,CAAC;YACtE;UACF;;UAEA;UACA,IAAIlG,KAAK,KAAK,EAAE,EAAE;YAChBrB,GAAG,CAAC0N,SAAS,CAAC,GAAGrM,KAAK;;YAEtB;YACA,IAAIqM,SAAS,KAAK,KAAK,IAAIrM,KAAK,EAAE;cAChC2N,YAAY,GAAG,IAAI;YACrB;UACF;QACF;;QAEA;QACA,IAAI,CAACA,YAAY,IAAI,CAAChP,GAAG,CAAC6L,GAAG,IAAI7L,GAAG,CAAC+L,OAAO,EAAE;UAC5C/L,GAAG,CAAC6L,GAAG,GAAG,UAAU7L,GAAG,CAAC+L,OAAO,EAAE;UACjCiD,YAAY,GAAG,IAAI;QACrB;;QAEA;QACA,IAAIA,YAAY,IAAIhP,GAAG,CAACwB,EAAE,EAAE;UAC1BZ,SAAS,CAAC+E,IAAI,CAAC3F,GAAG,CAAC;QACrB,CAAC,MAAM;UACLQ,OAAO,CAAC4E,IAAI,CAAC,YAAYJ,CAAC,GAAG,CAAC,kDAAkD,CAAC;QACnF;MACF;MAEA,IAAIpE,SAAS,CAAC2B,MAAM,KAAK,CAAC,EAAE;QAC1B,MAAM,IAAIsC,KAAK,CAAC,wDAAwD,CAAC;MAC3E;MAEArE,OAAO,CAACC,GAAG,CAAC,KAAKG,SAAS,CAAC2B,MAAM,oCAAoC,CAAC;;MAEtE;MACA,IAAImC,eAAe,EAAE;QACnB,MAAM,IAAI,CAACA,eAAe,CAAC,OAAO,CAAC;MACrC;;MAEA;MACA,MAAMkB,cAAc,GAAGhF,SAAS,CAAC2B,MAAM;MACvC,IAAIsD,cAAc,GAAG,CAAC;MACtB,IAAIC,aAAa,GAAG,CAAC;MAErB,OAAOD,cAAc,GAAGD,cAAc,EAAE;QACtC;QACA,MAAMG,KAAK,GAAG9F,UAAU,CAACL,EAAE,CAAC;QAC5B,MAAMoG,SAAS,GAAGC,IAAI,CAACC,GAAG,CAAC,GAAG,EAAEN,cAAc,GAAGC,cAAc,CAAC;;QAEhE;QACA,KAAK,IAAIb,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGgB,SAAS,EAAEhB,CAAC,EAAE,EAAE;UAClC,MAAM9B,QAAQ,GAAGtC,SAAS,CAACiF,cAAc,GAAGb,CAAC,CAAC;UAC9C,MAAMmB,KAAK,GAAGjD,QAAQ,CAAC0B,OAAO,CAAC;UAE/B,IAAIuB,KAAK,IAAIxB,cAAc,EAAE;YAC3B;YACA,MAAMyB,MAAM,GAAGpG,GAAG,CAACJ,EAAE,EAAE,OAAO,EAAEuG,KAAK,CAAC;YACtCJ,KAAK,CAACM,GAAG,CAACD,MAAM,EAAElD,QAAQ,CAAC;UAC7B,CAAC,MAAM;YACL;YACA,MAAMoD,aAAa,GAAGzG,UAAU,CAACD,EAAE,EAAE,OAAO,CAAC;YAC7C,MAAM2G,SAAS,GAAGvG,GAAG,CAACsG,aAAa,CAAC;YACpCP,KAAK,CAACM,GAAG,CAACE,SAAS,EAAErD,QAAQ,CAAC;UAChC;UAEA4C,aAAa,EAAE;QACjB;;QAEA;QACA,MAAMC,KAAK,CAACS,MAAM,CAAC,CAAC;QACpBX,cAAc,IAAIG,SAAS;QAC3BxF,OAAO,CAACC,GAAG,CAAC,YAAYuF,SAAS,oBAAoBH,cAAc,IAAID,cAAc,GAAG,CAAC;MAC3F;MAEApF,OAAO,CAACC,GAAG,CAAC,2BAA2BqF,aAAa,iBAAiB,CAAC;MACtE,OAAOA,aAAa;IACtB,CAAC,CAAC,OAAOtD,KAAK,EAAE;MACdhC,OAAO,CAACgC,KAAK,CAAC,4DAA4D,EAAEA,KAAK,CAAC;MAClF,MAAMA,KAAK;IACb;EACF;AACF;AAEA,eAAe,IAAIrC,iBAAiB,CAAC,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}